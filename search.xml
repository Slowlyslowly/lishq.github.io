<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JMM内存模型]]></title>
    <url>%2F2019%2F01%2F11%2FJMM-Mind%2F</url>
    <content type="text"><![CDATA[介绍Java内存模型思维导图 原图地址：https://lishq.oss-cn-beijing.aliyuncs.com/github.io/JMM-Mind.png 参考： 《并发编程的艺术》]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 实用指南]]></title>
    <url>%2F2019%2F01%2F10%2Fgit-review%2F</url>
    <content type="text"><![CDATA[前言分布式 VCS 和中央式的区别在于，分布式 VCS 除了中央仓库之外，还有本地仓库：团队中每一个成员的机器上都有一份本地仓库，这个仓库里包含了所有的版本历史，或者换句话说，每个人在自己的机器上就可以提交代码、查看历史，而无需联网和中央仓库交互。 优点： 大多数的操作可以在本地进行，所以速度更快，而且由于无需联网，所以即使不在公司甚至没有在联网，你也可以提交代码、查看历史，从而极大地减小了开发者的网络条件和物理位置的限制。 由于可以提交到本地，所以你可以分步提交代码，把代码提交做得更细，而不是一个提交包含很多代码，难以 review 也难以回溯。 缺点： 由于每一个机器都有完整的本地仓库，所以初次获取项目的时候会比较耗时。 由于每个机器都有完整的本地仓库，所以本地占用的存储比中央式 VCS 要高。 实用指南 把远程仓库取到本地 1git clone 远程仓库地址 把写完的代码提交 1234567891011添加文件到暂存区git add . 【添加所有文件到暂存区，add也支持匹配表达式，如 git add *.java】git add 文件名 【添加指定文件到暂存区】git commit -m '你提交的信息'注意：直接执行 git commit 时可能弹出“输入提交的信息界面”，需要按一下 "i"（小写）来切换到插入模式，然后就可以输入你的提交信息了；在输入完成后别按回车，而是要按 ESC 键返回到命令模式，然后连续输入两个大写的 "Z"，就保存并退出了。在这个过程中，可以使用 git status 来随时查看工作目录的状态：每个文件有 "changed / unstaged"（已修改）, "staged"（已修改并暂存）, "commited"（已提交） 三种状态，以及一种特殊状态 "untracked"（未跟踪）提交一次或多次之后，把本地提交 push 到中央仓库（git push）注意：如果 push 失败，就用 pull（git pull） 把本地仓库的提交和中央仓库的提交进行合并，然后再 push 一次 git log 列出提交历史git log -p 查看详细历史git log --stat 查看简要统计git show 查看具体的 commitgit diff --staged 比对暂存区和上一条提交git diff 比对工作目录和暂存区git diff HEAD 比对工作目录和上一条提交 .gitignore——排除不想被管理的文件和目录 123.gitignore，这个文本文件记录了所有你希望被 Git 忽略的目录和文件。文件中 # 打头的是注释文件，其他的都是对忽略文件的配置。匹配规则：https://git-scm.com/docs/gitignore 偏移符号 12345在 Git 中，有两个「偏移符号」： ^ 和 ~。^ 的用法：在 commit 的后面加一个或多个 ^ 号，可以把 commit 往回偏移，偏移的数量是 ^ 的数量。例如：master^ 表示 master 指向的 commit 之前的那个 commit； HEAD^^ 表示 HEAD 所指向的 commit 往前数两个 commit。~ 的用法：在 commit 的后面加上 ~ 号和一个数，可以把 commit 往回偏移，偏移的数量是 ~ 号后面的数。例如：HEAD~5 表示 HEAD 指向的 commit往前数 5 个 commit。 HEAD、master 与 branch1.HEAD 2.master 3.branch -------------------------------------------------------------------- 1.HEAD 是指向当前 commit 的引用，它具有唯一性，每个仓库中只有一个 HEAD。在每次提交时它都会自动向前移动到最新的 commit 2.branch 是一类引用。HEAD 除了直接指向 commit，也可以通过指向某个 branch 来间接指向 commit。当 HEAD 指向一个 branch 时，commit 发生时，HEAD 会带着它所指向的 branch 一起移动。 3.master 是 Git 中的默认 branch，它和其它 branch 的区别在于： a.新建的仓库中的第一个 commit 会被 master 自动指向； b.在 git clone 时，会自动 checkout 出 master。 4.branch 的创建、切换、删除和提交： a.创建 branch 的方式是 git branch 名称 或 git checkout -b 名称（创建后自动切换）； b.切换的方式是 git checkout 名称； c.push 的时候，如果当前分支是一个本地创建的分支，需要指定远程仓库名和分支名，用 git push origin branch_name 的格式，而不能只用 git push； 或者可以通过 git config 修改 push.default 来改变 push 时的行为逻辑。 d.git branch -a 看到所有分支 5.branch 的删除： a.git branch -d 名称。 b.git push origin -d branch_name # 用 -d 参数把远程仓库的 branch 也删了 c.git push origin :branch 注意： 1. HEAD 指向的 branch 不能删除。如果要删除 HEAD 指向的 branch，需要先用 checkout 把 HEAD 指向其他地方。 2. 由于 Git 中的 branch 只是一个引用，所以删除 branch 的操作也只会删掉这个引用，并不会删除任何的 commit（一定时间后，会被 Git 的回收机制删除掉） 3. 出于安全考虑，没有被合并到 master 过的 branch 在删除时会失败（如果你确认是要删除这个 branch，可以把 -d 改成 -D） Merge从两个 commit「分叉」的位置起，把目标 commit 的内容应用到当前 commit（HEAD 所指向的 commit），并生成一个新的 commit； 适用场景 合并分支 121. 当一个 branch 的开发已经完成，需要把内容合并回去时，用 merge 来进行合并。2. git merge branch1 pull 的内部操作 11. pull 的实际操作其实是把远端仓库的内容用 fetch 取下来之后，用 merge 来合并。 冲突 解决冲突后手动 commit git merge –abort 【放弃解决冲突，取消 merge】 Feature Branching：工作流 任何新的功能（feature）或 bug 修复全都新建一个 branch 来写； branch 写完后，合并到 master，然后删掉这个 branch。 Git合并特定commits 到另一个分支 合并某个分支上的单个commit 123451. git log 查看想选择哪些commits进行合并eg:dd2e86 - 946992 -9143a9 - a6fd86 - 5a60572.需要将62ecb3 合并到master，而不合并feature上的其他commitsgit checkout mastergit cherry-pick 62ecb3 合并某个分支上的一系列commits 123456假设需要合并feature分支的commit dd2e86 ~a6fd86 到master分支。首先需要基于feature创建一个新的分支，并指明新分支的最后一个commit：git checkout -b newbranch a6fd86然后，rebase 这个新分支的 commit 到master，dd2e86^ 指明你想从哪个特定的commit开始。git rebase --onto master dd2e86^ rebase——在新位置重新提交git rebase 目标基础点 场景： 我在主分支commit a时新建了新分支，此时开始分叉，分叉后我又在主分支改了东西commit b，此时我后悔了，我不该在commit a时分叉的。 因为commit b的东西我新分支也需要，此时用衍合（rebase）。 就等于我丢弃原分叉，在commit b重新分叉（原分叉的改动内容当然也是带上的，没有丢） 注意：为了避免和远端仓库发生冲突，一般不要从 master 向其他 branch 执行 rebase 操作。 而如果是 master 以外的 branch 之间的 rebase（比如 branch1 和 branch2 之间），就不必这么多费一步，直接 rebase 就好。 其它特性 git commit --amend 对最新一条 commit 进行修正，生成一条新的commit替换了原commit。 注意：commit之后，push之前使用有效;只针对目前最新的 commit 有效 git reset --hard 目标commit 撤销最新的提交 撤销过往的提交 1. 用 git rebase -i 在编辑界面中删除想撤销的 commits 2. 用 git rebase --onto 在 rebase 命令中直接剔除想撤销的 commits git push origin branch1 -f 忽略冲突，强制 push git revert HEAD^ commit 撤销提交 reset 的三种参数： 1. --hard：重置位置的同时，清空工作目录的所有改动； 2. --soft：重置位置的同时，保留工作目录和暂存区的内容，并把重置 HEAD 的位置所导致的新的文件差异放进暂存区。 3. --mixed（默认）：重置位置的同时，保留工作目录的内容，并清空暂存区。 场景： 当你手头有一件临时工作要做，需要把工作目录暂时清理干净，那么你可以： git stash -u （扔） git stash pop （取） 恢复已删除的 branch 1. git reflog 查看一下 HEAD 的移动历史 2. git checkout c08de9a 3. git checkout -b branch1 注意：不再被引用直接或间接指向的 commits 会在一定时间后被 Git 回收 tag：不可移动的 branch，tag 被用来在关键版本处打标记用。 git config： Git 的设置 https://git-scm.com/docs/git-config cherry-pick：把选中的 commits 一个个合并进来 参考： https://git-scm.com/docs]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线上问题调查常用命令]]></title>
    <url>%2F2019%2F01%2F08%2Fjava-devops-review%2F</url>
    <content type="text"><![CDATA[前言Java性能排查基本操作，本文的排查环境是 Linux。 Java性能相关 gc(健康度) ， 堆栈(gc不掉的数据)， 线程(cpu竞争) 查看jvm进程 root用户登陆，jps（JVM Process Status Tools） 查看堆内对象是否正常 jmap -histo 61367 | more jstat（JVM Statistics Monitoring Tools） jstat主要用于监控虚拟机的各种运行状态信息，如类的装载、内存、垃圾回收、JIT编译器等 jstat [option vmid [interval [s|ms] [vount] ] ] 参数interval和count分别表示查询间隔和查询次数，如每1毫秒查询一次进程20445的垃圾回收情况，监控20次，命令如下所示： jstat –gc 20445 1 20 -------------------------------------------------------------- Option Function -class 监视类的装载、卸载数量以及类的装载总空间和耗费时间等 -gc 监视Java堆，包含eden、2个survivor区、old区和永久带区域的容量、已用空间、GC时间合计等信息 -gccapcity 监视内容与-gc相同，但输出主要关注Java区域用到的最大和最小空间 -gcutil 监视内容与-gc相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil输出信息相同，额外输出导致上次GC产生的原因 -gcnew 监控新生代的GC情况 -gcnewcapacity 与-gcnew监控信息相同，输出主要关注使用到的最大和最小空间 -gcold 监控老生代的GC情况 -gcoldcapacity 与-gcold监控信息相同，输出主要关注使用到的最大和最小空间 -gcpermcapacity 输出永久带用到的最大和最小空间 -compiler 输出JIT编译器编译过的方法、耗时信息 -printcompilation 输出已经被JIT编译的方法 example: jstat -gcutil jpsPid 1000 10 -------------------------------------------------------------- top H show all thread by process P 按cpu占用排序 M 按内存占用排序 1 显示cpu个数 -------------------------------------------------------------- 查找占用cpu高的java线程: top -H -p javaId // 找出java thread id printf '0x%x\n' java thread id // 转16进制 jstack jstack用于JVM当前时刻的线程快照，又称threaddump文件，它是JVM当前每一条线程正在执行的堆栈信息的集合。生成线程快照的主要目的是为了定位线程出现长时间停顿的原因，如线程死锁、死循环、请求外部时长过长导致线程停顿的原因。通过jstack我们就可以知道哪些进程在后台做些什么？在等待什么资源等！ jstack [option] vmid -------------------------------------------------------------- Option Function -F 当正常输出的请求不响应时强制输出线程堆栈 -l 除堆栈信息外，显示关于锁的附加信息 -m 显示native方法的堆栈信息 示例：jstack -l 20445 jstack Pid > jstack.log 打印堆栈 java堆的经验值: Space Option Occupancy Factor Java heap -Xmx 3x or 4x old generation space occupancy after full garbage collection Perm Generation -MaxPermSize 1.2 or 1.5x perm generation space occupancy after full garbage collection Young Generation -Xmn 1x or 1.5x young generation space occupancy after full garbage collection Old Generation 2x or 3x old generation space occupancy after full garbage collection 优化思路 调整分区的比例； 尽可能的让gc发生在年轻代中； 年轻代的大小，起始值，最大值，设置一样； 设置他进阶的生命周期和进阶允许大小设置。]]></content>
      <tags>
        <tag>Devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用运维工具汇总]]></title>
    <url>%2F2019%2F01%2F08%2Fdevops-review%2F</url>
    <content type="text"><![CDATA[大纲中间件 运维工具 性能测试中使用的其他命令 进程/内存的运维，监控工具 中间件redis常用命令：info，monitor，slowlog, redis-benchmark, scanmore：https://www.redis.cn/commands/info.html elasticsearch_plugin/head：概览，索引，基本查询，符合查询 _plugin/kopf：内存大小，磁盘占用，索引管理。 进程/内存jvisualvm：实时查看堆栈信息，需要添加jmx启动参数 性能测试中使用的其他命令查看网络流量：cat /proc/net/dev 查看系统平均负载：cat /proc/loadavg 查看系统内存情况：cat /proc/meminfo 查看CPU的利用率：cat /proc/stat 端口相连接的机器数： ss -nao | grep 18090 | wc -l netstat -anpt | grep 18090 | wc -l 查看java线程： ps -eLf | grep java | wc -l 运维工具cat：代码层面的监控。 netdata：Linux系统性能实时监控平台]]></content>
      <tags>
        <tag>Devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij idea 常用快捷键]]></title>
    <url>%2F2019%2F01%2F08%2Fintellij-IDEA-shortcut%2F</url>
    <content type="text"><![CDATA[介绍去年开始改用 IDEA，在使用 IDEA 时不想重头记一套新的快捷键，快捷键设置以 eclipse 为主。整理一些自己常用的快捷键，同时下面为 windows 环境下配置 CTRL系列CTRL + H 快速打开搜索框 CTRL + O 打开大纲视图 CTRL + W 关闭当前窗口 CTRL + T 查看接口实现类 CTRL + E 最近打开过的文件 CTRL + SHIFT + [ 切换不同项目 CTRL + SHIFT + ALT + T 调出重构菜单 CTRL + SHIFT + M 自动声明变量类型 CTRL + SHIFT + R 快速打开资源 CTRL + SHIFT + T 快速打开类 CTRL + B 强制刷新 CTRL + SHIFT + A 快捷键查询 CTRL + Page Up 上一窗口 CTRL + Page Down 下一窗口 CTRL + SHIFT + F12 切换全屏幕 CTRL + SHIFT + X 大小写转换 ALT系列ALT + F1 神器，按了此组合，接下来你可以跳转到项目结构，导航栏，甚至可以在Finder中定位该文件 ALT + / 智能提醒神器，当你不知道要写什么内容的时候，试试这个组合吧，或许他会给你带来灵感 ALT + +/- 鼠标定位到之前编辑的位置/之后编辑的位置 ALT + Enter 改进或优化代码构造 ALT + SHIFT + R 重命名 ALT + SHIFT + O 高亮变量 ALT + SHIFT + M 抽取方法 ALT + F12 打开/关闭终端（较常用） 结构类CTRL + ALT + SHIFT + U 根据上下文展示UML图 ALT + 类 出现放大镜 F4 + 类 查看该类源码 for循环系列it** 生成for循环代码块 测试用例系列CTRL + SHIFT + S 创建当前类或接口的测试类]]></content>
      <tags>
        <tag>Devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring常用扩展接口总结]]></title>
    <url>%2F2018%2F12%2F05%2Fspring-extend-review%2F</url>
    <content type="text"><![CDATA[前言Spring源码学习笔记，Spring常用扩展接口总结，错误之处欢迎指正，共同学习 介绍Spring 提供了大量的可扩展接口。因此了解这些接口对于我们定制自己的功能，熟练使用 Spring 非常重要。 常用扩展1.FactroyBean 2.BeanPostProcess 3.InstantiationAwareBeanPostProcessor 4.BeanNameAware、ApplicationContextAware 和 BeanFactoryAware 5.BeanFactoryPostProcessor 6.InitialingBean、DisposableBean -------------------------------------------------------------------- 1.FactroyBean 个性化地定制自己想要实例化出来的Bean，比如AOP的实现 a.getObject() 方法是最重要的，控制Bean的实例化过程 b.getObjectType()方法获取接口返回的实例的class c.isSingleton()方法获取该Bean是否为一个单例的Bean 2.BeanPostProcess 在每个Bean初始化前后做操作。 3.InstantiationAwareBeanPostProcessor 在Bean实例化前后做一些操作。 a.实例化在初始化之前执行 b.通常不会直接实现 InstantiationAwareBeanPostProcessor 接口，而是会采用继承 InstantiationAwareBeanPostProcessorAdapter 这个抽象类的方式来使用。 4.BeanNameAware、ApplicationContextAware 和 BeanFactoryAware 针对bean工厂，可以获取上下文，可以获取当前bena的id。 a.从上下文获取bean时使用，可以让实现类或子接口的实现类注入ApplicationContext，获取上下文的信息。很多项目中都使用此接口做了Spring的工具类。 5.BeanFactoryPostProcessor Spring允许在Bean创建之前，读取Bean的元属性，并根据自己的需求对元属性进行改变，比如将Bean的scope从singleton改变为prototype。 a.BeanFactoryPostProcessor的执行优先级高于BeanPostProcessor b.BeanFactoryPostProcessor的 postProcessBeanFactory() 方法只会执行一次，携带了每个bean的基本信息 6.InitialingBean 在属性设置完毕后做一些自定义操作 DisposableBean 在关闭容器前做一些操作。 a.InitialingBean 实现 afterPropertiesSet()方法 b.DisposableBean 实现 destory() 方法 总结通过了解 Spring 的扩展接口，我们可以基于 Spring 做一些除了简单注入之外的定制功能。同时，我们也发现 Spring 的扩展性非常高，符合设计模式中的开闭原则，对修改关闭，对扩展开放。我们在以后的开发工作中也可以借鉴 Spring 的设计思想，让程序更加优雅。]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习笔记之AOP]]></title>
    <url>%2F2018%2F12%2F04%2Fspring-deep-aop%2F</url>
    <content type="text"><![CDATA[前言Spring源码学习笔记，Spring-AOP实现大致过程，错误之处欢迎指正，共同学习 介绍类应该是纯净的，不应含有与本身无关的逻辑。单一职责原则。 Spring AOP 接口设计AOP概念总结 1.Advice 2.Pointcut 3.Advisor 4.Joinpoint 5.Aspect -------------------------------------------------------------------- 1.Advice（增强，定义在链接点做什么） a.Before Advice（执行前增强，实现MethodBeforeAdvice接口） b.Around Advice（环绕增强，可以实现以上三种功能，实现MethodInterceptor接口） c.After Running Advice（方法执行后增强，实现AfterRunningAdvice接口） d.After Throw Advice（抛出异常后增强，实现ThrowsAdvice接口） e.Introduction（引入，特殊的advice，普通advice都是作用在pointcut指定的方法上，而introduction作用在类上，可以添加类中没有的方法和属性） 2.Pointcut（连接点，定义匹配哪些方法） 3.Advisor（通知器，将 Advice 和 PointCut 结合起来，目的是为了将advice与pointcut解耦和） a.PointcutAdvisor（一个advice和一个pointcut，作用在某个连接点上） b.IntroductionAdvisor（作用于类上） 4.Joinpoint（连接点，所有可能的需要注入切面的地方。如方法前后、类初始化、属性初始化前后等等。pointcut只能选择连接点切入） a.通过joinPoint 参数，可以获取目标对象的信息,如类名称,方法参数,方法名称等 5.Aspect（切面，切面是切点和增强的集合，一般单独作为一个类。通知和切点共同定义了关于切面的全部内容，它是什么时候，在何时和何处完成功能。） Spring AOP 的底层实现有两种可选，一种是 JDK 动态代理，一种是 CGLib 动态代理。先说下结论，如果要代理的 target 有接口，则默认采用 JDK 动态代理。如果没有，则采用 CGLib 动态代理。当然也可以强制指定使用 CGLib 动态代理。方法: XML配置AOP: &lt;aop:config proxy-target-class=”true”&gt; 注解配置AOP: &lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt; CGLib 创建代理的速度比较慢，但创建代理后运行的速度却非常快，而 JDK 动态代理正好相反。如果在运行的时候不断地用 CGLib 去创建代理，系统的性能会大打折扣，所以建议一般在系统初始化的时候用 CGLib 去创建代理，并放入 Spring 的 ApplicationContext 中以备后用。 源码开始Spring 使用 AOP 可以通过XML配置和注解两种方式，但是底层原理都是一样的。Spring 是否支持注解的 AOP 是由一个配置文件控制的，也就是&lt;aop:aspectj-autoproxy /&gt;，当在配置文件中声明了这句配置的时候，Spring就会支持注解的 AOP，那么我们分析就从这句注解开始 123456789101112131415161718192021222324252627282930313233343536// AopNamespaceHandler.javapublic void init() &#123; // In 2.0 XSD as well as in 2.1 XSD. registerBeanDefinitionParser("config", new ConfigBeanDefinitionParser()); registerBeanDefinitionParser("aspectj-autoproxy", new AspectJAutoProxyBeanDefinitionParser()); registerBeanDefinitionDecorator("scoped-proxy", new ScopedProxyBeanDefinitionDecorator()); // Only in 2.0 XSD: moved to context namespace as of 2.1 registerBeanDefinitionParser("spring-configured", new SpringConfiguredBeanDefinitionParser());&#125;// 注册AnnotationAutoProxyCreatorpublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; // 注册AspectJAnnotationAutoProxyCreator AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element); // 对于注解中子类的处理 extendBeanDefinition(element, parserContext); return null;&#125;public static void registerAspectJAnnotationAutoProxyCreatorIfNecessary( ParserContext parserContext, Element sourceElement) &#123; BeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary( parserContext.getRegistry(), parserContext.extractSource(sourceElement)); // 对于 proxy-target-class 属性的处理 useClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement); // 注册组件并通知，便于监听器做进一步处理 registerComponentIfNecessary(beanDefinition, parserContext);&#125;public static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary( BeanDefinitionRegistry registry, @Nullable Object source) &#123; return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);&#125; AnnotationAwareAspectJAutoProxyCreator 在类的层级中，我们看到 AnnotationAwareAspectJAutoProxyCreator 实现了 BeanPostProcessor 接口，而实现 BeanPostProcessor 后，当 Spring 加载这个 Bean 时会在实例化前调用其 postProcessAfterInitialization 方法，而我们对于 AOP 逻辑的分析也由此开始。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 父类 AbstractAutoProxyCreatorpublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; // 根据给定的 bean 的class和name构建出个key Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) &#123; // 如果它适合被代理，则需要封装指定bean return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125;protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 如果已经处理过 if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 无需增强 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 给定的bean类是否代表一个基础设施类，基础设施类不应代理，或者配置了指定bean不需要自动代理 if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. // 如果存在增强方法则创建代理 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); // 如果获取到了增强则需要针对增强创建代理 if (specificInterceptors != DO_NOT_PROXY) &#123; this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 函数中我们已经看到了代理创建的雏形。当然，真正开始之前还需要经过一些判断，比如是否已经处理过或者是否是需要跳过的bean,而真正创建代理的代码是从 getAdvicesAndAdvisorsForBean 开始的。创建代理主要包含了两个步骤： 获取增强方法或者增强器 根据获取的增强进行代理 获取增强方法的实现1234567891011121314151617181920212223protected Object[] getAdvicesAndAdvisorsForBean( Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray();&#125;protected static final Object[] DO_NOT_PROXY = null;protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 获取所有的增强 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 寻找所有的增强中适用于bean的增强并应用 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 获取增强器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; // Add all the Spring advisors found according to superclass rules. // 当使用注解方式配置 AOP 的时候并不是丢弃了对XML配置的支持 // 在这里调用父类方法加载配置文件中的 AOP 声明 List&lt;Advisor&gt; advisors = super.findCandidateAdvisors(); // Build Advisors for all AspectJ aspects in the bean factory. if (this.aspectJAdvisorsBuilder != null) &#123; advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); &#125; return advisors;&#125;public List&lt;Advisor&gt; buildAspectJAdvisors() &#123; List&lt;String&gt; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; synchronized (this) &#123; aspectNames = this.aspectBeanNames; if (aspectNames == null) &#123; List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); aspectNames = new ArrayList&lt;&gt;(); // 获取所有的 beanName String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors( this.beanFactory, Object.class, true, false); // 循环所有的 beanName 找出对应的增强方法 for (String beanName : beanNames) &#123; // 略过不合法的bean if (!isEligibleBean(beanName)) &#123; continue; &#125; // We must be careful not to instantiate beans eagerly as in this case they // would be cached by the Spring container but would not have been weaved. // 获取对应的bean的实例 Class&lt;?&gt; beanType = this.beanFactory.getType(beanName); if (beanType == null) &#123; continue; &#125; // 如果存在 Aspect 注解 if (this.advisorFactory.isAspect(beanType)) &#123; aspectNames.add(beanName); AspectMetadata amd = new AspectMetadata(beanType, beanName); if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) &#123; MetadataAwareAspectInstanceFactory factory = new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName); // 解析标记AspectJ注解中的增强方法 List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory); if (this.beanFactory.isSingleton(beanName)) &#123; this.advisorsCache.put(beanName, classAdvisors); &#125; else &#123; this.aspectFactoryCache.put(beanName, factory); &#125; advisors.addAll(classAdvisors); &#125; else &#123; // ...... &#125; &#125; &#125; this.aspectBeanNames = aspectNames; return advisors; &#125; &#125; &#125; if (aspectNames.isEmpty()) &#123; return Collections.emptyList(); &#125; // 记录在缓存中 List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;(); for (String aspectName : aspectNames) &#123; List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName); if (cachedAdvisors != null) &#123; advisors.addAll(cachedAdvisors); &#125; else &#123; MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName); advisors.addAll(this.advisorFactory.getAdvisors(factory)); &#125; &#125; return advisors;&#125; 获取所有 beanName，这一步骤中所有在 beanFactory 中注册的Bean都会被提取出来 遍历所有 beanName，并找出声明 AspectJ 注解的类，进行进一步的处理 对标记为 AspectJ 注解的类进行增强器的提取 将提取结果加入缓存 寻找匹配的增强器 1234567891011121314151617181920212223242526272829303132333435363738protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; // 过滤已经得到的Advisors return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125;&#125;public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) &#123; if (candidateAdvisors.isEmpty()) &#123; return candidateAdvisors; &#125; List&lt;Advisor&gt; eligibleAdvisors = new ArrayList&lt;&gt;(); // 首次处理引介增强 for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; boolean hasIntroductions = !eligibleAdvisors.isEmpty(); for (Advisor candidate : candidateAdvisors) &#123; // 引介增强已经处理 if (candidate instanceof IntroductionAdvisor) &#123; // already processed continue; &#125; // 对于普通bean的处理 if (canApply(candidate, clazz, hasIntroductions)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; return eligibleAdvisors;&#125; findAdvisorsThatCanApply 函数的主要功能是寻找所有增强器中适用于当前 class 的增强器。引介增强与普通的增强处理是不一样的，所以分开处理。而对于真正的匹配在 canApply 中实现 123456789101112131415161718192021222324252627282930313233343536public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, "Pointcut must not be null"); if (!pc.getClassFilter().matches(targetClass)) &#123; return false; &#125; MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; // No need to iterate the methods if we're matching any method anyway... return true; &#125; IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;&gt;(); if (!Proxy.isProxyClass(targetClass)) &#123; classes.add(ClassUtils.getUserClass(targetClass)); &#125; classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); for (Method method : methods) &#123; if (introductionAwareMethodMatcher != null ? introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) : methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; return false;&#125; 创建代理在获取了所有对应bean的增强器后，便可以进行代理的创建了 12345678910111213141516171819202122232425262728293031323334353637383940protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; ProxyFactory proxyFactory = new ProxyFactory(); // 获取当前类中相关属性 proxyFactory.copyFrom(this); // 决定对于给定的bean是否应该使用TargetClass而不是它的接口代理 if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; // 添加代理接口 evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); // 加入增强器 proxyFactory.addAdvisors(advisors); // 设置要代理的类 proxyFactory.setTargetSource(targetSource); // 定制代理 customizeProxyFactory(proxyFactory); // 用来控制代理工厂被配置之后，是否还允许修改通知 // 缺省值为false(代理被配置之后，不允许修改) // private boolean freezeProxy = false; proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; return proxyFactory.getProxy(getProxyClassLoader());&#125; 对于代理类的创建及处理，Spring委托给了ProxyFactory去处理，此函数中主要是对ProxyFactory的初始化操作，进而对真正的创建代理做准备。 获取当前类中的属性 添加代理接口 封装Advisor并加入到ProxyFactory中 设置要代理的类 为子类提供了定制的函数 customizeProxyFactory，子类可以在此函数中进行对 ProxyFactory的进一步封装 进行获取代理操作 将拦截器封装为增强器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected Advisor[] buildAdvisors(@Nullable String beanName, @Nullable Object[] specificInterceptors) &#123; // 解析注册的所有InterceptorName Advisor[] commonInterceptors = resolveInterceptorNames(); List&lt;Object&gt; allInterceptors = new ArrayList&lt;&gt;(); if (specificInterceptors != null) &#123; // 加入拦截器 allInterceptors.addAll(Arrays.asList(specificInterceptors)); if (commonInterceptors.length &gt; 0) &#123; if (this.applyCommonInterceptorsFirst) &#123; allInterceptors.addAll(0, Arrays.asList(commonInterceptors)); &#125; else &#123; allInterceptors.addAll(Arrays.asList(commonInterceptors)); &#125; &#125; &#125; // ...... Advisor[] advisors = new Advisor[allInterceptors.size()]; for (int i = 0; i &lt; allInterceptors.size(); i++) &#123; // 拦截器进行封装转化为Advisor advisors[i] = this.advisorAdapterRegistry.wrap(allInterceptors.get(i)); &#125; return advisors;&#125;public Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException &#123; // 如果要封装的对象本身就是Advisor直接返回 if (adviceObject instanceof Advisor) &#123; return (Advisor) adviceObject; &#125; // 封装方法只对 Advisor 和 Advice 两种类型的数据有效 if (!(adviceObject instanceof Advice)) &#123; throw new UnknownAdviceTypeException(adviceObject); &#125; Advice advice = (Advice) adviceObject; if (advice instanceof MethodInterceptor) &#123; // So well-known it doesn't even need an adapter. return new DefaultPointcutAdvisor(advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; // Check that it is supported. if (adapter.supportsAdvice(advice)) &#123; return new DefaultPointcutAdvisor(advice); &#125; &#125; throw new UnknownAdviceTypeException(advice);&#125; 由于Spring中涉及过多的拦截器、增强器、增强方法等方式来对逻辑进行增强，所以非常有必要统一封装成Advisor来进行代理的创建 代理的创建与获取123public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; 创建代理1234567891011121314151617181920212223242526272829protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; // 创建代理 return getAopProxyFactory().createAopProxy(this);&#125;public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; // 首先考虑使用cglib来实现代理对象，当然如果同时目标对象不是接口的实现类的话 if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: " + "Either an interface or a target is required for proxy creation."); &#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; return new ObjenesisCglibAopProxy(config); &#125; else &#123; // 这里使用JDK来生成Proxy,返回JDK类型的AopProxy return new JdkDynamicAopProxy(config); &#125;&#125;optimize控制cglib代理是否使用优化ProxyTargetClass：true时，目标类本身被代理，而不是目标类的接口。即使用cglib代理hasNoUserSuppliedProxyInterfaces： 是否存在代理接口 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP如果目标对象实现了接口，可以强制使用CGLIB实现AOP如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换 区别：JDK动态代理只能对实现了接口的类生成代理，而不能针对类CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，因为是继承，所以该类或方法最好不要声明成final 获取代理两种代理方式的使用方法 JDK代理使用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071// 业务接口public interface Subject &#123; void request(); void hello();&#125;// 业务接口实现类public class RealSubject implements Subject&#123; @Override public void request() &#123; System.out.println("real subject execute request"); &#125; @Override public void hello() &#123; System.out.println("hello"); &#125;&#125;// 创建自定义的 InvocationHandler，用于对接口提供的方法进行增强public class JdkDynamicProxy implements InvocationHandler&#123; //目标对象 private Object target; public JdkDynamicProxy(Object target) &#123; super(); this.target = target; &#125; //执行目标对象的方法 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("before"); Object result = null; try&#123; result = method.invoke(target,args); &#125;catch (Exception e)&#123; System.err.println("ex:"+e.getMessage()); throw e; &#125;finally &#123; System.out.println("after"); &#125; return result; &#125; // 获取目标对象的代理对象 public Object getProxy() &#123; // System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); return Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), target.getClass().getInterfaces(),this); &#125;&#125;@Testpublic void test() &#123; // 实例化目标对象 Subject subject = new RealSubject(); // 实例化 InvocationHandler JdkProxySubject jdkProxySubject = new JdkProxySubject(subject); // 根据目标对象生成代理对象 Subject proxy = (Subject) jdkProxySubject.getProxy(); proxy.request();&#125; 执行结果如下 before real subject execute request after 那么，我们看看Spring中的JDK代理实现。继续之前的跟踪，到达JdkDynamicAopProxy.getProxy()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Creating JDK dynamic proxy: " + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125;public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try &#123; if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; // The target does not implement the equals(Object) method itself. return equals(args[0]); &#125; else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; // The target does not implement the hashCode() method itself. return hashCode(); &#125; else if (method.getDeclaringClass() == DecoratingProxy.class) &#123; // There is only getDecoratedClass() declared -&gt; dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); &#125; else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; // Service invocations on ProxyConfig with the proxy config... // 通过反射机制来对目标对象的方法进行调用 return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); &#125; Object retVal; // 有时候目标对象内部的自我调用将无法实施切面中的增强，则需要通过此属性暴露代理 if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // Get as late as possible to minimize the time we "own" the target, // in case it comes from a pool. // 这里是得到目标对象的地方，当然这个目标对象可能来自于一个实例池，或一个简单的Java对象 target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // Get the interception chain for this method. // 获取当前方法的拦截器链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // Check whether we have any advice. If we don't, we can fallback on direct // reflective invocation of the target, and avoid creating a MethodInvocation. // 如果没有设定拦截器，那么我们就直接调用目标的对应方法 if (chain.isEmpty()) &#123; // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... // 如果有拦截器的设定，那么需要调用拦截器之后才调用目标对象的相应方法 // 这里通过构造一个 ReflectiveMethodInvocation 来实现，封装拦截器 // 以便于使用其 proceed 进行链接表用拦截器 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. // 执行拦截器链 retVal = invocation.proceed(); &#125; // Massage return value if necessary. // ......&#125; invoke 函数最主要的工作就是创建了一个拦截器链，并使用 ReflectiveMethodInvocation 类进行了类的封装，而在 ReflectiveMethodInvocation 类的 proceed 方法中实现了拦截器的逐一调用 1234567891011121314151617181920212223242526272829303132333435// 对拦截器的调用处理public Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. // 执行完所有增强后执行切点方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 获取下一个要拦截的拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. // 这里获得相应的拦截器,如果拦截器可以匹配上的话,那就调用拦截器的invoke方法 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. // 如果拦截器匹配不上,那就调用下一个拦截器 return proceed(); &#125; &#125; else &#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. // 将 this 作为参数传递以保证当前实例中调用链的执行 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; CGLIB使用示例 1234567891011121314151617181920212223242526public class MethodInterceptorDemo implements MethodInterceptor&#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println("before in cglib"); Object result = null; try&#123; result = proxy.invokeSuper(obj, args); &#125;catch (Exception e)&#123; System.err.println("get ex:"+e.getMessage()); throw e; &#125;finally &#123; System.out.println("after in cglib"); &#125; return result; &#125;&#125;@Testpublic void test() &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(RealSubject.class); enhancer.setCallback(new MethodInterceptorDemo()); Subject subject = (Subject) enhancer.create(); subject.hello();&#125; 执行结果如下 before in cglib hello after in cglib CglibAopProxy 有众多内部类。这些内部类是为了实现 Cglib 的各种回调而实现的。主要实现了 MethodInterceptor 接口，Callback 接口，Joinpoint 接口，Invocation 接口等待，总之是实现了Spring 的 cglib 模块的各种接口。 实现与 JDK 方式实现代理中的 invoke 方法大同小异，都是首先构造链，然后封装此链进行串联调用。区别是JDK中直接构造 ReflectiveMethodInvocation，而在cglib中使用 CglibMethodInvocation。CglibMethodInvocation 继承自 ReflectiveMethodInvocation，但是proceed方法没有重写 总结通过源码分析我们知道注解方式的底层是通过继承 ProxyProcessorSupport 来实现的，并且扩展的是 BenaPostProcessor 接口，通过Spring 的扩展接口，能够对特定的Bean进行增强。而 AOP 正是通过这种方式实现的。我们也可以通过扩展 Spring 的某些接口来增强我们需要的 Bean 的某些功能。]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码学习笔记之IOC]]></title>
    <url>%2F2018%2F11%2F28%2Fspring-deep-ioc%2F</url>
    <content type="text"><![CDATA[前言Spring源码学习笔记，Spring-Ioc源码浅析，错误之处欢迎指正，共同学习 介绍Ioc 容器的核心是控制对象的创建，销毁，管理对象之间的依赖关系，并由IOC容器完成对象的注入。我们只需要关注业务逻辑。 IOC 原理Ioc 底层通过 java 反射创建实例，利用set方法对实例的依赖进行注入。 搭建源码研究环境 直接从 spirng 的 github 上 clone spring-framework 源码，部署项目 debug 启动该项目，运行main方法 123456789public static void main(String[] args) &#123; ApplicationContext ctx = new FileSystemXmlApplicationContext( "spring-context/src/test/resources/org/springframework/context/lishqTest/beans.xml"); System.out.println("begin..."); System.out.println("number : " + ctx.getBeanDefinitionCount()); System.out.println(((TestBean) ctx.getBean("beans1.bean1")).getName()); System.out.println(((TestBean) ctx.getBean("beans1.bean2")).getObjRef());&#125; 输出 new Instance......when new Instance......when begin... number : 2 lishq-toSpring test.lishqTest.TestBean@329302 Spring的IOC实现 资源(Resource)定位. BeanDefinition 的载入和 BeanFactory 的构造. 向 IOC 容器(BeanFactory)注册 BeanDefinition. 根据 lazy-init 属性初始化 Bean 实例和依赖注入. IOC中几个重要概念及其关系 1.BeanFactory 2.ApplicationContext 3.BeanDefinition -------------------------------------------------------------------- 1.BeanFactory是IOC容器的接口定义，定义了容器的基本功能 a.获取Bean b.注册Bean c.more 2.ApplicationContext 则是扩展后的容器，它通过继承 MessageSource，ResourceLoader，ApplicationEventPublisher 接口，在BeanFactory 简单IOC容器的基础上添加了许多对高级容器的支持。 a.MessageSource 接口，提供了消息处理的功能。在web项目上用于国际化 b.ResourceLoader 是资源加载接口，用于对不同的Resource进行加载。Resource getResource(String location)通过一个标识加载资源信息。 c.ApplicationEventPublisher 提供了发布 event 组件的接口。spring 的事件体系 和Spring内置事件处理 3.BeanDefinition 可简单理解为容器实现依赖反转功能的核心数据结构 a.Spring 通过定义 BeanDefinition 来管理基于Spring 的应用中的各种对象以及他们直接的相互依赖关系 b.BeanDefinition 抽象了我们对 Bean的定义，是让容器起作用的主要数据类型 Spring Bean 解析过程 Spring Bean 解析过程如上图所示，下面我们据此逻辑debug源码 FileSystemXmlApplicationContext 12345678910111213141516// FileSystemXmlApplicationContext 的构造方法，默认刷新为truepublic FileSystemXmlApplicationContext(String configLocation) throws BeansException &#123; this(new String[] &#123;configLocation&#125;, true, null);&#125;// 该构造器做了2件事情，一是设置配置文件，二是刷新容器。public FileSystemXmlApplicationContext( String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh();// 初始化容器核心方法 &#125;&#125; AbstractApplicationContext.refresh() 构建BeanFactory，以便于产生所需的 Bean 注册可能感兴趣的事件 创建Bean实例对象 触发被监听的事件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 整个IOC容器初始化的所有逻辑public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 为刷新准备应用上下文 prepareRefresh(); // 告诉子类刷新内部bean工厂，即在子类中启动refreshBeanFactory()的地方----创建bean工厂，根据配置文件生成bean定义 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 准备在此上下文中使用的bean工厂。 prepareBeanFactory(beanFactory); try &#123; // 允许在上下文子类中对bean工厂进行后处理。 postProcessBeanFactory(beanFactory); // 调用在上下文中注册为bean的工厂处理器。 invokeBeanFactoryPostProcessors(beanFactory); // 注册拦截bean创建的bean处理器。 registerBeanPostProcessors(beanFactory); // 初始化此上下文的消息源。 initMessageSource(); // 初始化上下文中的事件机制 initApplicationEventMulticaster(); // 初始化特定上下文子类中的其他特殊bean。 onRefresh(); // 检查监听Bean并且将这些Bean向容器注册 registerListeners(); // 实例化所有的非延迟加载的单例类 finishBeanFactoryInitialization(beanFactory); // 发布容器事件，结束refresh过程 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // 为防止bean资源占用，在异常处理中，销毁已经在前面过程中生成的单件bean destroyBeans(); // 重置“active”标志 cancelRefresh(ex); // 将异常传播给调用方。 throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; Spring 通过 refresh 操作重建了 ApplicaitonContext，在这个过程中同时也构建了默认的 BeanFactory 以及加载了 BeanDefinition。AbstractApplicationContext类在refresh()方法中调用了obtainFreshBeanFactory， 此方法主要负责重建BeanFactory以及加载BeanDefinition。 下面我们对此方法进行简要分析： obtainFreshBeanFactory 12345678910111213141516171819202122protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; // 如果存在就销毁 destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); // 设置序列化 beanFactory.setSerializationId(getId()); // 定制的BeanFactory customizeBeanFactory(beanFactory); // 使用BeanFactory加载bean定义 AbstractXmlApplicationContext loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex); &#125;&#125; 可以看到BeanFactory的创建过程，首先判断是否已存在BeanFactory，如果已存在则销毁：destroyBeans() 清除Bean引用的缓存closeBeanFactory() 释放已创建的BeanFactory 其次调用 createBeanFactory 建立默认的 BeanFactoryDefaultListableBeanFactory，也就是 BeanFactory的默认实现； 当BeanFactory建立好之后，进行一项简单的配置 customizeBeanFactory()，以决定在加载 BeanDefinition 的过程中是否允许循环引用以及是否允许对已有BeanDefinition进行覆写。 然后我们看到一个很感兴趣的方法，就是 loadBeanDefinitions(beanFactory)，看名字是加载 Definitions，Definition 是核心之一，代表着 IOC 中的基本数据结构。该方法也是个抽象方法，默认实现是 AbstractXmlApplicationContext ，我们看看该方法实现： loadBeanDefinitions XmlBeanDefinitionReader loadBeanDefinitions(); doLoadBeanDefinitions(); registerBeanDefinitions(); 12345678910111213141516171819/** * 首先创建一个 XmlBeanDefinitionReader ，用于读取XML中配置，设置了环境，资源加载器， * 最后初始化，加载。可以说，该方法将加载，解析Bean的定义，也就是把用户定义的数据结构 * 转化为 IOC容器中的特定数据结构。 */protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // 为给定的BeanFactory创建一个新的XmlBeanDefinitionReader XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 允许子类提供自定义的读取器初始化，然后继续实际加载bean定义 initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);&#125; 我们主要关注该方法的 loadBeanDefinitions(beanDefinitionReader) 就是BeanDefinition的主要加载过程。它使用指定的 XmlBeanDefinitionReader 进行加载BeanDefinition。这个方法仅负责加载或者注册BeanDefinition，而生命周期是通过bean工厂的refreshBeanFactory方法管理 loadBeanDefinitions 123456789101112protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; // 获取是否有配置好的Resource，如果有直接交由reader进行加载 Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; // 加载给定的路径文件 reader.loadBeanDefinitions(configLocations); &#125;&#125; 可以看出，对于BeanDefinition的加载最终是使用 XmlBeanDefinitionReader 的实例进行加载的，此处只是对其指定了加载的资源或者资源的位置。 123456789public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, "Location array must not be null"); int count = 0; // 循环加载配置文件 for (String location : locations) &#123; count += loadBeanDefinitions(location); &#125; return count;&#125; 此方法位于AbstractBeanDefinitionReader类中，主要针对字符串路径进行解析，最终得到Resource对象，然后将Resource交由XmlBeanDefinitionReader进行处理。所以针对 xml 的资源加载的最终位置还是位于XmlBeanDefinitionReader中 123456789101112131415161718192021222324252627282930313233// 从指定的资源位置加载bean定义，返回找到的bean定义的数量public int loadBeanDefinitions(String location, @Nullable Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; // 获取资源加载器 ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( "Cannot load bean definitions from location [" + location + "]: no ResourceLoader available"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; // 循环加载resource 资源数组 Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); // 根据配置文件加载Bean定义 int count = loadBeanDefinitions(resources); if (actualResources != null) &#123; Collections.addAll(actualResources, resources); &#125; // ...... return count; &#125; &#125; else &#123; // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int count = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; return count; &#125;&#125; 12345678910111213// 根据输入流加载 Document 文档对象，然后根据得到的文档对象注册到容器protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); // 真正的注册bean int count = registerBeanDefinitions(doc, resource); // ...... return count; &#125; // ......&#125; 可以看到通过 doLoadDocument 方法将其解析为Document对象，然后通过 registerBeanDefinitions 方法对 Document 对象进行提取与 BeanDefinition 的注册. 这里的Document是符合 w3c 定义的标准xml文档; 我们知道xml解析一般有DOM方式(document)、SAX方式(Simple API for XML)以及StAX(Streaming API for xml)方式；而此处的Resource不会包含太大量的信息，所以采用了DOM方式，即一次将整个XML都加载到内存中进行解析. registerBeanDefinitions DefaultBeanDefinitionDocumentReader registerBeanDefinitions(); doRegisterBeanDefinitions(); parseBeanDefinitions(); 123456789101112131415161718192021// 解析文档中根层次的元素:“import”、“alias”、“bean”protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 解析root的过程，判断root为spring默认标签还是用户自定义标签，分别交由不同委托类解析 123456789101112131415161718private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; // 通过resource属性取得配置文件的位置，然后将其转换为Resource，交由XmlBeanDefinitionReader来解析 importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; // 进行是否可重写校验和循环引用校验后，将alias标签的name和alias属性添加到上下文的aliasMap中； processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; // 处理和注册bean processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // beans标签，进行迭代调用doRegisterBeanDefinitions方法 doRegisterBeanDefinitions(ele); &#125;&#125; 1234567891011121314151617181920212223/** * Process the given bean element, parsing the bean definition * and registering it with the registry. * 处理给定的 bean 元素，解析 bean 定义，并在注册中心注册。 */protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 创建一个 BeanDefinitionHolder BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. // 开始注册 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, ex); &#125; // 执行容器通知事件 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 首先创建一个 BeanDefinitionHolder，该方法会调用 BeanDefinitionReaderUtils.registerBeanDefinition 方法， 最后执行容器通知事件。 1234567891011121314151617181920212223/** * 向给定的bean工厂注册给定的bean定义 * @param definitionHolder bean定义，包括名称和别名 * @param registry 要注册的bean工厂 * @throws BeanDefinitionStoreException 如果注册失败，抛出BeanDefinitionStoreException */public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); // 将bean的名字和 BeanDefinition 注册 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125; 首先从bean的持有者那里获取了beanName，然后调用 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition())， 将bena的名字和 BeanDefinition 注册： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, "Bean name must not be empty"); Assert.notNull(beanDefinition, "BeanDefinition must not be null"); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Validation of bean definition failed", ex); &#125; &#125; BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName); if (existingDefinition != null) &#123; if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition); &#125; // ...... this.beanDefinitionMap.put(beanName, beanDefinition); &#125; else &#123; if (hasBeanCreationStarted()) &#123; // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) &#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; // 仍处于启动注册阶段,最终放进这个map 实现注册 // private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; if (existingDefinition != null || containsSingleton(beanName)) &#123; resetBeanDefinition(beanName); &#125;&#125; 注册bean的最后一步，将beanName和 beanDefinition 放进一个 ConcurrentHashMap（256） 中。 那么这个 beanDefinition 是时候创建的呢？ 就是在 DefaultBeanDefinitionDocumentReader.processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) 方法中，在这里创建了 BeanDefinitionHolder， 而该实例中解析Bean并将Bean 保存在该对象中。所以称为持有者。该实例会调用 parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) 方法，该方法用于解析XML文件并创建一个 BeanDefinitionHolder 返回，该方法会调用 parseBeanDefinitionElement(ele, beanName, containingBean) 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, @Nullable BeanDefinition containingBean) &#123; // 入栈，用于跟踪解析过程 this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; // public static final String CLASS_ATTRIBUTE = "class"; // 从XML元素中取出 class 元素 className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; try &#123; // 根据class属性和parent属性创建BeanDefinition, // 首先通过类加载器寻找class类并将其设置于beanClass属性 // 如果类加载器暂时无法发现此类，则将class设置于beanClassName属性上 AbstractBeanDefinition bd = createBeanDefinition(className, parent); parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); parseMetaElements(ele, bd); parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); parseConstructorArgElements(ele, bd); parsePropertyElements(ele, bd); parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; // ...... finally &#123; this.parseState.pop(); &#125; return null;&#125; 我们看看该方法，可以看到，该方法从XML元素中取出 class 元素，然后拿着 className 调用 createBeanDefinition(className, parent) 方法，该方法核心是调用 BeanDefinitionReaderUtils.createBeanDefinition 方法： 123456789101112131415161718192021222324protected AbstractBeanDefinition createBeanDefinition(@Nullable String className, @Nullable String parentName) throws ClassNotFoundException &#123; return BeanDefinitionReaderUtils.createBeanDefinition( parentName, className, this.readerContext.getBeanClassLoader());&#125;public static AbstractBeanDefinition createBeanDefinition( @Nullable String parentName, @Nullable String className, @Nullable ClassLoader classLoader) throws ClassNotFoundException &#123; // 泛型的bean定义，也就是最终生成的bean定义。 GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setParentName(parentName); if (className != null) &#123; if (classLoader != null) &#123; // 设置Class 对象，该对象就是我们在配置文件中配置的Class对象。最后返回。 bd.setBeanClass(ClassUtils.forName(className, classLoader)); &#125; else &#123; bd.setBeanClassName(className); &#125; &#125; return bd;&#125; 该方法很简单，创建一个 Definition 的持有者，然后设置该持有者的Class对象，该对象就是我们在配置文件中配置的Class对象。最后返回。 至此，xml中定义的BeanDefinition元数据被注册至应用上下文中，创建bean工厂，生成Bean定义。但还没有实例化该类。 Spring ioc 依赖注入及lazy－init 我们刚刚创建了Bean工厂，并创建 BeanDefinitions 放进 Map 里，以beanName为key。那么我们现在有了Bean定义，但还没有实例，也没有构建Bean与Bean之间的依赖关系。 接下来我们看如何实例及构建 Bean 依赖关系 1：BeanDefinition 保存所有 bean 定义及依赖关系 2：解析所有 bean 定义，存储到 BeanDefinition 中 3：getBean() 时，触发 ioc 依赖注入 4：getBean() 由使用或者 context 中的 finishBeanFactoryInitialization() 循环触发（判断是否lazy，是否是单例） 5：创建bean自身---由 factoryBean 或者自定义的 facotry-method 或者默认构造方法(cglib或class.newInstance()) 6：ioc 依赖注入： A: - BeanDefinitionValueResolver，判断各种属性类型获取属性值（如果ref引用类型，递归调用getBean()，其它则返回对应值） B: - 正式注入：BeanWrapper.setPropertyValues() AbstractApplicationContext.refresh().finishBeanFactoryInitialization(beanFactory) 实例化所有的非延迟加载的单例类 preInstantiateSingletons12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public void preInstantiateSingletons() throws BeansException &#123; // private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256); List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // 触发所有非延迟单例bean的初始化... // 创建bean并递归构建依赖关系 for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 创建bean getBean(beanName); &#125; &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // 为所有适用的bean触发初始化后回调 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; doGetBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123;final String beanName = transformedBeanName(name);Object bean;// ......try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", ex); &#125; &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // ......&#125;&#125;// ......return (T) bean;&#125; 可以看到，该方法首先会获取依赖关系，拿着依赖的BeanName 递归调用 getBean方法，直到调用 getSingleton 方法返回依赖bean，而 getSingleton 方法的参数是 createBean 返回的实例，该方法内部调用 AbstractAutowireCapableBeanFactory.doCreateBean 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 创建实例 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; // 填充Bean，发生依赖注入的地方 populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(......); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; // ...... return exposedObject;&#125; 核心代码： instanceWrapper = createBeanInstance(beanName, mbd, args) 创建实例。 populateBean(beanName, mbd, instanceWrapper) ， 用于填充Bean，发生依赖注入。 createBeanInstance 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 使用适当的实例化策略，为指定的bean创建一个新实例: * 工厂方法、构造函数自动连接或简单实例化. */protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; // 确保bean类在这一点上得到了实际的解析. Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Bean class isn't public, and non-public access not allowed: " + beanClass.getName()); &#125; Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // Shortcut when re-creating the same bean... boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; if (resolved) &#123; if (autowireNecessary) &#123; return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; return instantiateBean(beanName, mbd); &#125; &#125; // Candidate constructors for autowiring? Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); &#125; // Preferred constructors for default construction? ctors = mbd.getPreferredConstructors(); if (ctors != null) &#123; return autowireConstructor(beanName, mbd, ctors, null); &#125; // No special handling: simply use no-arg constructor. return instantiateBean(beanName, mbd);&#125; 该方法首先创建Class 对象，然后获取构造器对象，最后调用 instantiateBean(beanName, mbd) 123456789101112131415161718192021/** * 使用它的默认构造函数实例化给定的bean. */protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; try &#123; Object beanInstance; final BeanFactory parent = this; if (System.getSecurityManager() != null) &#123; beanInstance = AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; getInstantiationStrategy().instantiate(mbd, beanName, parent), getAccessControlContext()); &#125; else &#123; beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &#125; // ......&#125; 该方法核心逻辑是 beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent)，携带BeanName，RootBeanDefinition ,发挥的策略对象是 SimpleInstantiationStrategy，该方法内部调用静态方法 BeanUtils.instantiateClass(constructorToUse)， 最后调用 Constructor 的 newInstance 方法，也就是最终使用反射创建了该实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) &#123; // Don't override the class with CGLIB if no overrides. if (!bd.hasMethodOverrides()) &#123; Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) &#123; constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) &#123; final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) &#123; throw new BeanInstantiationException(clazz, "Specified class is an interface"); &#125; try &#123; if (System.getSecurityManager() != null) &#123; constructorToUse = AccessController.doPrivileged( (PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;) clazz::getDeclaredConstructor); &#125; else &#123; constructorToUse = clazz.getDeclaredConstructor(); &#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &#125; catch (Throwable ex) &#123; throw new BeanInstantiationException(clazz, "No default constructor found", ex); &#125; &#125; &#125; return BeanUtils.instantiateClass(constructorToUse); &#125; else &#123; // Must generate CGLIB subclass. return instantiateWithMethodInjection(bd, beanName, owner); &#125;&#125;public static &lt;T&gt; T instantiateClass(Constructor&lt;T&gt; ctor, Object... args) throws BeanInstantiationException &#123; Assert.notNull(ctor, "Constructor must not be null"); try &#123; // 判断是否是 Kotlin 类型。如果不是，则调用构造器的实例方法 ReflectionUtils.makeAccessible(ctor); return (KotlinDetector.isKotlinReflectPresent() &amp;&amp; KotlinDetector.isKotlinType(ctor.getDeclaringClass()) ? KotlinDelegate.instantiateClass(ctor, args) : ctor.newInstance(args)); &#125; // ......&#125; 到这里，我们的实例已经创建。但是我们的实例的依赖还没有设置： populateBean(beanName, mbd, instanceWrapper) ， 用于填充Bean，依赖注入。 populateBean 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; return; &#125; // 获取该bean的所有属性，也就是我们配置property元素 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; if (pvs != null) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125;&#125;protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; if (pvs.isEmpty()) &#123; return; &#125; if (System.getSecurityManager() != null &amp;&amp; bw instanceof BeanWrapperImpl) &#123; ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &#125; MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; if (mpvs.isConverted()) &#123; // Shortcut: use the pre-converted values as-is. try &#123; bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125; &#125; original = mpvs.getPropertyValueList(); &#125; else &#123; original = Arrays.asList(pvs.getPropertyValues()); &#125; TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // 创建一个深度副本，解析值的任何引用 List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;&gt;(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) &#123; if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; else &#123; String propertyName = pv.getName(); Object originalValue = pv.getValue(); // 获取 pvName 所对应的容器value Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. if (resolvedValue == originalValue) &#123; if (convertible) &#123; pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125; &#125; if (mpvs != null &amp;&amp; !resolveNecessary) &#123; mpvs.setConverted(); &#125; // Set our (possibly massaged) deep copy. try &#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125; // ......&#125; 该方法核心逻辑是 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null)， 即获取该 bean 的所有属性，也就是我们配置的 property 元素。最后执行 applyPropertyValues(beanName, mbd, bw, pvs) 方法。现在的PropertyValues 都是字符串，没有值，这个方法的作用就是获取值，关键代码：Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue)，该方法会获取 pvName 所对应的容器 value，该方法内部会调用 BeanWrapperImpl.resolveReference(argName, ref) 方法 resolveReference 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private Object resolveReference(Object argName, RuntimeBeanReference ref) &#123; try &#123; Object bean; String refName = ref.getBeanName(); refName = String.valueOf(doEvaluate(refName)); if (ref.isToParent()) &#123; if (this.beanFactory.getParentBeanFactory() == null) &#123; throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, "Can't resolve reference to bean '" + refName + "' in parent factory: no parent factory available"); &#125; bean = this.beanFactory.getParentBeanFactory().getBean(refName); &#125; else &#123; // 根据属性名从容器中获取实例,递归 bean = this.beanFactory.getBean(refName); this.beanFactory.registerDependentBean(refName, this.beanName); &#125; if (bean instanceof NullBean) &#123; bean = null; &#125; return bean; &#125; catch (BeansException ex) &#123; throw new BeanCreationException( this.beanDefinition.getResourceDescription(), this.beanName, "Cannot resolve reference to bean '" + ref.getBeanName() + "' while setting " + argName, ex); &#125;&#125;public void setValue(final @Nullable Object value) throws Exception &#123; final Method writeMethod = (this.pd instanceof GenericTypeAwarePropertyDescriptor ? ((GenericTypeAwarePropertyDescriptor) this.pd).getWriteMethodForActualAccess() : this.pd.getWriteMethod()); if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; ReflectionUtils.makeAccessible(writeMethod); return null; &#125;); try &#123; AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; writeMethod.invoke(getWrappedInstance(), value), acc); &#125; catch (PrivilegedActionException ex) &#123; throw ex.getException(); &#125; &#125; else &#123; ReflectionUtils.makeAccessible(writeMethod); writeMethod.invoke(getWrappedInstance(), value); &#125;&#125; 该方法是最后一步，我们看到该方法会找到set方法，然后调用 Method 的 invoke 方法，完成属性注入。 总结Spring 的 Bean 其实就是 BeanDefinition，在 Bean 的创建和依赖注入的过程中，需要根据 BeanDefinition 的信息来递归的完成依赖注入。这些递归都是以 getBean() 为入口的，一个递归是在上下文体系中查找需要的 Bean 和创建 Bean 的递归调用；另一个 Bean 是在依赖注入时，通过递归调用容器的 getBean 方法，得到当前的依赖 Bean，同时也触发对依赖 Bean 的创建和注入。在对 Bean 的属性进行依赖注入时，解析的过程也是一个递归的过程，这样，根据依赖关系，一层一层的完成 Bean 的创建和注入，直到最后完成当前 Bean 的创建。有了这个顶层 Bean 的创建和对他的属性依赖注入的完成，意味着当前 Bean 相关的整个依赖链的注入也完成了。]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty-轻量级对象池-recycler]]></title>
    <url>%2F2018%2F11%2F22%2Fnetty-recycler%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，轻量级对象池-Recycler源码浅析，错误之处欢迎指正, 共同学习 介绍由于Java 创建一个实例的消耗不小，所以现在很多框架都使用对象池。创建对象的时候不需要每次都通过new方式创建，如果Recycler有对象直接获取二次利用，不需要对象的时候放入Recycler对象池。通过重用对象，能够避免频繁创建对象和销毁对象带来的损耗。 Recycler的使用 定义基于 FastThreadLocal 的轻量级对象池 Recycler 负责对象的回收和二次利用，不需要每次分配内存减少内存使用，减少 new 对象频率即减少 Young GC 频率 创建对象通过 Recycler 的 get() 获取对象池里面的对象，不需要对象时可以显式调用 recycle() 方法回收对象放到对象池 通过自定义 newObject() 方法定义对象创建，参数handle负责对象回收到对象池Recycler 1234567891011121314151617181920212223242526272829private static final Recycler&lt;User&gt; RECYCLER = new Recycler&lt;User&gt;() &#123; @Override protected User newObject(Handle&lt;User&gt; handle) &#123; return new User(handle); &#125;&#125;;private static class User &#123; private final Recycler.Handle&lt;User&gt; handle; public User(Recycler.Handle&lt;User&gt; handle) &#123; this.handle = handle; &#125; public void recycle() &#123; handle.recycle(this); &#125;&#125;public static void main(String[] args) &#123; User user = RECYCLER.get(); user.recycle(); RECYCLER.get().recycle(); User user1 = RECYCLER.get(); System.out.println(user1 == user);&#125; 执行结果如下1true Recycler的创建1234567891011121314151617181920212223242526protected Recycler() &#123; this(DEFAULT_MAX_CAPACITY_PER_THREAD);&#125;private final FastThreadLocal&lt;Stack&lt;T&gt;&gt; threadLocal = new FastThreadLocal&lt;Stack&lt;T&gt;&gt;() &#123; @Override protected Stack&lt;T&gt; initialValue() &#123; return new Stack&lt;T&gt;(Recycler.this, Thread.currentThread(), maxCapacityPerThread,// Use 32k instances as default. maxSharedCapacityFactor,//2 ratioMask, //7 maxDelayedQueuesPerThread);//2*cpu &#125;&#125;;Stack(Recycler&lt;T&gt; parent, Thread thread, int maxCapacity, int maxSharedCapacityFactor, int ratioMask, int maxDelayedQueues) &#123; this.parent = parent; this.thread = thread; this.maxCapacity = maxCapacity; availableSharedCapacity = new AtomicInteger(max(maxCapacity / maxSharedCapacityFactor, LINK_CAPACITY));//own 32k, shared 16k elements = new DefaultHandle[min(INITIAL_CAPACITY, maxCapacity)]; this.ratioMask = ratioMask;//控制对象回收频率 this.maxDelayedQueues = maxDelayedQueues;//当前线程创建的对象可以在多少线程缓存&#125; Recycler成员变量FastThreadLocal&lt;Stack&gt;类型的threadLocal,Stack成员变量包括DefaultHandle类型数组elements[实际存放对象池,Handle包装对象并且被外部对象引用从而回收对象],thread[当前Stack归属线程],ratioMask[控制对象回收频率],maxCapacity[承载元素最大容量],maxDelayedQueues[当前线程创建的对象释放的最大线程数量],head/prev/cursor,availableSharedCapacity[当前线程创建的对象在其他线程缓存的最大数量] Recycler中获取对象 获取当前线程的Stack 从Stack里面弹出DefaultHandle对象 创建对象并绑定到Stack 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public final T get() &#123; if (maxCapacityPerThread == 0) &#123; return newObject((Handle&lt;T&gt;) NOOP_HANDLE); &#125; Stack&lt;T&gt; stack = threadLocal.get(); DefaultHandle&lt;T&gt; handle = stack.pop(); if (handle == null) &#123; handle = stack.newHandle(); handle.value = newObject(handle);// 跳转到用户自定义代码 &#125; return (T) handle.value;&#125;private static final Handle NOOP_HANDLE = new Handle() &#123; @Override public void recycle(Object object) &#123; // NOOP &#125;&#125;;// 一个handle绑定一个stackDefaultHandle&lt;T&gt; newHandle() &#123; return new DefaultHandle&lt;T&gt;(this);&#125;DefaultHandle(Stack&lt;?&gt; stack) &#123; this.stack = stack;&#125;DefaultHandle&lt;T&gt; pop() &#123; // 当前stack里有多少对象 int size = this.size; if (size == 0) &#123; if (!scavenge()) &#123; return null; &#125; size = this.size; &#125; size --; DefaultHandle ret = elements[size]; elements[size] = null; if (ret.lastRecycledId != ret.recycleId) &#123; throw new IllegalStateException("recycled multiple times"); &#125; ret.recycleId = 0; ret.lastRecycledId = 0; this.size = size; return ret;&#125; 回收对象到Recycler 同线程回收对象 异线程回收对象 同线程回收对象 12345678910111213141516171819202122232425262728293031323334353637public void recycle(Object object) &#123; if (object != value) &#123; throw new IllegalArgumentException("object does not belong to handle"); &#125; stack.push(this);&#125;void push(DefaultHandle&lt;?&gt; item) &#123; Thread currentThread = Thread.currentThread(); if (thread == currentThread) &#123; // The current Thread is the thread that belongs to the Stack, we can try to push the object now. pushNow(item); &#125; else &#123; // The current Thread is not the one that belongs to the Stack, we need to signal that the push // happens later. pushLater(item, currentThread); &#125;&#125;private void pushNow(DefaultHandle&lt;?&gt; item) &#123; if ((item.recycleId | item.lastRecycledId) != 0) &#123; throw new IllegalStateException("recycled already"); &#125; item.recycleId = item.lastRecycledId = OWN_THREAD_ID; int size = this.size; if (size &gt;= maxCapacity || dropHandle(item)) &#123; // Hit the maximum capacity or should drop - drop the possibly youngest object. return; &#125; if (size == elements.length) &#123; elements = Arrays.copyOf(elements, min(size &lt;&lt; 1, maxCapacity)); &#125; elements[size] = item; this.size = size + 1;&#125; 回收对象到Recycler:调用Handle的recycle()方法回收对象,使用Stack的push()方法把当前对象压入栈里面,判断当前线程是否为创建Stack的thread执行同/异线程回收对象1.同线程回收对象-&gt;stack.pushNow()设置recycleId/lastRecycledId为OWN_THREAD_ID,当前Stack对象数量超过承载最大容量或者Handle没有被回收过并且回收对象数量+1&amp;对象回收频率不等于0即回收1/8对象则丢弃对象,当前Stack对象数量达到数组容量则重新创建2倍Stack对象数量的数组,赋值数组当前Stack对象数量位置为回收对象 异线程回收对象 获取WeakOrderQueue 创建WeakOrderQueue 将对象追加到WeakOrderQueue 回收对象到Recycler:2.异线程回收对象-&gt;stack.pushLater()(1)获取WeakOrderQueue-&gt;DELAYED_RECYCLED.get()通过当前Stack对象获取delayedRecycled的WeakOrderQueue(2)创建WeakOrderQueue-&gt;WeakOrderQueue.allocate()把WeakOrderQueue插入到Stack对象头部实现当前线程分配Stack对象(3)将对象追加到WeakOrderQueue-&gt;queue.add()将DefaultHandle对象追加到尾指针tail的elements数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263private void pushLater(DefaultHandle&lt;?&gt; item, Thread thread) &#123; Map&lt;Stack&lt;?&gt;, WeakOrderQueue&gt; delayedRecycled = DELAYED_RECYCLED.get(); WeakOrderQueue queue = delayedRecycled.get(this); if (queue == null) &#123; if (delayedRecycled.size() &gt;= maxDelayedQueues) &#123; // Add a dummy queue so we know we should drop the object delayedRecycled.put(this, WeakOrderQueue.DUMMY); return; &#125; // Check if we already reached the maximum number of delayed queues and if we can allocate at all. if ((queue = WeakOrderQueue.allocate(this, thread)) == null) &#123; // drop object return; &#125; delayedRecycled.put(this, queue); &#125; else if (queue == WeakOrderQueue.DUMMY) &#123; // drop object return; &#125; queue.add(item);&#125;private static final FastThreadLocal&lt;Map&lt;Stack&lt;?&gt;, WeakOrderQueue&gt;&gt; DELAYED_RECYCLED = new FastThreadLocal&lt;Map&lt;Stack&lt;?&gt;, WeakOrderQueue&gt;&gt;() &#123; @Override protected Map&lt;Stack&lt;?&gt;, WeakOrderQueue&gt; initialValue() &#123; return new WeakHashMap&lt;Stack&lt;?&gt;, WeakOrderQueue&gt;(); &#125;&#125;;static WeakOrderQueue allocate(Stack&lt;?&gt; stack, Thread thread) &#123; // We allocated a Link so reserve the space return reserveSpace(stack.availableSharedCapacity, LINK_CAPACITY) ? new WeakOrderQueue(stack, thread) : null;&#125;private static boolean reserveSpace(AtomicInteger availableSharedCapacity, int space) &#123; assert space &gt;= 0; for (;;) &#123; int available = availableSharedCapacity.get(); if (available &lt; space) &#123; return false; &#125; if (availableSharedCapacity.compareAndSet(available, available - space)) &#123; return true; &#125; &#125;&#125;private WeakOrderQueue(Stack&lt;?&gt; stack, Thread thread) &#123; head = tail = new Link(); owner = new WeakReference&lt;Thread&gt;(thread); synchronized (stack) &#123; next = stack.head; stack.head = this; &#125; // Its important that we not store the Stack itself in the WeakOrderQueue as the Stack also is used in // the WeakHashMap as key. So just store the enclosed AtomicInteger which should allow to have the // Stack itself GCed. availableSharedCapacity = stack.availableSharedCapacity;&#125; 异线程收割对象 获取当前线程的Stack 从Stack里面弹出对象 创建对象并绑定到Stack 异线程收割对象-&gt;stack.scavenge()从其他线程回收对象使用scavengeSome()方法获取当前需要回收WeakOrderQueue cursor,while循环向当前Stack关联的WeakOrderQueue回收对象,使用WeakOrderQueue cursor的transfer()方法把WeakOrderQueue的Link传输到Stack,循环将当前Link数组元素传输到当前Stack底层数组,cursor的关联线程owner是否为空释放cursor节点,如果没有回收到对象则重置prev指针置为空/cursor指针置为head头节点即下次从头部开始回收]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty解码器抽象父类-ByteToMessageDecoder解析]]></title>
    <url>%2F2018%2F11%2F20%2Fnetty-byteToMessageDecoder%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，解码器抽象父类-ByteToMessageDecoder源码浅析，错误之处欢迎指正, 共同学习 累加字节流123456789101112131415161718192021222324252627282930313233public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof ByteBuf) &#123; // 从对象池中取出一个List CodecOutputList out = CodecOutputList.newInstance(); try &#123; ByteBuf data = (ByteBuf) msg; first = cumulation == null; if (first) &#123; // 第一次解码 cumulation = data;// 累计 &#125; else &#123; // 第二次解码，就将 data 向 cumulation 追加，并释放 data cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data); &#125; // 得到追加后的 cumulation 后，调用 decode 方法进行解码 // 解码过程中，调用 fireChannelRead 方法，主要目的是将累积区的内容 decode 到 数组中 callDecode(ctx, cumulation, out); &#125; catch (DecoderException e) &#123; throw e; &#125; catch (Throwable t) &#123; throw new DecoderException(t); &#125; finally &#123; // ...... &#125; &#125; else &#123; // 非ByteBuf，直接将当前对象向下进行传播 ctx.fireChannelRead(msg); &#125;&#125;1. 从对象池中取出一个空的数组。2. 判断成员变量是否是第一次使用，将 unsafe 中传递来的数据写入到这个 cumulation 累积区中。3. 写到累积区后，调用子类的 decode 方法，尝试将累积区的内容解码，每成功解码一个，就调用后面节点的 channelRead 方法。若没有解码成功，什么都不做。 12345678910111213141516171819202122232425private Cumulator cumulator = MERGE_CUMULATOR;public static final Cumulator MERGE_CUMULATOR = new Cumulator() &#123; @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) &#123; ByteBuf buffer; // 判断当前cumulation是否可写 if (cumulation.writerIndex() &gt; cumulation.maxCapacity() - in.readableBytes() || cumulation.refCnt() &gt; 1) &#123; // 扩容 buffer = expandCumulation(alloc, cumulation, in.readableBytes()); &#125; else &#123; buffer = cumulation; &#125; // 把当前数据写入到累加器 buffer.writeBytes(in); // 把读进来的数据进行释放 in.release(); return buffer; &#125;&#125;;将 unsafe.read 传递过来的 ByteBuf 的内容写入到 cumulation 累积区中，然后释放掉旧的内容，由于这个变量是成员变量，因此可以多次调用 channelRead 方法写入。同时这个方法也考虑到了扩容的问题。 调用子类的decode方法进行解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123; try &#123; // 如果累计区还有可读字节 while (in.isReadable()) &#123; // mark 解析前数组大小 int outSize = out.size(); // 判断list中是否有对象 if (outSize &gt; 0) &#123; // 调用后面的业务 handler 的 ChannelRead 方法向下传播 fireChannelRead(ctx, out, outSize); // 清空 list out.clear(); // 解码过程中如果当前 context 被 remove 掉，直接 break if (ctx.isRemoved()) &#123; break; &#125; outSize = 0; &#125; // mark 当前可读字节数 int oldInputLength = in.readableBytes(); // 调用 decode 方法，将成功解码后的数据放入 out 数组中， decode(ctx, in, out); // 解码过程中如果当前 context 被 remove 掉，直接 break if (ctx.isRemoved()) &#123; break; &#125; // 判断 decode 方法是否解析出对象 if (outSize == out.size()) &#123; // 当前累加器数据是否可以拼装成一个完整的数据包 if (oldInputLength == in.readableBytes()) &#123; break; &#125; else &#123; continue;//当前到数据，但没有解析到对象，continue &#125; &#125; // 没有从累加器中读取数据 if (oldInputLength == in.readableBytes()) &#123; throw new DecoderException( StringUtil.simpleClassName(getClass()) + ".decode() did not read anything but decoded a message."); &#125; if (isSingleDecode()) &#123; break; &#125; &#125; &#125; catch (DecoderException e) &#123; throw e; &#125; catch (Throwable cause) &#123; throw new DecoderException(cause); &#125;&#125; 123456789101112该方法主要逻辑：只要累积区还有未读数据，就循环进行读取。1. 调用 decode 方法，内部调用了子类重写的 decode 方法。decode 方法的逻辑就是将累积区的内容按照约定进行解码，如果成功解码，就添加到数组中。同时该方法也会检查该 handler 的状态，如果被移除出 pipeline 了，就将累积区的内容直接刷新到后面的 handler 中。2. 如果 Context 节点被移除了，直接结束循环。如果解码前的数组大小和解码后的数组大小相等，且累积区的可读字节数没有变化，说明此次读取什么都没做，就直接结束。如果字节数变化了，说明虽然数组没有增加，但确实在读取字节，就再继续读取。3. 如果上面的判断过了，说明数组读到数据了，但如果累积区的 readIndex 没有变化，则抛出异常，说明没有读取数据，但数组却增加了，子类的操作是不对的。4. 如果是个单次解码器，解码一次就直接结束了。所以，这段代码的关键就是子类需要重写 decode 方法，将累积区的数据正确的解码并添加到数组中。每添加一次成功，就会调用 fireChannelRead 方法，将数组中的数据传递给后面的 handler。完成之后将数组的 size 设置为 0.所以，如果你的业务 handler 在这个地方可能会被多次调用。也可能一次也不调用。取决于数组中的值。当然，如果解码 handler 被移除了，就会将累积区的所有数据刷到后面的 handler。 将解析到的ByteBuf向下传播12345678910111213141516171819202122232425262728293031323334353637383940414243public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof ByteBuf) &#123; // ...... &#125; catch (Throwable t) &#123; throw new DecoderException(t); &#125; finally &#123; // 如果累计区没有可读字节了 if (cumulation != null &amp;&amp; !cumulation.isReadable()) &#123; numReads = 0;// 将次数归零 cumulation.release();// 释放累计区 cumulation = null;// Help GC &#125; // 如果超过了 16 次，就压缩累计区，主要是将已经读过的数据丢弃，将 readIndex 归零。 else if (++ numReads &gt;= discardAfterReads) &#123; numReads = 0; discardSomeReadBytes(); &#125; int size = out.size(); // 如果没有向数组插入过任何数据 decodeWasNull = !out.insertSinceRecycled(); // 循环数组，向后面的 handler 发送数据，如果数组是空，那不会调用 fireChannelRead(ctx, out, size); // 将数组回收 out.recycle(); &#125; &#125; else &#123; // 非ByteBuf，直接将当前对象向下进行传播 ctx.fireChannelRead(msg); &#125;&#125;1. 如果累积区没有可读数据了，将计数器归零，并释放累积区。2. 如果不满足上面的条件，且计数器超过了 16 次，就压缩累积区的内容，压缩手段是删除已读的数据。将 readIndex 置为 0。static void fireChannelRead(ChannelHandlerContext ctx, CodecOutputList msgs, int numElements) &#123; for (int i = 0; i &lt; numElements; i ++) &#123; // 将解析出来的每一个对象向下传播 ctx.fireChannelRead(msgs.getUnsafe(i)); &#125;&#125;将 read 方法的数据读取到累积区，使用解码器解码累积区的数据，解码成功一个就放入到一个数组中，并将数组中的数据一次次的传递到后面的handler。记录 decodeWasNull 属性，这个值的决定来自于你有没有成功的向数组中插入数据，如果插入了，它就是 fasle，没有插入，他就是 true。这个值的作用在于，当 channelRead 方法结束的时候，执行该 decoder 的 channelReadComplete 方法（如果你没有重写的话），会判断这个值 总结解码的主要逻辑就是将所有的数据全部放入累积区，子类从累积区取出数据进行解码后放入到一个 数组中，ByteToMessageDecoder 会循环数组调用后面的 handler 方法，将数据一帧帧的发送到业务 handler 。完成这个的解码逻辑。 可以说，ByteToMessageDecoder 是解码器的核心，Netty 所有的解码器，都可以在此类上扩展，一切取决于 decode 的实现。只要遵守 ByteToMessageDecoder 的约定即可。]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty内存管理-bytebuf总结]]></title>
    <url>%2F2018%2F11%2F19%2Fnetty-bytebuf-review%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，bytebuf总结，错误之处欢迎指正, 共同学习 ByteBuf介绍 内存分配负责把数据从底层 IO 读到 ByteBuf 传递应用程序，应用程序处理完之后再把数据封装成 ByteBuf 写回到 IO，ByteBuf 是直接与底层 IO 打交道的抽象 Demo12345678910public class Scratch &#123; public static void main(String[] args) &#123; PooledByteBufAllocator allocator = PooledByteBufAllocator.DEFAULT; //int page = 1024 * 8; //allocator.directBuffer(2 * page); //allocator.directBuffer(16); ByteBuf byteBuf = allocator.directBuffer(16); byteBuf.release(); &#125;&#125; ByteBuf结构以及重要apiByteBuf结构 1234567+-------------------+------------------+------------------+| discardable bytes | readable bytes | writable bytes || | (CONTENT) | |+-------------------+------------------+------------------+| | | |0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity [读数据指针] [写数据指针] read，write，set方法 read 方法读数据在当前 readerIndex 指针开始往后读， readByte()/readShort()/readInt()/readLong() 把 readerIndex 指针往前移一格，读 readerIndex 指针后面 1/2/4/8 个字节数据，write 方法把数据写到 ByteBuf， read/write 方法 readerIndex/writerIndex 指针往后移动，set 方法在当前指针设置成指定值，不会移动指针 mark，reset方法 mark 方法标记当前 readerIndex/writerIndex 指针，reset 方法还原之前读/写数据 readerIndex/writerIndex 指针，不会改变 readerIndex/writerIndex 指针。确保指针读/写完数据能够保持原样 1234567891011public int readableBytes() &#123; return writerIndex - readerIndex;&#125;public int writableBytes() &#123; return capacity() - writerIndex;&#125;public int maxWritableBytes() &#123; return maxCapacity() - writerIndex;&#125; ByteBuf分类 AbstractByteBuf 抽象实现 ByteBuf。保存和标记读写指针，记录 ByteBuf 最多分配容量及抽象方法子类实现 12345678910111.Pooled 和 UnpooledPooled 池化内存分配每次都是从预先分配好的一块内存取一段连续内存封装成 ByteBuf 提供给应用程序。Unpooled 非池化每次进行内存分配的时候直接调用系统 API 向操作系统申请一块内存，直接分配。2.Unsafe 和非UnsafeUnsafe 直接获取 ByteBuf 在 JVM 的内存地址，基于内存地址调用 JDK 的Unsafe 进行读写操作，使用 UnsafeByteBufUtil.getByte(memory, idx(index)) 通过 ByteBuf 底层分配内存首地址和当前指针基于内存偏移地址获取对应的值。非Unsafe 不依赖 JDK 底层 Unsafe 对象，使用 HeapByteBufUtil.getByte(array, index) 通过内存数组和索引获取对应的值。3.Heap 和 DirectHeap 在堆上进行内存分配，分配内存需要被 GC 管理无需手动释放内存，依赖底层byte 数组。Direct 调用 JDK 的 API 进行内存分配，分配内存不受 JVM 控制。最终不会参与 GC 过程，需要手动释放内存避免造成内存无法释放，依赖 DirectByteBuffer 对象内存，分配工具: Unpooled$directBuffer()方法 ByteBufAllocator分析 ByteBuf 通过 ByteBufAllocator 内存分配管理器分配内存，内存分配管理器最顶层抽象负责分配所有类型的内存 123456789101112131.ByteBufAllocator功能ByteBufAllocator 重载 buffer() 方法分配一块内存。buffer()方法分配内存是否为 Direct/Heap内存依赖具体实现。ioBuffer() 方法分配内存更希望是适合 IO 的 Direct Buffer，directBuffer()/headBuffer()方法堆内/堆外进行内存分配。compositeBuffer() 方法分配将两个 ByteBuf 合并变成CompositeByteBuf2.AbstractByteBufAllocatorAbstractByteBufAllocator 抽象实现 ByteBufAllocator。buffer() 方法分配 Buffer 依赖实现分配内存，调用 directBuffer()/heapBuffer() 方法分配默认 Buffer 容量和最大扩充容量的ByteBuf。newDirectBuffer()/newHeapBuffer() 方法分配 Pooled/Unpooled 依赖底层实现3.ByteBufAllocator两个子类PooledByteBufAllocator 从预先分配好的内存取一段内存，UnpooledByteBufAllocator 调用系统API 分配内存，调用 hasUnsafe() 方法获取 Unsafe 决定分配 Unsafe/非Unsafe UnPooledByteBufAllocator分析 123456789101112131.heap内存的分配newHeapBuffer() 方法通过 hasUnsafe() 方法判断是否有 Unsafe。传递【initialCapacity容量，Byte数组】参数 setArray() 方法设置 array 以及 setIndex() 方法设置读/写指针创建UnpooledUnsafeHeapByteBuf/UnpooledHeapByteBuf，_get***() 方法通过 Unsafe 方式返回数组对象偏移量对应的数组索引方式返回 array 数组 index位置byte2.direct内存的分配newDirectBuffer() 方法通过 hasUnsafe() 方法判断是否有 Unsafe。调用 allocateDirect(initialCapacity)创建Direct。ByteBuffer 使用 setByteBuffer() 方法设置 buffer[UnpooledUnsafeDirectByteBuf 使用 directBufferAddress() 方法获取 buffer 内存地址设置memoryAddress ]创建 UnpooledUnsafeDirectByteBuf/UnpooledDirectByteBuf，_get***()方法通过 addr() 方法 memoryAdress+index 计算内存地址Unsafe 获取对应这块内存的 byte/ByteBuffer获取 buffer index位置对应的byte PooledByteBufAllocator概述 1234567891011121314151617181920212223242526271.拿到线程局部缓存PoolThreadCache-&gt;threadCache.get()通过 PoolThreadLocalCache 类型成员变量 threadCache 的 get() 方法获取当前线程的PoolThreadCache 局部缓存 cache，不同线程在对象内存堆上进行分配，PoolThreadLocalCache[继承FastThreadLocal]的 initialValue() 方法通过 heapArenas/directArenas 调用leastUsedArena() 方法获取 heapArena/directArena 数组，构造PoolThreadLocalCache2.在线程局部缓存的Arena上进行内存分配线程局部缓存 PoolThreadCache 维护两块内存：heapArena/directArena堆内/堆外内存，初始化PoolThreadLocalCache 通过 heapArenas/directArenas 调用 leastUsedArena() 方法获取用到最少的 heapArena/directArena 竞技场，heapArenas/directArenas 通过构造PooledByteBufAllocator 调用newArenaArray() 方法根据 DEFAULT_NUM_HEAP/DIRECT_ARENA[max(io.netty.allocator.numHeap/DirectArenas,min(runtime.availableProcessors()*2[默认使用2倍CPU核数减少同步不用加锁分配],runtime.maxMemory()/io.netty.allocator.pageSize &lt;&lt; io.netty.allocator.maxOrder/2/3))]容量创建PoolArena数组遍历设置PoolArena的HeapArena/DirectArena3.PooledByteBufAllocator结构 -------- -------- -------- -------- |Thread| |Thread| |Thread| |Thread| -------- -------- -------- -------- -----|-------------|-------------|-------------|----- | ------- ------- ------- ------- | | |Arena| |Arena| |Arena| |Arena| | | ------- ------- ------- ------- | | ----------------- tinyCacheSize | | |PoolThreadCache| smallCacheSize | | ----------------- normalCacheSize | -----------------------------------------------------创建 ByteBuffer 通过 PoolThreadCache 获取 Arena 对象，PoolThreadCache 通过ThreadLocal 方式把内存分配器 Arena 塞到成员变量，每个线程调用 get()方法获取到对应的Arena，即线程与Arena绑定。或者通过底层维护的 ByteBuffer 缓存列表譬如创建1024字节的ByteBuffer用完释放其他地方继续分配1024字节内存通过ByteBuffer缓存列表返回，PooledByteBufAllocator 维护 tinyCacheSize、smallCacheSize 以及 normalCacheSize 缓存 ByteBuffer 的大小用来构造 PooledByteBufAllocator 使用 createSubPageCaches() 方法创建 MemoryRegionCache 数组缓存列表 directArena分配direct内存的流程 123456789101112131.从对象池里面拿到PooledByteBuf进行复用调用 newByteBuf() 方法使用 PooledUnsafeDirectByteBuf/PooledDirectByteBuf 的newInstance()方法通过对象池 RECYCLER 的 get() 方法获取 PooledDirectByteBuf 对象。调用reuse() 方法复用，按照指定maxCapacity扩容，设置引用数量为1以及设置readerIndex/writerIndex读/写指针为0，重置markedReaderIndex/markedWriterIndex，标记读/写指针为02.从缓存上进行内存分配ByteBuf 之前使用过并且被 release。分配差不多规格大小 ByteBuf 当 capacity&lt;pageSize 或者capacity&lt;=chunkSize 调用 cache的allocateTiny()/allocateSmall()/allocateNormal() 方法在缓存上进行内存分配3.从内存堆里面进行内存分配未命中缓存当 capacity&lt;pageSize 或者 capacity&lt;=chunkSize 调用allocateNormal() 方法。当capacity&gt;chunkSize 调用 allocateHuge() 方法在内存堆里面进行内存分配 内存规格的介绍 12345 0 &lt;-tiny-&gt;512B&lt;-small-&gt;8K&lt;-normal-&gt;16M&lt;-huge-&gt; |_____________________| | SubPage Page Chunk16M 作为分界点对应的 Chunk，所有的内存申请以 Chunk 为单位向操作系统申请，内存分配在 Chunk 里面执行相应操作。16M Chunk 按照 Page 进行切分为 2048 个 Page，8K Page 按照 SubPage 切分命中缓存的分配逻辑 缓存数据结构 12345678910111213141516171819 --------------------------MemoryRegionCache---------------------------- | queue: Chunk&amp;Handler Chunk&amp;Handler ..... Chunk&amp;Handler | | sizeClass: tiny(0~512B) small(512B~8K) normal(8K~16M) | | size: N*16B 512B、1K、2K、4K 8K、16K、32K | -----------------------------------------------------------------------queue 由 Entry[Chunk&amp;Handler，Handler指向唯一一段连续内存，Chunk+指向Chunk的一段连续内存确定 Entry 的内存大小和内存位置]组成Cache链。在缓存里查找有无对应的链定位到 queue 里面的 Entry，sizeClass即内存规格包括 tiny(0~512B)、small(512B~8K) 以及 normal(8K~16M)，size 即 MemoryRegionCache 缓存ByteBuf 的大小，同一个 MemoryRegionCache的queue 里面所有元素都是固定的大小，包括tiny(N*16B)、small(512B、1K、2K、4K) 以及 normal(8K、16K、32K) --------------MemoryRegionCache------------- | tiny[32] 0 16B 32B 48B ... 480B 496B | | small[4] 512B 1K 2K 4K | | normal[3] 8K 16K 32K | --------------------------------------------queue 存储每种大小的 ByteBuf，sizeClass包括 Tiny、Small以及 Normal，同一个size 的ByteBuf有哪些可以直接利用，每个线程维护 PoolThreadCache 涵盖 tinySubPageHeap/DirectCaches、smallSubPageHeap/DirectCaches、normalHeap/DirectCaches 三种内存规格大小缓存 Cache，调用createSubPageCaches()/createNormalCaches() 方法创建MemoryRegionCache 数组 命中缓存的分配流程 1234567申请内存调用 normalizeCapacity() 方法 reqCapacity 大于Tiny找2的幂次方数值确保数值大于等于reqCapacity，Tiny内存规格以16的倍数自增分段规格化，目的是为了缓存分配后续 release 放到缓存里面而不需要释放，调用cache 的 allocateTiny()/allocateSmall()/allocateNormal()方法分配缓存1.找到对应 size 的 MemoryRegionCache-&gt;cacheForTiny()/cacheForSmall()/cacheForNormal()调用cacheForTiny()/cacheForSmall()/cacheForNormal()方法使用PoolArena的tinyIdx()/smallIdx()/log2(normCapacity&gt;&gt;numShiftsNormalDirect/numShiftsNormalHeap)方法计算索引通过数组下标方式获取缓存节点MemoryRegionCache2.从queue中弹出一个entry[chunk连续内存]给ByteBuf初始化调用queue的poll()方法弹出个entry使用initBuf()方法根据entry的chunk和handle通过initBuf()/initBufWithSubpage()方法调用PooledByteBuf的init()方法设置ByteBuf的chunk和handle给ByteBuf初始化3.将弹出的entry扔到对象池进行复用-&gt;entry.recycle()调用entry的recycle()方法设置chunk为null&amp;handle为-1使用recyclerHandle的recycle()方法压到栈里扔到对象池后续ByteBuf回收从对象池获取entry将entry的chunk和handle指向被回收的ByteBuf进行复用减少GC以及减少对象重复创建和销毁 arena、chunk、page、subpage概念 1234567891011121314151617181920212223242526272829303132333435363738394041424344 PoolThreadCache ------------- | --------- | | | Cache | | | --------- | | --------- | | | Arena | | | --------- | -------------Arena划分开辟连续内存进行分配，Cache直接缓存连续内存进行分配 Arena ------------------------------------------------------------- | ------------- ------------- ------------- | | | --------- | | --------- | | --------- | | | | | Chunk | | | | Chunk | | | | Chunk | | | | | --------- | | -------- | | --------- | | | | | | |--------&gt;| | | |--------&gt;| | | | | | | --------- | | -------- | | --------- | | | | | Chunk | | | | Chunk | | | | Chunk | | | | | --------- | | -------- | | --------- | | | | | | |&lt;--------| | | |&lt;--------| | | | | | | --------- | | -------- | | --------- | | | | | Chunk | | | | Chunk | | | | Chunk | | | | | --------- | | -------- | | --------- | | | ------------- ------------- ------------- | | ChunkList ChunkList ChunkList | -------------------------------------------------------------Arena的ChunkList[每个节点都是Chunk]通过链表方式连接并且每个ChunkList里面有对应的Chunk进行双向链表连接是因为实时计算每个Chunk的分配情况按照内存使用率分别归为ChunkListPoolArena维护不同使用率的PoolChunkList即Chunk集合q100/q075/q050/q025/q000/qInit调用prevList()方法双向链表连接 --------------------- --------------------- | ------ ------ | | ------ ------ | | | 8K | ... | 8K | | | | 2K | ... | 2K | | | ------ ------ | | ------ ------ | | ------ ------ | | ------ ------ | | | 8K | ... | 8K | | | | 2K | ... | 2K | | | ------ ------ | | ------ ------ | --------------------- --------------------- Chunk SubPage[]Chunk以8K大小划分为Page，Page以2K大小划分为SubPagePoolArena维护PoolSubpage tinySubpagePools/smallSubpagePools，PoolSubpage的chunk表示子页SubPage从属Chunk，elemSize表示子页SubPage划分数值，bitmap记录子页SubPage内存分配情况[0:未分配/1:已分配]，prev/next表示子页SubPage以双向链表方式连接内存分配从线程的PoolThreadCache里面获取对应的Arena，Arena通过ChunkList获取Chunk进行内存分配,Chunk内存分配判断分配内存大小超过1个Page以Page为单位分配，远远小于1个Page获取Page切分成若干SubPage进行内存划分 page 级别内存分配 12345678910111213141.尝试在现有的chunk上分配调用PoolChunkList q050/q025/q000/qInit/q075的allocate()方法尝试在现有的chunk上分配，首次PoolChunkList为空无法在现有的chunk上分配，从head节点开始往下遍历每个chunk尝试分配获取handle，handle小于0表示未分配指向next节点继续分配，handle大于0调用chunk的initBuf()方法初始化PooledByteBuf并且判断chunk的使用率是否超过最大使用率从当前PoolChunk移除添加到nextList下一个链表2.创建一个chunk进行内存分配调用newChunk()方法创建PoolChunk对象，通过PoolChunk的allocate()方法分配normCapacity内存获取handle指向chunk里面一块连续内存，通过allocateDirect()方法获取直接内存使用PoolChunk构造方法创建1&lt;&lt;maxOrder[11]容量memoryMap和depthMap一次一级地向下移动在每个级别遍历左到右并将值设置为子深度创建PoolChunk对象，调用PoolChunk对象的allocate()方法使用allocateRun()方法计算分配深度通过allocateNode()方法分配节点[从0层开始往下查询空闲节点即未使用且大小满足normCapacity的节点，调用setValue()方法标记节点为unusable[12]即已被使用，使用updateParentsAlloc()方法逐层往上查询父节点标记已被使用在内存中分配索引 0&lt;----------------------------0~16M 1&lt;------------------------0~8M 8~16M 2&lt;----------------0~4M 4~8M 8~12M 12~16M ... 10&lt;-----------------0~16K 16K~32K 32K~48K ... 11&lt;---------------0~8K 8K~16K 16K~24K 24K~32K ...3.初始化PooledByteBuf调用PoolChunk的initBuf()方法初始化PooledByteBuf即获取chunk的一块连续内存过后把对应的标记打到PooledByteBuf，调用memoryMapIdx()方法计算chunk连续内存在memoryMap的索引，使用bitmapIdx()方法计算chunk连续内存在bitMap的索引，通过runOffset(memoryMapIdx)计算偏移量以及runLength()方法计算最大长度调用PooledByteBuf的init()方法设置初始化PooledByteBuf subpage 级别的内存分配 1234567891011121314151617181920212223242526272829调用tinyIdx()方法计算normCapacity&gt;&gt;4获取tinySubpagePools的索引tableIdx，根据tableIdx获取tinySubpagePools下标位置的PoolSubpage头节点head，默认情况头节点head无任何内存信息指向它自己表示当前头节点head为空,头节点head的后置节点next非头节点head本身调用initBufWithSubpage()方法初始化PooledByteBuf，反之调用allocateNormal()方法进行subpage级别的内存分配 -------------tinySubpagePools-------------- | tiny[32] 0 16B 32B 48B ... 480B 496B | -------------------------------------------1.定位一个Subpage对象调用allocateNormal()方法内存分配通过PoolChunk对象的allocate()方法使用allocateSubpage()方法创建/初始化normCapacity容量新PoolSubpage添加到拥有此PoolChunk的PoolArena的子页面池里,调用arena的findSubpagePoolHead()方法获取PoolArena拥有的PoolSubPage池的头部并对头节点进行同步,子页面只能从页面分配根据maxOrder分配深度调用allocateNode()方法分配节点获取节点index,使用subpageIdx()方法获取SubPage的索引subpageIdx --------------------- | ------ ------ | | | 8K | ... | 8K | | | ------ ------ | | ------ ------ | | | 8K | ... | 8K | | | ------ ------ | --------------------- Chunk中的SubPages2.初始化Subpage以SubPage的索引获取subpages数组subpageIdx位置的subpage,subpage为空调用PoolSubpage的构造方法创建PoolSubpage,使用init()方法pageSize/normCapacity计算最大SubPage划分数量初始化位图bitmap标识Subpage是否被分配初始化PoolSubpage,调用addToPool()方法把PoolSubpage添加到头节点head所在的链表子页面池,使用allocate()方法获取位图bitmap未被使用的Subpage,可用Subpage为0从子页面池移除Subpage,调用toHandle()方法将bitmapIdx转成为handle[对应Chunk里面第几个节点第几个Subpage即一块内存里面的哪一块连续内存]把memoryMapIdx作为低32位和bitmapIdx作为高32位 -------------tinySubpagePools-------------- | tiny[32] 0 16B 32B 48B ... 480B 496B | | | | | | 16B | -------------------------------------------3.初始化PooledByteBuf调用PoolChunk的initBuf()方法初始化PooledByteBuf即获取chunk的一块连续内存过后把对应的标记打到PooledByteBuf,调用memoryMapIdx()方法计算chunk连续内存在memoryMap的索引,使用bitmapIdx()方法计算chunk连续内存在bitMap的索引,调用initBufWithSubpage()方法通过runOffset(memoryMapIdx)+(bitmapIdx &amp; 0x3FFFFFFF)* subpage.elemSize计算偏移量以及Subpage划分数量调用PooledByteBuf的init()方法设置初始化PooledByteBuf ByteBuf的回收 调用ByteBuf的release()方法使用AbstractReferenceCountedByteBuf的release0()方法判断引用数量是否等于decrement相等调用deallocate()方法设置handle为-1表示不指向任何一块内存以及memory设置为空 123456781.连续的内存区段加到缓存调用chunk.arena.free()方法通过PoolThreadCache的add()方法把连续的内存区段[chunk&amp;handle唯一标识]添加到缓存,使用PoolThreadCache的cache()方法获取MemoryRegionCache节点,调用MemoryRegionCache的add()方法把chunk和handle封装成Entry加到queue,通过newEntry()方法获取对象池RECYCLER的Entry调用queue的offer()方法添加到queue2.标记连续的内存区段为未使用调用freeChunk()方法使用chunk.parent.free()方法通过Chunk释放连续内存,memoryMapIdx()/bitmapIdx()方法获取连续内存的memoryMapIdx/bitmapIdx,bitmapIdx不等于0表示释放SubPage子页面内存通过arena的findSubpagePoolHead()方法获取PoolSubPage头节点head调用subpage的free()方法释放把连续内存对应的位图标识为0,非SubPage通过分配内存反向标记将连续内存标记为未使用,Page级别完全二叉树,SubPage级别位图3.ByteBuf加到对象池调用recycle()方法通过recyclerHandle的recycle()方法将ByteBuf加到对象池即PooledByteBuf被销毁之后在对象池里面 总结12345678910111213141516171819202122231.ByteBuf的api和分类read**()/write**() 方法，AbstractByteBuf 实现ByteBuf 的数据结构抽象出一系列和数据读写相关的api给子类实现。ByteBuf分类按照三个维度区分：堆、Unsafe、UnPooled2.分配Pooled内存的总步骤:首先现成私有变量 PoolThreadCache 维护的缓存空间查找之前使用过被释放的内存，有的话基于连续内存进行分配，没有的话用一定算法在预先分配好的Chunk进行内存分配。3.不同规格的pooled内存分配与释放:Page级别的内存分配和释放通过完全二叉树的标记查找某一段连续内存，Page级别以下的内存分配首先查找到 Page 然后把此 Page 按照 SubPage 大小进行划分。最后通过位图的方式进行内存分配和释放，内存被释放的时候可能被加入到不同级别的缓存队列供下次分配使用4.内存的类别有哪些?* 堆内[基于byte字节内存数组分配]/堆外[基于JDK的DirectByteBuffer内存分配]* Unsafe[通过JDK的Unsafe对象基于物理内存地址进行数据读写]/非Unsafe[调用JDK的API进行读写]* UnPooled[每次分配内存申请内存]/Pooled[预先分配好一整块内存,分配的时候用一定算法从一整块内存取出一块连续内存]5.如何减少多线程内存分配之间的竞争?PooledByteBufAllocator内存分配器结构维护Arena数组，所有的内存分配都在Arena上进行，通过PoolThreadCache对象将线程和Arena进行一一绑定。默认情况一个Nio线程管理一个Arena实现多线程内存分配相互不受影响减少多线程内存分配之间的竞争6.不同大小的内存是如何进行分配的?Page 级别的内存分配和释放通过完全二叉树的标记查找某一段连续内存，Page级别以下的内存分配首先查找到Page然后把此Page按照SubPage大小进行划分最后通过位图的方式进行内存分配和释放，内存被释放的时候可能被加入到不同级别的缓存队列供下次分配使用]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty异步回调机制及对耗时业务的处理]]></title>
    <url>%2F2018%2F11%2F16%2Fnetty-asyc-callback%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，netty如何实现异步回调机制及对耗时业务的处理，错误之处欢迎指正, 共同学习 耗时业务的处理 handler 种加入线程池 context 中添加线程池 handler 种加入线程池1234567891011121314151617181920212223@ChannelHandler.Sharablepublic class ServerBusinessThreadPoolHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; public static final ChannelHandler INSTANCE = new ServerBusinessThreadPoolHandler(); private static ExecutorService threadPool = Executors.newFixedThreadPool(1000); @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception &#123; ByteBuf data = Unpooled.directBuffer(); data.writeBytes(msg); threadPool.submit(() -&gt; &#123; try &#123; //耗时的操作 Thread.sleep(1 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Object result = getResult(data); ctx.channel().writeAndFlush(result); &#125;); &#125;&#125; channelRead0 方法，我们模拟了一个耗时 1 秒的操作，于是，我们将这个任务提交到了一个自定义的业务线程池中，这样，就不会阻塞 Netty 的 IO 线程。 源码分析 判定当 outbound 的 executor 线程不是当前线程的时候，会将当前的工作封装成 task ，然后放入 mpsc 队列中，等待 IO 任务执行完毕后执行队列中的任务 1234567891011121314private void write(Object msg, boolean flush, ChannelPromise promise) &#123; // ...... EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; if (flush) &#123; next.invokeWriteAndFlush(m, promise); &#125; else &#123; next.invokeWrite(m, promise); &#125; &#125; else &#123; // ...... safeExecute(executor, task, promise, m); &#125;&#125; context 中添加线程池 在添加 pipeline 中的 handler 时候，添加一个线程池当我们在调用 addLast 方法添加线程池后，handler 将优先使用这个线程池，如果不添加，将使用 IO 线程。 123456789101112131415161718192021public static void main(String[] args) &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); EventLoopGroup businessGroup = new NioEventLoopGroup(1000); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup); bootstrap.channel(NioServerSocketChannel.class); bootstrap.childOption(ChannelOption.SO_REUSEADDR, true); bootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(businessGroup, ServerBusinessHandler.INSTANCE); &#125; &#125;); bootstrap.bind(Constant.PORT).addListener((ChannelFutureListener) future -&gt; System.out.println("bind success in port: " + Constant.PORT));&#125; 源码分析 以下代码跟踪可参考 netty启动过程源码分析 中 register0 方法 1234567public EventExecutor executor() &#123; if (executor == null) &#123; return channel().eventLoop(); &#125; else &#123; return executor; &#125;&#125; 如果 this.executor 为 null，就返回 channel().eventLoop()，这个是 io 读写线程,肯定是不能执行耗时任务的。而如果在调用 addLast 方法添加线程池后，handler 将优先使用这个线程池 异步回调机制 假设有小王和小李2个同学。小王不断的从Task队列中取出一个Task, 如果队列为空, 那么小王就什么也不做, 如果该Task是一个耗时任务, 而小王执行该任务的话, 后面的Task会得不到执行, 于是, 小王可以将Task交给小李执行, 这样, 小王就可以继续执行下一个Task了, 而小李执行完毕后, 将执行结果作为了Task放入到小王的任务队列中去, 这样, 当小王执行到该任务时, 也就得到了结果 简单实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Person extends Thread &#123; private static final String strFormat = " %s,这是一道%s的题"; //任务队列 BlockingQueue&lt;Runnable&gt; taskQueue; private Person(String name) &#123; super(name); taskQueue = new LinkedBlockingQueue&lt;&gt;(); &#125; @Override public void run() &#123; for(;;) &#123; try &#123; Runnable task = taskQueue.take(); task.run(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; //将任务提交到任务队列中去 private void submit(Runnable task) &#123; taskQueue.offer(task); &#125; public static void main(String[] args) &#123; final Person wang = new Person("小王"); final Person li = new Person("小李"); //启动小李 li.start(); //启动小王 wang.start(); //提交一个简单的题 wang.submit(() -&gt; &#123; System.out.println( Thread.currentThread().getName() + String.format(strFormat,1,"简单")); &#125;); //将复杂的题交给li来做 wang.submit(() -&gt; li.submit(() -&gt; &#123; System.out.println( Thread.currentThread().getName() + String.format(strFormat,2,"复杂")); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //做完之后将结果作为Task返回给wang wang.submit(() -&gt; System.out.println( Thread.currentThread().getName() + " 得到复杂题执行结果")); &#125;)); //提交一个简单的题 wang.submit(() -&gt; System.out.println( Thread.currentThread().getName() + String.format(strFormat,3,"简单"))); &#125;&#125; 执行结果： 1234小王 1,这是一道简单的题小王 3,这是一道简单的题小李 2,这是一道复杂的题小王 得到复杂题执行结果 Netty中的实现12345678910111213141516171819202122232425262728public class NettyPerson extends Thread &#123; private static final String strFormat = " %s,这是一道%s的题"; public static void main(String[] args) &#123; final DefaultEventExecutor wang = new DefaultEventExecutor(); final DefaultEventExecutor li = new DefaultEventExecutor(); wang.execute(() -&gt; System.out.println( Thread.currentThread().getName() + String.format(strFormat,1,"简单"))); wang.execute(() -&gt; &#123; // 生成一个promise final Promise&lt;Integer&gt; promise = wang.newPromise(); // 为该promise注册一个listener, 当任务执行完后回调该listener.该listener在异步任务提交者线程中执行 promise.addListener(future -&gt; System.out.println( Thread.currentThread().getName() + " 复杂题执行结果")); // 在另一个线程中执行一个异步任务, 执行完后, 将promise设置为成功 li.execute(() -&gt; &#123; System.out.println("执行计算任务的线程 " + Thread.currentThread()); promise.setSuccess(10); &#125;); &#125;); wang.execute(() -&gt; System.out.println( Thread.currentThread().getName() + String.format(strFormat,3,"简单"))); &#125;&#125; 执行结果： 1234defaultEventExecutor-1-1 1,这是一道简单的题defaultEventExecutor-1-1 3,这是一道简单的题执行计算任务的线程 Thread[defaultEventExecutor-3-1,5,main]defaultEventExecutor-1-1 复杂题执行结果 源码分析DefaultPromise.setSuccess(V result) 1234567public Promise&lt;V&gt; setSuccess(V result) &#123; if (setSuccess0(result)) &#123; notifyListeners(); return this; &#125; throw new IllegalStateException("complete already: " + this);&#125; DefaultPromise.notifyListeners() 123456789101112131415161718192021222324/** * 如果当前线程不是executor, 就将notifyListener包装成一个Task添加了executor的 * taskqueue中执行, 如果是executor则直接在当前线程中执行. * * 从上面的行为可以猜得到, executor成员的含义应该是异步任务的提交者 */protected EventExecutor executor() &#123; return executor;&#125;private void notifyListeners() &#123; EventExecutor executor = executor(); if (executor.inEventLoop()) &#123; // ...... notifyListenersNow(); &#125; safeExecute(executor, new Runnable() &#123; @Override public void run() &#123; notifyListenersNow(); &#125; &#125;);&#125; DefaultEventExecutor.newPromise(); 12345678// 利用DefaultEventExecutor生成promise时, 将该executor赋值给promise.executor.public &lt;V&gt; Promise&lt;V&gt; newPromise() &#123; return new DefaultPromise&lt;V&gt;(this);&#125;public DefaultPromise(EventExecutor executor) &#123; this.executor = checkNotNull(executor, "executor");&#125; 总结handler 中加入线程池更加的自由，比如访问数据库等操作。 Context 中添加线程池，会将整个 handler 都交给业务线程池，不够灵活。]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty核心组件-pipeline解析(二)]]></title>
    <url>%2F2018%2F11%2F14%2Fnetty-pipeline-2nd%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，Pipeline源码浅析，错误之处欢迎指正, 共同学习 背景在 netty核心组件-pipeline解析(一) 中我们了解了pipeline 的基本概念和初始化及节点添加与删除逻辑，知道了 Netty 是如何处理网络数据的，这篇分析 pipeline 的事件和异常的传播。 pipeline中的inBound事件传播在 netty-接受请求过程源码分析 我们已经分析了新连接的建立过程。接着我们在 NioEventLoop 类的 processSelectedKey 方法中，监听 accpet 事件和 read 事件。 启动服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static void main(String[] args) throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, true) .childAttr(AttributeKey.newInstance("childAttr"), "childAttrValue") .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(new InBoundHandlerA()); ch.pipeline().addLast(new InBoundHandlerB()); ch.pipeline().addLast(new InBoundHandlerC()); &#125; &#125;); ChannelFuture f = b.bind(8880).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125;&#125;public class InBoundHandlerA extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("InBoundHandlerA: " + msg); ctx.fireChannelRead(msg); &#125;&#125;public class InBoundHandlerB extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("InBoundHandlerB: " + msg); ctx.fireChannelRead(msg); &#125; @Override public void channelActive(ChannelHandlerContext ctx) &#123; ctx.channel().pipeline().fireChannelRead("hello world"); &#125;&#125;public class InBoundHandlerC extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("InBoundHandlerC: " + msg); ctx.fireChannelRead(msg); &#125;&#125; 通过 telnet 来连接上面启动好的netty服务，断点打在 NioEventLoop 类的 processSelectedKey 方法中，监听 accpet 事件和 read 事件。 1234567if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // AbstractNioMessageChannel$NioMessageUnsafe unsafe.read(); if (!ch.isOpen()) &#123; return; &#125;&#125; 进入的是 NioSocketChannelUnsafe 的抽象父类 AbstractNioMessageChannel 的 read 方法。精简过的代码如下： 123456789101112131415public final void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); // 读取数据到容器 // ...... // 让 handler 处理容器中的数据 pipeline.fireChannelRead(readBuf.get(i)); // 告诉容器处理完毕了，触发完成事件 pipeline.fireChannelReadComplete();&#125; 首先从 unsafe 中读取数据，然后，将读好的数据交给 pipeline，pipeline 调用 inbound 的 channelRead 方法，读取成功后，调用 inbound 的 handler 的 ChannelReadComplete 方法。 我们首先进入 pipeline 的 fireChannelRead 方法，这个方法是实现了 invoker 的方法。 1234public final ChannelPipeline fireChannelRead(Object msg) &#123; AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125; 内部调用的是 AbstractChannelHandlerContext.invokeChannelRead(head, msg) 静态方法，并传入了 head，我们知道入站数据都是从 head 开始的，以保证后面所有的 handler 都由机会处理数据流。 12345678910111213static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, "msg"), next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelRead(m); &#125; else &#123; executor.execute(new Runnable() &#123; public void run() &#123; next.invokeChannelRead(m); &#125; &#125;); &#125;&#125; 调用这个 Context （也就是 head） 的 invokeChannelRead 方法，并传入数据。 1234567891011private void invokeChannelRead(Object msg) &#123; if (invokeHandler()) &#123; try &#123; ((ChannelInboundHandler) handler()).channelRead(this, msg); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125; &#125; else &#123; fireChannelRead(msg); &#125;&#125; 我们知道, 在Handler处理完数据后, 要想将数据传递到后一个Handler中, 要调用Context的相关方法, 假如这里一个InBoundHandler处理完了一个数据, 调用了 1234@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ctx.fireChannelRead(msg);&#125; 这个方法将msg传递到下一个handler中, 而前面已经知道, 下一个handler可能运行在另一个executor中, 那么解答不同exexutor中handler间数据的传递就在这个方法中了. 下面看这个方法做了什么. 12345@Overridepublic ChannelHandlerContext fireChannelRead(final Object msg) &#123; invokeChannelRead(findContextInbound(), msg); return this;&#125; 先调用的findContextInbound() 该方法很简单，找到当前 Context 的 next 节点（inbound 类型的）并返回。这样就能将请求传递给后面的 inbound handler 了。 重复上面的逻辑，最终到达我们自定义的 handler。 再看invokeChannelRead() 1234567891011121314static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelRead(m); &#125; else &#123; executor.execute(new OneTimeTask() &#123; @Override public void run() &#123; next.invokeChannelRead(m); &#125; &#125;); &#125;&#125; 现在真相大白了, 先返回下一个handler的executor, 然后利用 executor.inEventLoop()判断当前handler的executort和下一个Handler的executor是不是相同, 如果是, 就直接在当前executor中执行, 如果不是, 则打包成一个Task, 加入到下一个executor的TaskQueue中执行. 而next.invokeChannelRead(msg)是 123private void invokeChannelRead(Object msg) &#123; ((ChannelInboundHandler) handler()).channelRead(this, msg); &#125; 即, 调用handler的channelRead方法, 至此, msg传入到了下一个handler中 所以如果两个handler在不同executor中执行, 那么将msg传递到下一个handler是通过TaskQueue来进行了. 现在, 可以总结ChannelHandlerContext的作用了. 它将与处理数据无关的职能从handler中剥离了出去, 用来管理数据在pipeline中的传递. TailContext节点如果数据在 handler 传递过程中没有进行处理，最后传递到 TailContext 节点进行释放 123public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; onUnhandledInboundMessage(msg);&#125; 对未处理inbound消息做最后的处理 12345678910protected void onUnhandledInboundMessage(Object msg) &#123; try &#123; logger.debug( "Discarded inbound message &#123;&#125; that reached at the tail of the pipeline. " + "Please check your pipeline configuration.", msg); &#125; finally &#123; // 对msg对象的引用数减1，当msg对象的引用数为0时，释放该对象的内存 ReferenceCountUtil.release(msg); &#125;&#125; 控制台打印输出： 123InBoundHandlerA: hello worldInBoundHandlerB: hello worldInBoundHandlerC: hello world SimpleChannelInboundHandler 在前面的例子中，假如中间有一个ChannelHandler未对channelRead事件进行传播，就会导致消息对象无法得到释放，最终导致内存泄露。 我们还可以继承 SimpleChannelInboundHandler 来自定义ChannelHandler，它的channelRead方法，对消息对象做了msg处理，防止内存泄露。 123456789101112131415161718192021public abstract class SimpleChannelInboundHandler&lt;I&gt; extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; boolean release = true; try &#123; if (acceptInboundMessage(msg)) &#123; @SuppressWarnings("unchecked") I imsg = (I) msg; channelRead0(ctx, imsg); &#125; else &#123; release = false; ctx.fireChannelRead(msg); &#125; &#125; finally &#123; if (autoRelease &amp;&amp; release) &#123; ReferenceCountUtil.release(msg); &#125; &#125; &#125;&#125; pipeline中的outBound事件传播以后再补充吧(TODO) pipeline 中异常的传播以后再补充吧(TODO) 总结以后再补充吧(TODO)]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty核心组件-pipeline解析(一)]]></title>
    <url>%2F2018%2F11%2F13%2Fnetty-pipeline-1st%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，Pipeline源码浅析，错误之处欢迎指正, 共同学习 背景netty在服务端端口绑定和新连接建立的过程中会建立相应的channel，而与channel的动作密切相关的是pipeline这个概念，在使用Pipeline中自己也有如下不解。 1.ChannelHandlerContext的作用是什么，为什么每一个Handler需要包装一个ChannelHandlerContext 2.数据是如何在不同Handler中传递的 3.Handler在哪一个executor中执行呢? 可以为Handler指派不同的executor吗, 如果handler在不同的executor中执行, 那么数据又是怎么在handler中传递的呢? 4.HeadContext和TailContext的作用是什么? 5.InBound Event来OutBound Event到底是什么? 有什么不同呢? 在Handler中传递有什么区别呢? 下面我们通过源码分析回答这些问题。 pipeline介绍 ChannelPipeline ChannelHandler ChannelHandlerContext 我们在之前的文章中知道，每当 ServerSocket 创建一个新的连接，就会创建一个 Socket，对应的就是目标客户端。而每一个新创建的 Socket 都将会分配一个全新的 ChannelPipeline（以下简称 pipeline），他们的关系是永久不变的；而每一个 ChannelPipeline 内部都含有多个 ChannelHandlerContext（以下简称 Context），他们一起组成了双向链表，这些 Context 用于包装我们调用 addLast 方法时添加的 ChannelHandler（以下简称 handler）。 所以说，他们的关系是这样的： 在运行过程中, 每一个NioSocketChannel对应的Pipeline实际是如下这样子 仔细观察可以发现 Pipeline内部实际上是一个双向链表, 每个元素实际上是一个ChannelHandlerContext每一个Handler被一个ChannelHandlerContext所包装该Pipeline中隐含着两个Context, 一个是HeadContext, 另一个是TailContext, 通过源代码可以看出, 这两个Context也是Handler. 上图中：ChannelSocket 和 ChannelPipeline 是一对一的关联关系，而 pipeline 内部的多个 Context 形成了链表，Context 只是对 Handler 的封装。 pipeline里面有多个handler, 每个handler节点过滤在pipeline中流转的event, 如果判定需要自己处理这个event,则处理(用户可以在pipeline中添加自己的handler) 总的来说，当一个请求进来的时候，会进入 Socket 对应的 pipeline，并流经 pipeline 所有的 handler 知道了他们的概念，我们继续深入看看他们的设计。 1.ChannelPipeline 作用及设计首先看 pipeline 的接口设计： 123456789101112131415public interface ChannelPipeline extends ChannelInboundInvoker, ChannelOutboundInvoker, Iterable&lt;Entry&lt;String, ChannelHandler&gt;&gt; &#123; ChannelPipeline addFirst(String name, ChannelHandler handler); ChannelPipeline addLast(String name, ChannelHandler handler); ChannelPipeline addBefore(String baseName, String name, ChannelHandler handler); ChannelPipeline addAfter(String baseName, String name, ChannelHandler handler); ChannelPipeline remove(ChannelHandler handler); ChannelPipeline replace(ChannelHandler oldHandler, String newName, ChannelHandler newHandler);&#125; 通过 UML 图，可以看到该接口继承了 inBound，outBound，Iterable 接口，表示他可以调用当数据出站的方法和入站的方法，同时也能遍历内部的链表。 再看看他的几个具有代表性的方法，基本上都是针对 handler 链表的插入，追加，删除，替换操作，甚至，我们可以想象他就是一个 LinkedList。同时，他也能返回 channel（也就是 socket）。 handler 在 pipeline 中处理 I/O 事件的方式： -------------------------------------------------------------------- I/O Request via Channel or ChannelHandlerContext | +---------------------------------------------------+---------------+ | ChannelPipeline | | | \|/ | | +---------------------+ +-----------+----------+ | | | Inbound Handler N | | Outbound Handler 1 | | | +----------+----------+ +-----------+----------+ | | /|\ | | | | \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler N-1 | | Outbound Handler 2 | | | +----------+----------+ +-----------+----------+ | | /|\ . | | . . | | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()| | [ method call] [method call] | | . . | | . \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 2 | | Outbound Handler M-1 | | | +----------+----------+ +-----------+----------+ | | /|\ | | | | \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 1 | | Outbound Handler M | | | +----------+----------+ +-----------+----------+ | | /|\ | | +---------------+-----------------------------------+---------------+ | \|/ +---------------+-----------------------------------+---------------+ | | | | | [ Socket.read() ] [ Socket.write() ] | | | | Netty Internal I/O Threads (Transport Implementation) | +-------------------------------------------------------------------+ 注意： 你的业务程序不能将线程阻塞，他将会影响 IO 的速度，进而影响整个 Netty 程序的性能。如果你的业务程序很快，就可以放在 IO 线程中，反之，你需要异步执行。或者在添加 handler 的时候添加一个线程池，例如： 12// 下面这个任务执行的时候，将不会阻塞 IO 线程，执行的线程来自 group 线程池pipeline.addLast(group, "handler", new MyBusinessLogicHandler()); 2.ChannelHandler 作用及设计首先看 ChannelHandler 的接口设计： ChannelHandler 是一个顶级接口，没有继承任何接口： 1public interface ChannelHandler &#123;&#125; 定义了 3 个方法： 123456789101112public interface ChannelHandler &#123; // 当把 ChannelHandler 添加到 pipeline 时被调用 void handlerAdded(ChannelHandlerContext ctx) throws Exception; // 当从 pipeline 中移除时调用 void handlerRemoved(ChannelHandlerContext ctx) throws Exception; // 当处理过程中在 pipeline 发生异常时调用 @Deprecated void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;&#125; 总的来说，ChannelHandler 的作用就是处理 IO 事件或拦截 IO 事件，并将其转发给下一个处理程序 ChannelHandler。 从上面的代码中，可以看到，ChannelHandler 并没有提供很多的方法，因为 Handler 处理事件时分入站和出站的，两个方向的操作都是不同的，因此，Netty 定义了两个子接口继承 ChannelHandler。 2.1. ChannelInboundHandler 入站事件接口 12345678910111213141516171819202122public interface ChannelInboundHandler extends ChannelHandler &#123; void channelRegistered(ChannelHandlerContext ctx) throws Exception; void channelUnregistered(ChannelHandlerContext ctx) throws Exception; void channelActive(ChannelHandlerContext ctx) throws Exception; void channelInactive(ChannelHandlerContext ctx) throws Exception; void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; void channelReadComplete(ChannelHandlerContext ctx) throws Exception; void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; @Override @SuppressWarnings("deprecation") void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;&#125; 如果你经常使用 Netty 程序，你会非常的熟悉这些方法，比如 channelActive 用于当 Channel 处于活动状态时被调用；channelRead —— 当从Channel 读取数据时被调用等等方法。通常我们需要重写一些方法，当发生关注的事件，我们需要在方法中实现我们的业务逻辑，因为当事件发生时，Netty 会回调对应的方法。 注意：当你重写了上面的 channelRead 方法时，你需要显示的释放与池化的 ByteBuf 实例相关的内存。Netty 为此提供了了一个使用方法 ReferenceCountUtil.release(). 2.2. ChannelOutboundHandler 出站事件接口 ChannelOutboundHandler 负责出站操作和处理出站数据。接口方法如下： 1234567891011121314151617181920public interface ChannelOutboundHandler extends ChannelHandler &#123; void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception; void connect( ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception; void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception; void read(ChannelHandlerContext ctx) throws Exception; void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception; void flush(ChannelHandlerContext ctx) throws Exception;&#125; 大家可以熟悉熟悉这个接口，比如 bind 方法，当请求将 Channel 绑定到本地地址时调用，close 方法，当请求关闭 Channel 时调用等等，总的来说，出站操作都是一些连接和写出数据类似的方法。和入站操作有很大的不同。 总之，我们要区别入站方法和出站方法，这在 pipeline 中将会起很大的作用。 2.3. ChannelDuplexHandler 处理出站和入站事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ChannelDuplexHandler extends ChannelInboundHandlerAdapter implements ChannelOutboundHandler &#123; @Override public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception &#123; ctx.bind(localAddress, promise); &#125; @Override public void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) throws Exception &#123; ctx.connect(remoteAddress, localAddress, promise); &#125; @Override public void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception &#123; ctx.disconnect(promise); &#125; @Override public void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception &#123; ctx.close(promise); &#125; @Override public void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception &#123; ctx.deregister(promise); &#125; @Override public void read(ChannelHandlerContext ctx) throws Exception &#123; ctx.read(); &#125; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; ctx.write(msg, promise); &#125; @Override public void flush(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125;&#125; 从上面的代码中可以看出 ChannelDuplexHandler 间接实现了入站接口并直接实现了出站接口。是一个通用的能够同时处理入站事件和出站事件的类。 介绍了完了 ChannelHandler 的设计，我们再来看看 ChannelHandlerContext 。 3.ChannelHandlerContext 作用及设计实际上，从上面的代码中，我们已经看到了 Context 的用处，在 ChannelDuplexHandler 中，cxt 无处不在。事实上，以read 方法为例：调用 handler 的 read 方法，如果你不处理，就会调用 context 的 read 方法，context 再调用下一个 context 的 handler 的 read 方法。 我们看看 ChannelHandlerContext 的接口 UML : ChannelHandlerContext 继承了出站方法调用接口和入站方法调用接口。那么， ChannelInboundInvoker 和 ChannelOutboundInvoker 又有哪些方法呢？ ChannelInboundInvoker.java1234567891011121314151617181920public interface ChannelInboundInvoker &#123; ChannelInboundInvoker fireChannelRegistered(); ChannelInboundInvoker fireChannelUnregistered(); ChannelInboundInvoker fireChannelActive(); ChannelInboundInvoker fireChannelInactive(); ChannelInboundInvoker fireExceptionCaught(Throwable cause); ChannelInboundInvoker fireUserEventTriggered(Object event); ChannelInboundInvoker fireChannelRead(Object msg); ChannelInboundInvoker fireChannelReadComplete(); ChannelInboundInvoker fireChannelWritabilityChanged();&#125; ChannelOutboundInvoker.java 可以看到，这两个 invoker 就是针对入站或出站方法来的，就是再 入站或出站 handler 的外层再包装一层，达到在方法前后拦截并做一些特定操作的目的。 而 ChannelHandlerContext 不仅仅时继承了他们两个的方法，同时也定义了一些自己的方法： 12345678910111213141516public interface ChannelHandlerContext extends AttributeMap, ChannelInboundInvoker, ChannelOutboundInvoker &#123; Channel channel(); EventExecutor executor(); String name(); ChannelHandler handler(); boolean isRemoved(); ChannelPipeline pipeline(); ByteBufAllocator alloc();&#125; 这些方法能够获取 Context 上下文环境中对应的比如 channel，executor，handler ，pipeline，内存分配器，关联的 handler 是否被删除。 我们可以认为，Context 就是包装了 handler 相关的一切，以方便 Context 可以在 pipeline 方便的操作 handler 相关的资源和行为。 pipeline创建过程 介绍完了 pipeline 的接口设计和一些方法，那么我们就看看，netty中的pipeline是怎么玩转起来的 pipeline 初始化 pipeline 添加节点 pipeline 删除节点 1.pipeline 初始化1234567891011121314151617181920212223242526272829303132333435363738/** * 构造AbstratChannel通过 newChannelPipeline()创建Channel对应的Pipeline,创建 * TailContext tail节点和HeadContext head节点通过prev/next组成双向链表数据结构 */protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); // Pipeline在创建Channel的时候被创建 pipeline = newChannelPipeline();&#125;protected DefaultChannelPipeline newChannelPipeline() &#123; return new DefaultChannelPipeline(this);&#125;protected DefaultChannelPipeline(Channel channel) &#123; // pipeline中保存了channel的引用 this.channel = ObjectUtil.checkNotNull(channel, "channel"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125;1.Pipeline中的两大哨兵:head和tail2.TailContext tail节点继承AbstractChannelHandlerContext即为Pipeline节点数据结构ChannelHandlerContext,实现ChannelInboundHandler传播inBound事件即属于Inbound处理器ChannelHandler,exceptionCaught()/channelRead()方法用于异常未处理警告/Msg未处理建议处理收尾3.HeadContext head节点继承AbstractChannelHandlerContext即为Pipeline节点数据结构ChannelHandlerContext,实现ChannelOutboundHandler传播outBound事件即属于Outbound处理器ChannelHandler,使用pipeline.channel().unsafe()获取Channel的Unsafe实现底层数据读写,用于传播事件/读写事件委托Unsafe操作 pipeline中的每个节点是一个ChannelHandlerContext对象，每个context节点保存了它包裹的执行器 ChannelHandler 执行操作所需要的上下文，其实就是pipeline，因为pipeline包含了channel的引用，可以拿到所有的context信息 默认情况下，一条pipeline会有两个节点，head和tail 2.pipeline 添加节点当将Handler添加到Pipeline中时, 最终调用的方法是 1234567891011121314151617181920212223public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &#123; final AbstractChannelHandlerContext newCtx; // 防止多线程并发操作pipeline底层的双向链表 synchronized (this) &#123; // 检查是否有重复 handler checkMultiplicity(handler); // 创建节点 newCtx = newContext(group, filterName(name, handler), handler); // 添加节点 addLast0(newCtx); if (!registered) &#123; newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; &#125; // ...... &#125; // 回调用户代码 callHandlerAdded0(newCtx); return this;&#125; 2.1. 检查是否有重复 handler 1234567891011private static void checkMultiplicity(ChannelHandler handler) &#123; if (handler instanceof ChannelHandlerAdapter) &#123; ChannelHandlerAdapter h = (ChannelHandlerAdapter) handler; if (!h.isSharable() &amp;&amp; h.added) &#123; throw new ChannelPipelineException( h.getClass().getName() + " is not a @Sharable handler, so can't be added or removed multiple times."); &#125; h.added = true; &#125;&#125; 通过 checkMultiplicity() 方法判断 ChannelHandler 是否为 ChannelHandlerAdapter 实例，ChannelHandler 强制转换 ChannelHandlerAdapter 判断是否可共享[isSharable()] &amp; 是否已经被添加过 [h.added] , ChannelHandlerAdapter 非共享并且已经被添加过抛出异常拒绝添加 2.2. 创建节点 123private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) &#123; return new DefaultChannelHandlerContext(this, childExecutor(group), name, handler);&#125; 该方法主要做了两件事 1.将handler包装一个ChannelHandlerContext2.从group中取得一个childExecutor, 赋值给DefaultChannelHandlerContext的executor成员3.根据该handler是InBoundHandler还是OutBoundHandler为该Context设置inbound或outbound 其中DefaultChannelHandlerContext的executor的含义是. 执行所包装的Handler的executor 所以可以看出. Handler可以在不同的executor中执行, 如果不指定, 则该executor是NioEventLoop, 这就是默认情况下Handler在NioEventLoop中执行. 2.3. 添加节点 1234567private void addLast0(AbstractChannelHandlerContext newCtx) &#123; AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;&#125; 调用 addLast0() 方法获取 tail 节点的前置节点 prev ,将当前节点的前置节点 prev 置为 tail 节点的前置节点 prev ,当前节点的后置节点 next 置为 tail 节点, tail 节点的前置节点 prev 的后置节点 next 置为当前节点, tail 节点的前置节点 prev 置为当前节点,通过链表的方式添加到 Channel 的 Pipeline 2.4. 回调用户代码 12345678private void callHandlerAdded0(final AbstractChannelHandlerContext ctx) &#123; try &#123; ctx.handler().handlerAdded(ctx); ctx.setAddComplete(); &#125; catch (Throwable t) &#123; // ...... &#125;&#125; handlerAdded执行用户代码示例 12345678910public class OutBoundHandlerB extends ChannelOutboundHandlerAdapter &#123; @Override public void handlerAdded(final ChannelHandlerContext ctx) &#123; ctx.executor().schedule(() -&gt; &#123; ctx.channel().write("hello world"); ctx.write("hello world"); &#125;, 3, TimeUnit.SECONDS); &#125;&#125; setAddComplete 12345678final void setAddComplete() &#123; for (;;) &#123; int oldState = handlerState; if (oldState == REMOVE_COMPLETE || HANDLER_STATE_UPDATER.compareAndSet(this, oldState, ADD_COMPLETE)) &#123; return; &#125; &#125;&#125; 修改节点的状态至：REMOVE_COMPLETE（说明该节点已经被移除） 或者 ADD_COMPLETE pipeline 删除节点netty 有个最大的特性之一就是Handler可插拔，做到动态编织pipeline，比如在首次建立连接的时候，需要通过进行权限认证，在认证通过之后，就可以将此context移除，下次pipeline在传播事件的时候就就不会调用到权限认证处理器 下面是权限认证Handler最简单的实现，第一个数据包传来的是认证信息，如果校验通过，就删除此Handler，否则，直接关闭连接 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class AuthHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // &#125; @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf password) throws Exception &#123; if (paas(password)) &#123; ctx.pipeline().remove(this); &#125; else &#123; ctx.close(); &#125; &#125; private boolean paas(ByteBuf password) &#123; return false; &#125;&#125;@Overridepublic final ChannelPipeline remove(ChannelHandler handler) &#123; remove(getContextOrDie(handler)); return this;&#125;// 找到节点private AbstractChannelHandlerContext getContextOrDie(ChannelHandler handler) &#123; AbstractChannelHandlerContext ctx = (AbstractChannelHandlerContext) context(handler); if (ctx == null) &#123; throw new NoSuchElementException(handler.getClass().getName()); &#125; else &#123; return ctx; &#125;&#125;/** * 从head节点的后置节点next遍历循环判断节点的Handler是否为指定ChannelHandler获取封装 * ChannelHandler的ChannelHandlerContext节点,ChannelHandlerContext节点为空抛异常 */@Overridepublic final ChannelHandlerContext context(ChannelHandler handler) &#123; if (handler == null) &#123; throw new NullPointerException("handler"); &#125; AbstractChannelHandlerContext ctx = head.next; for (;;) &#123; if (ctx == null) &#123; return null; &#125; if (ctx.handler() == handler) &#123; return ctx; &#125; ctx = ctx.next; &#125;&#125;private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) &#123; assert ctx != head &amp;&amp; ctx != tail; synchronized (this) &#123; remove0(ctx); if (!registered) &#123; callHandlerCallbackLater(ctx, false); return ctx; &#125; // ...... &#125; // 获取当前节点的ChannelHandler使用handlerRemove()方法回调删除Handler事件 callHandlerRemoved0(ctx); return ctx;&#125; 总结1.了解了pipeline 的接口设计和一些方法。Context 包装 handler，多个 Context 在 pipeline 中形成了双向链表，添加和删除节点均只需要调整链表结构。 2.pipeline中的每个节点包着具体的处理器ChannelHandler，节点根据ChannelHandler的类型是ChannelInboundHandler还是ChannelOutboundHandler来判断该节点属于in还是out或者两者都是 下一篇，总结 pipeline 的事件传播机制。 参考 https://www.jianshu.com/p/6efa9c5fa702]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty-接受请求过程源码分析]]></title>
    <url>%2F2018%2F11%2F11%2Fnetty-accept-request%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，接受请求过程源码浅析，错误之处欢迎指正, 共同学习 背景netty启动过程源码分析，我们得知，服务器最终注册了一个 Accept 事件等待客户端的连接。我们也知道，NioServerSocketChannel 将自己注册到了 boss 单例线程池（reactor 线程）上，也就是 EventLoop. EventLoop所做的事情均分为以下三个步骤 1.轮询注册在selector上的IO事件 2.处理IO事件 3.执行异步task 新链接的建立 检测到有新的连接 将新的连接注册到worker线程组 注册新连接的读事件 1.检测新连接 进入到 NioEventLoop 源码中,找到 processSelectedKey()方法设置断点 debug 启动 EchoServer 的 main 方法 建立一个新的连接：telnet 127.0.0.1 8888 上面代码表示boos reactor线程已经轮询到 SelectionKey.OP_ACCEPT 事件，说明有新的连接进入，此时将调用channel的 unsafe来进行实际的操作。接下来，进入到它的read方法，进入新连接处理的第二步 2.注册到reactor线程 12341.检查该 eventloop 线程是否是当前线程。2.执行 doReadMessages 方法，并传入一个 readBuf 变量，这个变量是一个 List，也就是容器。3.循环容器，执行 pipeline.fireChannelRead(readBuf.get(i));4.清理容器，触发 pipeline.fireChannelReadComplete() 进入 doReadMessages 方法 netty调用jdk底层 javaChannel().accept();由于netty中reactor线程第一步就扫描到有accept事件发生，因此，这里的accept方法是立即返回的，返回jdk底层nio创建的一条channel netty将jdk的 SocketChannel 封装成自定义的 NioSocketChannel，添加到容器中，做后续处理 默认一次最多读取16条连接 创建NioSocketChannel 1234567891011121314151617181920212223242526@Overrideprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; SocketChannel ch = javaChannel().accept(); try &#123; if (ch != null) &#123; buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; catch (Throwable t) &#123; logger.warn("Failed to create a new channel from an accepted socket.", t); try &#123; ch.close(); &#125; catch (Throwable t2) &#123; logger.warn("Failed to close a socket.", t2); &#125; &#125; return 0;&#125;@Overrideprotected ServerSocketChannel javaChannel() &#123; return (ServerSocketChannel) super.javaChannel();&#125; 该方法调用了 NioServerSocketChannel 中的 serverSocketChannel.accept() 方法。返回了一个 Nio 的通道，注意：这个通道，就是我们刚刚 Boss 线程监听到的 Accept 事件，相当于一个 Tcp 连接。然后我们看 NioSocketChannel 的创建过程，其中参数 this 是 NioServerSocketChannel ，这个就是 SocketChannel 的 parent 属性，ch 是 SocketChannel 。构造方法如下： 12345678910111213141516171819202122232425262728293031323334353637383940public NioSocketChannel(Channel parent, SocketChannel socket) &#123; super(parent, socket); config = new NioSocketChannelConfig(this, socket.socket());&#125;// NioSocketChannel的父类为 AbstractNioByteChannel// 注册了SelectionKey.OP_READ，表示对channel的读感兴趣protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; super(parent, ch, SelectionKey.OP_READ);&#125;//AbstractNioByteChannel的父类 AbstractNioChannelprotected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; // readInterestOp 表示该channel关心的事件是 SelectionKey.OP_READ，后续会将该事件注册到selector，之后设置该通道为非阻塞模式 this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; if (logger.isWarnEnabled()) &#123; logger.warn( "Failed to close a partially initialized socket.", e2); &#125; &#125; throw new ChannelException("Failed to enter non-blocking mode.", e); &#125;&#125;// super(parent)protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe();// NioSocketChannel$NioSocketChannelUnsafe pipeline = newChannelPipeline();&#125; Netty中的Channel的分类 1.Unsafe[实现Channel读写抽象]，服务端NioMessageUnsafe读连接,客户端NioByteUnsafe读数据2.AbstractChannel用于实现channel的大部分方法，其中我们最熟悉的就是其构造函数中，创建出一条channel的基本组件3.AbstractNioChannel基于AbstractChannel做了nio相关的一些操作，保存jdk底层的 SelectableChannel，并且在构造函数中设置channel为非阻塞4.最后，就是两大channel，NioServerSocketChannel，NioSocketChannel对应着服务端接受新连接过程和新连接读写过程,分别创建NioServerSocketChannelConfig，NioSocketChannelConfig 在创建出一条 NioSocketChannel之后，放置在List容器里面之后，就开始进行下一步操作 12345678910111213141516171819202122@Overridepublic void read() &#123; // ...... try &#123; do &#123; int localRead = doReadMessages(readBuf); // ...... &#125; while (allocHandle.continueReading()); int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); // ...... &#125; finally &#123; // ...... &#125;&#125; 循环执行 pipeline.fireChannelRead 方法 DefaultChannelPipeline.fireChannelRead(NioSocketChannel)123456// 这里的Pipeline是NioServerSocketChannel的Pipeline, 此时Pipeline中有一个ServerBootstrapAcceptor, 所以会传递到ServerBootstrapAcceptor的channelRead方法@Overridepublic final ChannelPipeline fireChannelRead(Object msg) &#123; AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125; ServerBootstrapAcceptor.channelRead(ctx, msg)1234567891011121314151617181920212223242526272829303132333435363738394041424344@Overridevoid init(Channel channel) throws Exception &#123; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;);&#125;// 初始化ServerBootstrapAcceptor时, 该Acceptor有四个属性是由ServerBootstrap传过来的.this.childGroup = currentChildGroup;this.childHandler = currentChildHandler;this.childOptions = currentChildOptions;this.childAttrs = currentChildAttrs;// 这里的childGroup就是subReactor, childHandler就是ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;...&#125;)这个ChannelInitializer是用来初始化NioSocketChannel所对应的Pipeline的.// 来看ServerBootstrapAcceptor的read方法.public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); // ...... try &#123; childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125;&#125; 拿到该channel，也就是我们之前new出来的 NioSocketChannel对应的pipeline，将用户代码中的childHandler，添加到pipeline，然后进入到 childGroup.register(child)，这里的childGroup就是我们在启动代码中new出来的NioEventLoopGroup。之后, 触发channelRegister事件, 执行ChannelInitializer的initChannel方法, 进一步初始化NioSocketChannel所对应的pipeline. 至此, 接收客户端并注册到NioEventLoop的过程完毕。 接下来重点看下childGroup.register方法，为什么是subReactor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// next方法使用位运算获取数组中的EventLoop@Overridepublic ChannelFuture register(Channel channel) &#123; return next().register(channel);&#125;@Overridepublic ChannelFuture register(Channel channel) &#123; return register(new DefaultChannelPromise(channel, this));&#125;@Overridepublic ChannelFuture register(final ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, "promise"); promise.channel().unsafe().register(this, promise); return promise;&#125;promise.channel() 方法返回的是 NioSocketChannelpromise.channel().unsafe() NioSocketChannel$NioSocketChannelUnsafe所以最终调用的是 NioSocketChannel 的内部类的 register 方法。参数是当前的 EventLoop 和 promisepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // ...... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; // ...... &#125; &#125;&#125;// register0private void register0(ChannelPromise promise) &#123; try &#123; // ...... boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); // ......&#125;// doRegister(),真正的注册过程protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().selector, 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; // Force the Selector to select now as the "canceled" SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; &#125; else &#123; // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; &#125; &#125; &#125;&#125;将该条channel绑定到一个selector上去，一个selector被一个reactor线程使用，后续该channel的事件轮询，以及事件处理，异步task执行都是由此reactor线程来负责绑定完reactor线程之后，调用 pipeline.invokeHandlerAddedIfNeeded() pipeline.invokeHandlerAddedIfNeeded(); 12345678910111213141516171819202122232425262728293031// 该方法最终会调用到用户的initChannel方法private boolean initChannel(ChannelHandlerContext ctx) throws Exception &#123; if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) &#123; // Guard against re-entrance. try &#123; initChannel((C) ctx.channel()); &#125; catch (Throwable cause) &#123; // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); &#125; finally &#123; remove(ctx); &#125; return true; &#125; return false;&#125;// 也就是用户代码ServerBootstrap b = new ServerBootstrap();b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(new EchoServerHandler()); &#125; &#125;); 3.注册读事件12345678910111213141516171819202122232425262728293031private void register0(ChannelPromise promise) &#123; try &#123; // ...... // 再调用一下业务pipeline中每个处理器的 ChannelHandlerAdded方法处理下回调 pipeline.fireChannelRegistered(); if (isActive()) &#123; // 在连接已经建立的情况下返回true if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // ...... &#125;&#125;protected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; // 将 SelectionKey.OP_READ事件注册到selector中去，表示这条通道已经可以开始处理read事件了 final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 总结1.boos reactor线程轮询到有新的连接进入2.通过封装jdk底层的channel创建 NioSocketChannel以及一系列的netty核心组件3.将该条连接通过chooser，选择一条worker reactor线程绑定上去4.注册读事件，开始新连接的读写 问:Netty是在哪里检测有新连接接入的?答:Boss线程通过服务端Channel绑定的Selector轮询OP_ACCEPT事件,通过JDK底层Channel的accept()方法获取JDK底层SocketChannel创建新连接 问:新连接是怎样注册到NioEventLoop线程的?答:Worker线程调用Chooser的next()方法选择获取NioEventLoop绑定到客户端Channel,使用doRegister()方法将新连接注册到NioEventLoop的Selector上面 Netty新连接接入处理逻辑:服务端Channel绑定的NioEventLoop即Boss线程轮询OP_ACCEPT事件,调用服务端Channel的accept()方法获取客户端Channel封装成NioSocketChannel,封装创建组件Unsafe用来实现Channel读写和Pipeline负责数据处理业务逻辑链,服务端Channel通过连接接入器ServerBootstrapAcceptor给客户端Channel分配NioEventLoop,将客户端Channel绑定到Selector上面,通过传播Channel Active方法将客户端Channel读事件注册到Selector]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty-fastThreadLocal-源码分析]]></title>
    <url>%2F2018%2F11%2F09%2Fnetty-fastThreadLocal%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，性能优化工具类之FastThreadLocal源码浅析，错误之处欢迎指正, 共同学习 如何使用1234567891011121314151617181920@Testpublic void test() &#123; FastThreadLocal&lt;Object&gt; fastThreadLocal = new FastThreadLocal&lt;Object&gt;() &#123; @Override protected Object initialValue() &#123; return new Object(); &#125; @Override protected void onRemoval(Object value) throws Exception &#123; System.out.println("onRemoval"); &#125; &#125;; System.out.println(fastThreadLocal.get()); fastThreadLocal.set("lishq"); System.out.println(fastThreadLocal.get()); fastThreadLocal.remove(); System.out.println(fastThreadLocal.get());&#125; 123456java.lang.Object@b6cbcclishqonRemovaljava.lang.Object@a7e666Process finished with exit code 0 构造方法解析Netty重新设计了更快的FastThreadLocal，主要实现涉及 FastThreadLocalThread FastThreadLocal InternalThreadLocalMap FastThreadLocalThread是Thread类的简单扩展，主要是为了扩展threadLocalMap属性FastThreadLocal提供的接口和传统的ThreadLocal一致，主要是set和get方法，用法也一致不同地方在于FastThreadLocal的值是存储在InternalThreadLocalMap这个结构里面的，传统的ThreadLocal性能槽点主要是在读写的时候hash计算和当hash没有命中的时候发生的遍历 123456789101112131415161718public FastThreadLocal() &#123; // 初始化时分配一个全局唯一的index index = InternalThreadLocalMap.nextVariableIndex();&#125;Object[] indexedVariables;//获取数组对应的下标public static int nextVariableIndex() &#123; int index = nextIndex.getAndIncrement(); if (index &lt; 0) &#123; nextIndex.decrementAndGet(); throw new IllegalStateException("too many thread-local indexed variables"); &#125; return index;&#125;static final AtomicInteger nextIndex = new AtomicInteger(); nextIndex是InternalThreadLocalMap父类的一个全局静态的AtomicInteger类型的对象，这意味着所有的FastThreadLocal实例将共同依赖这个指针来生成唯一的索引，而且是线程安全的; InternalThreadLocalMap实例和Thread对象一一对应; 该index也是绑定的FastThreadLocal对象的value在Object[]数组中的索引位置 get方法解析1.FastThreadLocal的获取 1234567891011//获取当前线程的InternalThreadLocalMap中的当前ftl的valuepublic final V get(InternalThreadLocalMap threadLocalMap) &#123; // 直接采用index下标访问threadLocalMap中数组的指定位置元素,如果该索引处的value是有效值，不是占位值，则直接返回 Object v = threadLocalMap.indexedVariable(index); if (v != InternalThreadLocalMap.UNSET) &#123; return (V) v; &#125; // 没有设置有效值，执行初始化操作，获取初始值 return initialize(threadLocalMap);&#125; 2.获取InternalThreadLocalMap12345678910111213public final V get() &#123; //获取到与当前线程关联的InternalThreadLocalMap, 通过该map来查询具体数据 return get(InternalThreadLocalMap.get());&#125;public static InternalThreadLocalMap get() &#123; Thread thread = Thread.currentThread(); if (thread instanceof FastThreadLocalThread) &#123; return fastGet((FastThreadLocalThread) thread); &#125; else &#123; return slowGet(); &#125;&#125; 如果当前线程是ftlt线程，则使用fastGet进行获取；否则使用slowGet进行获取。 fastGet: 12345678//底层自己维护了一个ThreadLocalMap对象private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) &#123; InternalThreadLocalMap threadLocalMap = thread.threadLocalMap(); if (threadLocalMap == null) &#123; thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap()); &#125; return threadLocalMap;&#125; 如果该threadLocalMap已经实例化过，则直接返回，否则，先创建一个InternalThreadLocalMap实例，然后将该实例设置到ftlt的threadLocalMap属性中。 12345678910111213141516/** * 无效的value值（占位符），不使用null做无效值的原因是因为netty认为null也是一个有效值， * 例如：假设没有重写FastThreadLocal的initialValue()方法，则该方法返回为null，netty会将null作为有效值直接存储起来 */public static final Object UNSET = new Object();private InternalThreadLocalMap() &#123; super(newIndexedVariableTable());&#125;//初始化32size的数组，并将每一个元素初始化为UNSETprivate static Object[] newIndexedVariableTable() &#123; Object[] array = new Object[32]; Arrays.fill(array, UNSET); return array;&#125; slowGet: 123456789101112static final ThreadLocal&lt;InternalThreadLocalMap&gt; slowThreadLocalMap = new ThreadLocal&lt;InternalThreadLocalMap&gt;();private static InternalThreadLocalMap slowGet() &#123; ThreadLocal&lt;InternalThreadLocalMap&gt; slowThreadLocalMap = UnpaddedInternalThreadLocalMap.slowThreadLocalMap; //这个过程比较慢？ InternalThreadLocalMap ret = slowThreadLocalMap.get(); if (ret == null) &#123; ret = new InternalThreadLocalMap(); slowThreadLocalMap.set(ret); &#125; return ret;&#125; 之所以成为slowGet的原因是因为： fastGet可以直接从当前线程的属性获取；而slowGet需要根据slowThreadLocalMap的索引值与数组长度进行计算之后进行获取，如果没有直接根据索引命中的话，还可能需要进行线性探测的向后循环查找操作，当然还可能有一些清理和整理逻辑。fastGet设置InternalThreadLocalMap，直接给当前线程的属性赋值，而slowGet的set操作需要使用线性探测法进行设置，并会至少执行一次log级别的资源回收整理操作 如上两点也是ftl比tl快的原因。但是可以看出tl在不断的回收无效的Entry使得新的Entry可以插入而不需要额外空间，但是ftl只能不断的增加index，不断向后增加，而index前边被remove掉的位置不能被重用，所以Object[]数组的size会越来越大,算是一种空间换时间的做法。 3.从InternalThreadLocalMap获取值 1234567Object[] indexedVariables;//获取指定位置的元素public Object indexedVariable(int index) &#123; Object[] lookup = indexedVariables; return index &lt; lookup.length? lookup[index] : UNSET;&#125; 4.初始化操作 1234567891011121314151617181920212223242526272829303132333435private V initialize(InternalThreadLocalMap threadLocalMap) &#123; V v = null; try &#123; //获取初始值 v = initialValue(); &#125; catch (Exception e) &#123; PlatformDependent.throwException(e); &#125; // 初始化后再设置，下次就不用再初始化 threadLocalMap.setIndexedVariable(index, v); //添加当前的FastThreadLocal到InternalThreadLocalMap的Set&lt;FastThreadLocal&lt;?&gt;&gt;中 addToVariablesToRemove(threadLocalMap, this); return v;&#125;//初始化参数：由子类复写protected V initialValue() throws Exception &#123; return null;&#125;//设置值/** * @return &#123;@code true&#125; if and only if a new thread-local variable has been created */public boolean setIndexedVariable(int index, Object value) &#123; Object[] lookup = indexedVariables; if (index &lt; lookup.length) &#123; Object oldValue = lookup[index]; lookup[index] = value; return oldValue == UNSET; &#125; else &#123; expandIndexedVariableTableAndSet(index, value); return true; &#125;&#125; 如果索引小于indexedVariables.length，直接获取indexedVariables[index]；否则，进行扩容设置。 首先获取旧数组及其长度；然后进行新数组容量的计算（计算方式与1.8的HashMap一样：都是获取比给定值大的最小的2的n次方的数）；然后创建新数组并拷贝旧数组元素到新数组，最后对扩容多出来的元素初始化为UNSET，然后设置value值，最后将新数组赋值给indexedVariables成员变量。 到此为止设置值的操作就结束了，最后：添加当前的FastThreadLocal到InternalThreadLocalMap的Set&lt;FastThreadLocal&lt;?&gt;&gt;中 1234567891011121314private static void addToVariablesToRemove(InternalThreadLocalMap threadLocalMap, FastThreadLocal&lt;?&gt; variable) &#123; Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex); Set&lt;FastThreadLocal&lt;?&gt;&gt; variablesToRemove; //v搞成set集合，目的很简单，set里面不会放置重复的 threadLocal，放置同一个threadLocal多次 所有使用TheadLocal都会放到 variablesToRemoveIndex 数组中这个索引位置的 if (v == InternalThreadLocalMap.UNSET || v == null) &#123; variablesToRemove = Collections.newSetFromMap(new IdentityHashMap&lt;FastThreadLocal&lt;?&gt;, Boolean&gt;()); threadLocalMap.setIndexedVariable(variablesToRemoveIndex, variablesToRemove); &#125; else &#123; // 如果拿到的不是 UNSET ，说明这是第二次操作了，因此可以强转为 Set variablesToRemove = (Set&lt;FastThreadLocal&lt;?&gt;&gt;) v; &#125; //放到要清除set里面 variablesToRemove.add(variable);&#125; 这个方法的目的是将 FastThreadLocal 对象保存到一个 Set 中，因为 Netty 的 Map 只是一个数组，没有键，所以保存到一个 Set 中，这样就可以判断是否 set 过这个 map，例如 Netty 的 isSet 方法就是根据这个判断的。 5.注册资源清理器12345678910//当该ftl所在的线程不强可达时，清理其上当前ftl的value和set&lt;FastThreadLocal&lt;?&gt;&gt;中当前的ftlprivate void registerCleaner(final InternalThreadLocalMap threadLocalMap) &#123; Thread current = Thread.currentThread(); //如果已经开启了自动清理功能 或者 已经对threadLocalMap中当前的FastThreadLocal开启了清理线程 if (FastThreadLocalThread.willCleanupFastThreadLocals(current) || threadLocalMap.isCleanerFlagSet(index)) &#123; return; &#125; // 设置是否已经开启了对当前的FastThreadLocal清理线程的标志 threadLocalMap.setCleanerFlag(index);&#125; 获取当前线程，如果当前线程是 FastThreadLocalThread 类型 且 cleanupFastThreadLocals 是 true，则返回 true，直接return。也就是说，Netty 线程池里面创建的线程都符合这条件，只有用户自定义的线程池不符合。 当然还有一个条件：如果这个 ftl 的 index + 1 在 map 中的值不是空对象，则已经注册过了，也直接 return，不再重复注册。 set方法解析12345678910111213141516171819202122232425262728/** * 如果value是UNSET，表示删除当前的ThreadLocal对应的value； * 如果不是UNSET，则可能是修改，也可能是新增； * 如果是修改，修改value结束后返回; * 如果是新增，则先新增value，然后新增ThreadLocal到Set中，最后注册Cleaner清除线程 */public final void set(V value) &#123; if (value != InternalThreadLocalMap.UNSET) &#123; InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get(); if (setKnownNotUnset(threadLocalMap, value)) &#123; registerCleaner(threadLocalMap); &#125; &#125; else &#123; // 如果设置的值是UNSET，表示清除该FastThreadLocal的value remove(); &#125;&#125;private boolean setKnownNotUnset(InternalThreadLocalMap threadLocalMap, V value) &#123; // 新增value if (threadLocalMap.setIndexedVariable(index, value)) &#123; //添加清除map的线程，针对使用Jdk的Thread，防止内存泄漏 addToVariablesToRemove(threadLocalMap, this); return true; &#125; // 修改value return false;&#125; remove方法解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//清除当前的FastThreadLocalpublic final void remove() &#123; remove(InternalThreadLocalMap.getIfSet());&#125;public final void remove(InternalThreadLocalMap threadLocalMap) &#123; if (threadLocalMap == null) &#123; return; &#125; // 从 InternalThreadLocalMap 中删除当前的FastThreadLocal对应的value Object v = threadLocalMap.removeIndexedVariable(index); // 从 InternalThreadLocalMap 中的Set&lt;FastThreadLocal&lt;?&gt;&gt;中删除当前的FastThreadLocal对象 removeFromVariablesToRemove(threadLocalMap, this); //如果删除的是有效值，则进行onRemove方法的回调 if (v != InternalThreadLocalMap.UNSET) &#123; try &#123; onRemoval((V) v); &#125; catch (Exception e) &#123; PlatformDependent.throwException(e); &#125; &#125;&#125;private static void removeFromVariablesToRemove( InternalThreadLocalMap threadLocalMap, FastThreadLocal&lt;?&gt; variable) &#123; Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex); if (v == InternalThreadLocalMap.UNSET || v == null) &#123; return; &#125; @SuppressWarnings("unchecked") Set&lt;FastThreadLocal&lt;?&gt;&gt; variablesToRemove = (Set&lt;FastThreadLocal&lt;?&gt;&gt;) v; variablesToRemove.remove(variable);&#125;//删除指定位置的对象public Object removeIndexedVariable(int index) &#123; Object[] lookup = indexedVariables; if (index &lt; lookup.length) &#123; Object v = lookup[index]; lookup[index] = UNSET; return v; &#125; else &#123; return UNSET; &#125;&#125; removeAll方法解析12345678910111213141516171819202122232425262728293031323334public static void removeAll() &#123; InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.getIfSet(); if (threadLocalMap == null) &#123; return; &#125; try &#123; // 从indexedVariables[VARIABLES_TO_REMOVE_INDEX]获取目前InternalThreadLocalMap存储的有效的FastThreadLocal的值，之后遍历Set，进行remove操作 // 注意：这也是为什么我们会将有效的FastThreadLocal存储在一个Set中的原因（另外，如果没有Set&lt;FastThreadLocal&lt;?&gt;&gt;这个集合的话，我们需要直接去遍历整个indexedVariables数组，可能其中有效的并不多，影响效率） Object v = threadLocalMap.indexedVariable(variablesToRemoveIndex); if (v != null &amp;&amp; v != InternalThreadLocalMap.UNSET) &#123; @SuppressWarnings("unchecked") Set&lt;FastThreadLocal&lt;?&gt;&gt; variablesToRemove = (Set&lt;FastThreadLocal&lt;?&gt;&gt;) v; //将set先转换为数组,set的for-remove模式会报并发修改异常，array不会 FastThreadLocal&lt;?&gt;[] variablesToRemoveArray = variablesToRemove.toArray(new FastThreadLocal[0]); for (FastThreadLocal&lt;?&gt; tlv: variablesToRemoveArray) &#123; tlv.remove(threadLocalMap); &#125; &#125; &#125; finally &#123; //删除当前线程的InternalThreadLocalMap InternalThreadLocalMap.remove(); &#125;&#125;public static void remove() &#123; Thread thread = Thread.currentThread(); if (thread instanceof FastThreadLocalThread) &#123; ((FastThreadLocalThread) thread).setThreadLocalMap(null); &#125; else &#123; slowThreadLocalMap.remove(); &#125;&#125; 首先获取当前线程map，然后获取 Set，将 Set 转成数组，遍历数组，调用 ftl 的 remove 方法。最后，删除线程中 的 map 属性。 总结ftl使用了单纯的数组操作来替代了tl的hash表操作，所以在高并发的情况下，ftl操作速度更快。 ftl直接根据index进行数组set，而tl需要先根据tl的hashcode计算数组下标（而ftl是直接获取），然后再根据线性探测法进行set操作，其间如果发生hash冲突且有无效的Entry时，还要进行Entry的清理和整理操作。最后不管是否冲突，都要进行一次log级别的Entry回收操作，所以慢了。 ftl相较于tl不好的地方就是内存占用大，不会重复利用已经被删除（用UNSET占位）的数组位置，只会一味增大，是典型的“空间换时间”的操作。]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty核心组件-nioEventLoop解析]]></title>
    <url>%2F2018%2F11%2F07%2Fnetty-nioEventLoop%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，NioEventLoop源码浅析，错误之处欢迎指正, 共同学习 NioEventLoop创建NioEventLoop 的继承图 new NioEventLoopGroup()[线程组，默认2*cpu] new ThreadPerTaskExecutor()[线程创建器]:线程执行器的作用是负责创建NioEventLoopGroup对应底层线程 创建NioEventLoop对象数组，for循环创建每个NioEventLoop,调用newChild()配置NioEventLoop核心参数 chooserFactory.newChooser()[线程选择器]:给每个新连接分配NioEventLoop线程 1.IO线程组的创建:NioEventLoopGroup nThreads: Group内产生nTreads个NioEventLoop对象，每个EventLoop都绑定一个线程, 默认值为cpu cores * 2 executor: 每个EventLoop在一次run方法调用的生命周期内都是绑定在一个Thread身上(EventLoop父类SingleThreadEventExecutor中的thread实例变量) 每个EventLoop都绑定了一个Thread selectorProvider: group内每一个EventLoop都要持有一个selector 1234567public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider());&#125;protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);&#125; 12345678910111213141516171819202122232425262728293031323334protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; // ...... if (executor == null) &#123; //创建线程执行器,线程执行器的作用是负责创建NioEventLoopGroup对应底层线程,// 默认使用线程工厂是 DefaultThreadFactory executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &#125; //getClass获取到当前类，当前类是一个NIOEventloop protected ThreadFactory newDefaultThreadFactory() &#123; return new DefaultThreadFactory(getClass()); &#125; children = new EventExecutor[nThreads]; //产生nTreads个NioEventLoop对象保存在children数组中 for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; //创建NioEventLoop对象数组,配置NioEventLoop核心参数 children[i] = newChild(executor, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type &#125; finally &#123; // ...... &#125; &#125; //线程选择器，给每个新连接分配NioEventLoop线程 chooser = chooserFactory.newChooser(children); // ......&#125; 2.ThreadPerTaskThread 通过构造ThreadFactory，每次执行任务创建线程然后运行线程 每次执行任务都会创建一个线程实体FastThreadLocalThread; 123protected Thread newThread(Runnable r, String name) &#123; return new FastThreadLocalThread(threadGroup, r, name); &#125; 3.创建NioEventLoop线程 newChild():创建NioEventLoop线程 保持线程执行器ThreadPerTaskExecutor 创建一个MpscQueue:taskQueue用于外部线程执行Netty任务的时候，如果判断不是在NioEventLoop对应线程里面执行，而直接塞到任务队列里面，由NioEventLoop对应线程执行，PlatformDependent.newMpscQueue(maxPendingTasks)创建MpscQueue保存异步任务队列; 创建一个selector:provider.openSelector()创建selector轮询初始化连接 12345678910111213141516171819202122232425262728293031323334protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); &#125;NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) &#123; throw new NullPointerException("selectorProvider"); &#125; if (strategy == null) &#123; throw new NullPointerException("selectStrategy"); &#125; provider = selectorProvider; selector = openSelector(); selectStrategy = strategy; &#125;protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ObjectUtil.checkNotNull(executor, "executor"); taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, "rejectedHandler"); &#125;protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) &#123; // This event loop never calls takeTask() return PlatformDependent.newMpscQueue(maxPendingTasks); &#125; 4.创建线程选择器 123456789101112131415//调用chooser.next()方法给新连接绑定对应的NioEventLooppublic EventExecutor next() &#123; return chooser.next(); &#125;public EventExecutorChooser newChooser(EventExecutor[] executors) &#123; //判断是否是2的幂 if (isPowerOfTwo(executors.length)) &#123; //优化：NioEventLoop索引下标=index++&amp;(length-1) return new PowerOfTowEventExecutorChooser(executors); &#125; else &#123; //普通：NioEventLoop索引下标=abs(index++%length) return new GenericEventExecutorChooser(executors); &#125;&#125; NioEventLoop启动1.NioEventLoop启动触发器: 服务端启动绑定端口 新连接接入通过chooser绑定一个NioEventLoop bind-&gt;execute(task)[入口]:调用bind()方法把具体绑定端口操作封装成Task,通过eventLoop()方法获取channelRegistered()注册绑定NioEventLoop执行NioEventLoop的execute()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. // 提交了一个绑定任务到 eventLoop // 在eventLoop 中对于新的任务的策略是： // 判断当前线程是否为该NioEventLoop所关联的线程，如果是，则添加任务到任务队列中 // 如果不是，则先启动线程，然后添加任务到任务队列中去 channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; // bind 的实现是在 AbstractChannel 里面 channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;);&#125;@Overridepublic void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException("task"); &#125; //判断当前调用execute()方法线程是否为NioEventLoop线程,通过startThread()方法创建启动线程 boolean inEventLoop = inEventLoop(); if (inEventLoop) &#123; addTask(task); &#125; else &#123; startThread(); addTask(task); if (isShutdown() &amp;&amp; removeTask(task)) &#123; reject(); &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125; 2.创建线程 ThreadPerTaskExecutor.execute():通过线程执行器ThreadPerTaskExecutor执行任务创建并启动FastThreadLocalThread线程 thread = Thread.currentThread():NioEventLoop保存当前创建FastThreadLocalThread线程,保存的目的是为了判断后续对NioEventLoop相关执行的线程是否为本身,如果不是则封装成Task扔到TaskQueue串行执行实现线程安全 NioEventLoop.run()[启动] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970private void startThread() &#123; // 这一个 if 判断就是为了在线程刚创建的时候起作用，也就是线程刚创建才能进到这里 if (STATE_UPDATER.get(this) == ST_NOT_STARTED) &#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; delayedTaskQueue.add(new ScheduledFutureTask&lt;Void&gt;(this, delayedTaskQueue, Executors.&lt;Void&gt;callable(new PurgeTask(), null), ScheduledFutureTask.deadlineNanos(SCHEDULE_PURGE_INTERVAL), -SCHEDULE_PURGE_INTERVAL)); // 线程启动了 thread.start(); &#125; &#125;&#125;private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn("Unexpected exception from an event executor: ", t); &#125; finally &#123; for (;;) &#123; int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this); if (oldState &gt;= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet( SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) &#123; break; &#125; &#125; // Check if confirmShutdown() was called at the end of the loop. if (success &amp;&amp; gracefulShutdownStartTime == 0) &#123; logger.error("Buggy " + EventExecutor.class.getSimpleName() + " implementation; " + SingleThreadEventExecutor.class.getSimpleName() + ".confirmShutdown() must be called " + "before run() implementation terminates."); &#125; try &#123; // Run all remaining tasks and shutdown hooks. for (;;) &#123; if (confirmShutdown()) &#123; break; &#125; &#125; &#125; finally &#123; try &#123; cleanup(); &#125; finally &#123; STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED); threadLock.release(); if (!taskQueue.isEmpty()) &#123; logger.warn( "An event executor terminated with " + "non-empty task queue (" + taskQueue.size() + ')'); &#125; terminationFuture.setSuccess(null); &#125; &#125; &#125; &#125; &#125;);&#125; NioEventLoop执行逻辑1.检测IO事件 首先执行delayNanos(currentTimeNanos), 这个方法是做什么的呢? 12345a)每个EventLoop都有一个延迟执行任务的队列b)delayNanos就是去这个延迟队列里面瞄一眼是否有非IO任务未执行, 如果没有则返回1秒钟c)如果很不幸延迟队列里面有任务, delayNanos的计算结果就等于这个task的deadlineNanos到来之前的这段时间, 也即是说select在这个task按预约到期执行的时候就返回了, 不会耽误这个task.d)如果最终计算出来的可以无忧无虑select的时间(selectDeadLineNanos - currentTimeNanos)小于500000L纳秒, 就认为这点时间是干不出啥大事业的, 还是selectNow一下直接返回吧, 以免耽误了延迟队列里预约好的task.e)如果大于500000L纳秒, 表示很乐观, 就以1000000L纳秒为时间片, 放肆的去执行阻塞的select了, 阻塞时间就是timeoutMillis(n * 1000000L纳秒时间片). 阻塞的select返回后,如果遇到以下几种情况则立即返回 1234a)如果select到了就绪连接(selectedKeys &gt; 0)b)被用户waken up了（wakeUp标识当前select操作是否为唤醒状态,每次select操作把wakeUp设置为false标识此次需要进行select操作并且是未唤醒状态;）c)任务队列(上面介绍的那个MPSC)来了一个任务d)延迟队列里面有个预约任务到期需要执行了 如果上面情况都不满足, 代表select返回0了, 并且还有时间继续愉快的玩耍 这其中有一个统计select次数的计数器selectCnt, select过多并且都返回0, 默认512就代表过多了, 这表示需要调用rebuildSelector()重建selector了, 达到512可能是触发了nio的epoll cpu 100%的bug, 避免下次JDK空轮询继续发生 rebuildSelector的实际工作就是:重新打开一个selector, 将原来的那个selector中已注册的所有channel重新注册到新的selector中, 并将老的selectionKey全部cancel掉, 最后将旧的selector关闭 重建selector后, 不死心的再selectNow一下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//select()[检查是否有io事件]:轮询注册到selector上面的io事件private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; break; &#125; if (Thread.interrupted()) &#123; selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; // ... &#125; catch (CancelledKeyException ignored) &#123;&#125;&#125; 2.处理外部线程扔到TaskQueue里面的任务 EventLoop的大致数据结构是：一个任务队列，一个延迟任务队列(schedule)。分别存放在普通任务队列MpscQueue和定时任务队列ScheduledTaskQueue 普通任务队列MpscQueue在创建NioEventLoop构造的,外部线程调用NioEventLoop的execute()方法使用addTask()方法向TaskQueue添加task; 定时任务队列ScheduledTaskQueue在调用NioEventLoop的schedule()方法将Callable任务封装成ScheduledFutureTask,判断是否为当前NioEventLoop发起的schedule还是外部线程发起的schedule,当前NioEventLoop发起的schedule直接添加定时任务,外部线程发起的schedule为了保证线程安全(ScheduledTaskQueue是PriorityQueue非线程安全)添加定时任务操作当做普通任务Task保证对于定时任务队列操作都在NioEventLoop实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected boolean runAllTasks(long timeoutNanos) &#123; //先是fetchFromScheduledTaskQueue, 将延迟任务队列中已到期的task拿到非IO任务的队列中,此队列即为上文中提到的MPSC队列. fetchFromScheduledTaskQueue(); //task即是从MPSC queue中弹出的任务 Runnable task = pollTask(); if (task == null) &#123; return false; &#125; //又是计算一个deadline final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos; long runTasks = 0; long lastExecutionTime; for (;;) &#123; try &#123; task.run(); &#125; catch (Throwable t) &#123; logger.warn("A task raised an exception.", t); &#125; runTasks ++; // Check timeout every 64 tasks because nanoTime() is relatively expensive. // XXX: Hard-coded value - will make it configurable if it is really a problem. //每执行64个任务就检查下时间, 如果到了deadline, 就退出, 没办法, IO任务是亲生的, 非IO任务是后妈生的, 资源肯定要先紧IO任务用.我们使用netty时也要注意, 不要产生大量耗时的非IO任务, 以免影响了IO任务 if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125; &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); break; &#125; &#125; this.lastExecutionTime = lastExecutionTime; return true;&#125;private boolean fetchFromScheduledTaskQueue() &#123; long nanoTime = AbstractScheduledEventExecutor.nanoTime(); Runnable scheduledTask = pollScheduledTask(nanoTime); //while循环获取定时任务队列(按照截止时间&amp;添加时间排序)截止时间为nanoTime的定时任务(截止时间最小)添加到普通任务队列,如果添加失败则重新将定时任务添加到定时任 while (scheduledTask != null) &#123; if (!taskQueue.offer(scheduledTask)) &#123; // No space left in the task queue add it back to the scheduledTaskQueue so we pick it up again. scheduledTaskQueue().add((ScheduledFutureTask&lt;?&gt;) scheduledTask); return false; &#125; scheduledTask = pollScheduledTask(nanoTime); &#125; return true;&#125; 优化select过后, 对读写等事件的处理优化 12345678910111213141516171819202122232425262728293031private void processSelectedKeysOptimized(SelectionKey[] selectedKeys) &#123; for (int i = 0;; i ++) &#123; final SelectionKey k = selectedKeys[i]; if (k == null) &#123; break; &#125; // 每次拿到一个之后SelectionKey立即释放array对这个key的强引用,help gc selectedKeys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (needsToSelectAgain) &#123; for (;;) &#123; if (selectedKeys[i] == null) &#123; break; &#125; selectedKeys[i] = null; i++; &#125; selectAgain(); selectedKeys = this.selectedKeys.flip(); i = -1; &#125; &#125;&#125; 使用数组替换HashSet123a.避免了HashSet的频繁自动扩容。b.屏蔽了remove、contains、iterator这些不需要的功能。c.对于selectedKeys, 最重要的操作是遍历全部元素，遍历数组效率高于遍历Hashset 1234567891011121314151617181920212223final class SelectedSelectionKeySet extends AbstractSet&lt;SelectionKey&gt; &#123; SelectionKey[] keys; int size; SelectedSelectionKeySet() &#123; keys = new SelectionKey[1024]; &#125; @Override public boolean add(SelectionKey o) &#123; if (o == null) &#123; return false; &#125; keys[size++] = o; if (size == keys.length) &#123; increaseCapacity(); &#125; return true; &#125;&#125; 总结用户代码创建Boss/Worker Group NioEventLoop创建,默认创建2倍cpu核数个NioEventLoop,每个NioEventLoop都有线程选择器chooser线程分配并且优化NioEventLoop个数,构造NioEventLoop创建Selector和定时任务队列,创建Selector通过反射使用数组实现替换Selector HashSet数据结构;NioEventLoop调用execute()方法启动FastThreadLocalThread线程,创建线程保存到成员变量;NioEventLoop执行逻辑在run()方法包括检测io事件、处理io事件、执行任务队列 问:默认情况下,Netty服务端起多少线程?何时启动?答:默认2cpu即Runtime.getRuntime().availableProcessors()2]线程,调用execute()方法判断当前是否在本线程,如果是在本线程说明线程已经启动,如果是在外部线程调用execute()方法,首先调用startThread()方法判断当前线程是否启动,未启动就启动此线程 问:Netty是如何解决JDK空轮询Bug?答:判断阻塞select操作是否阻塞timeoutMillis时间,未阻塞timeoutMillis时间表示可能触发JDK空轮询;判断触发JDK空轮询的次数是否超过阈值(默认512),超过阈值调用rebuildSelector()方法重建Selector把之前的Selector上面所有的Key重新移到新的Selector避免JDK空轮询的Bug 问:Netty如何保证异步串行无锁化?答:外部线程调用EventLoop或者Channel方法通过inEventLoop()方法判断得出是外部线程,所有操作封装成Task丢到普通任务队列MpscQueue,异步执行普通任务队列MpscQueue待执行任务]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty启动过程源码分析]]></title>
    <url>%2F2018%2F11%2F04%2Fnetty-startup-details%2F</url>
    <content type="text"><![CDATA[前言netty学习系列笔记总结，服务端启动流程源码浅析，错误之处欢迎指正, 共同学习 服务端启动代码示例123456789101112131415161718192021222324EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer;SocketChannel() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(new EchoServerHandler()); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); &#125; finally &#123; // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; 服务端Channel的创建 创建底层JDK Channel 封装JDK Channel 创建基本组件绑定Channel; 1.bind(port)[用户代码入口]:serverBootstrap.bind(port)1234567891011121314151617181920212223242526272829303132// Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); if (sslCtx != null) &#123; p.addLast(sslCtx.newHandler(ch.alloc())); &#125; //p.addLast(new LoggingHandler(LogLevel.INFO)); p.addLast(serverHandler); &#125; &#125;); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); &#125; finally &#123; // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; 2.initAndRegister()[初始化并注册]12345678910111213141516171819202122232425final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); init(channel); &#125; catch (Throwable t) &#123; if (channel != null) &#123; // channel can be null if newChannel crashed (eg SocketException("too many open files")) channel.unsafe().closeForcibly(); &#125; // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture; &#125; 3.newChannel()[创建服务端Channel] 通过serverBootstrap.channel()方法传入NioServerSocketChannel类,构造ReflectiveChannelFactory实例将NioServerSocketChannel类设置为反射类; channelFactory.newChannel()通过clazz.newInstance()调用反射类构造方法反射创建服务端Channel 4.channelFactory在哪里初始化？123456789101112131415161718192021222324252627//首先channelFactory在开篇示例代码b.channel(NioServerSocketChannel.class)中被设置成new ReflectiveChannelFactory&lt;C&gt;(NioServerSocketChannel.class)public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException("channelClass"); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass)); &#125;//factory通过反射创建一个NioServerSocketChannel对象public class ReflectiveChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; &#123; private final Class&lt;? extends T&gt; clazz; public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) &#123; if (clazz == null) &#123; throw new NullPointerException("clazz"); &#125; this.clazz = clazz; &#125;@Overridepublic T newChannel() &#123; try &#123; return clazz.newInstance(); &#125; catch (Throwable t) &#123; throw new ChannelException("Unable to create Channel from class " + clazz, t); &#125; &#125; 5.通过JDK底层创建socketChannel(服务端Channel创建过程) 反射创建服务端Channel:NioServerSocketChannel默认构造方法调用newSocket()使用provider.openServerSocketChannel()创建服务端Socket1234567891011121314private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider();public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER)); &#125;//在newSocket()中创建了开篇提到的监听套接字ServerSocketChannelprivate static ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; return provider.openServerSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException("Failed to open a server socket.", e); &#125;&#125; 6.NioServerSocketChannelConfig()[TCP参数配置类]:设置底层JDK Channel TCP参数配置12345//SelectionKey.OP_ACCEPT标志就是监听套接字所感兴趣的事件了(但是还没注册进去)public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &#125; 7.configureBlocking(false)[阻塞模式]:设置非阻塞模式123456789101112131415161718192021//NioServerSocketChannel父类构造函数protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123;//将ServerSocketChannel设置为非阻塞模式, NIO开始 ch.configureBlocking(false); &#125; catch (IOException e) &#123; try &#123; ch.close(); &#125; catch (IOException e2) &#123; if (logger.isWarnEnabled()) &#123; logger.warn( "Failed to close a partially initialized socket.", e2); &#125; &#125; throw new ChannelException("Failed to enter non-blocking mode.", e); &#125; &#125; 8.AbstractChannel()[创建id,unsafe,pipeline]123456789101112131415161718192021//继续父类构造方法1)构造一个unsafe绑定在serverChanel上,newUnsafe()由子类AbstractNioMessageChannel实现, unsafe的类型为NioMessageUnsafe,NioMessageUnsafe类型专为serverChanel服务, 专门处理accept连接2)创建用于NioServerSocketChannel的管道 boss pipeline protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline(); &#125;3)head和tail是pipeline的两头, head是outbound event的末尾, tail是inbound event的末尾.按照上行事件(inbound)顺序来看, 现在pipeline中的顺序是head--&gt;tailDefaultChannelPipeline(AbstractChannel channel) &#123; this.channel = channel; tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; 服务端Channel的初始化 init()[初始化服务端channel,初始化入口] set ChildOptions,ChildAttrs:提供给通过服务端Channel创建的新连接Channel,每次accept新连接都配置用户自定义的两个属性配置 config handler[配置服务端Pipeline] add ServerBootstrapAcceptor[添加连接器]:提供给accept接入的新连接分配NIO线程 保存用户自定义基本属性,通过配置属性创建连接接入器,连接接入器每次accept新连接使用自定义属性配置新连接 1234567891011121314151617181920212223242526//1.设置NioServerSocketChannel的options和attrs.//2.预先复制好将来要设置给NioSocketChannel的options和attrs.//3.init做的第二件事就是在boss pipeline添加一个ChannelInitializer,//4.那么现在pipeline中的顺序变成了head--&gt;ChannelInitializer--&gt;tail(注意head和tail永远在两头, addLast方法对他俩不起作用)void init(Channel channel) throws Exception &#123; // ...... p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;); &#125; 注册Selector将底层JDK Channel注册到事件轮询器Selector上面,并把服务端Channel作为Attachment绑定在对应底层JDK Channel AbstractChannel.register(channel)[注册Selector入口] doRegister() 调用JDK底层注册:JDK Channel注册Selector调用javaChannel().register(eventLoop().selector, 0, this),将服务端Channel通过Attachment绑定到Selector invokeHandlerAddedIfNeeded():事件回调,触发Handler fireChannelRegistered()[传播事件] 12345678910111213141516171819202122public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // ......//赋值操作，后续所有的IO操作交给eventLoop处理 AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123;//实际的注册 register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; // ...... &#125; &#125; &#125; register0()1234567891011121314151617private void register0(ChannelPromise promise) &#123; try &#123; // ......1.在doRegister()之后还调用了pipeline.fireChannelRegistered(), 触发ChannelInitializer#channelRegistered()方法. doRegister(); // ...... safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (firstRegistration &amp;&amp; isActive()) &#123; pipeline.fireChannelActive(); &#125; &#125; catch (Throwable t) &#123; // ...... &#125;&#125; doRegister()123456789101112//javaChannel().register(), 这里先把interestOps注册为0protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(((NioEventLoop) eventLoop().unwrap()).selector, 0, this); return; &#125; catch (CancelledKeyException e) &#123; // ...... &#125; &#125;&#125; 服务端口的绑定 AbstractUnsafe.bind()[端口绑定] doBind():javaChannel().bind()[JDK动态绑定] pipeline.fireChannelActive()[传播事件]:HeadContext.readIfIsAutoRead()将注册Selector的事件重新绑定为OP_ACCEPT事件,有新连接接入Selector轮询到OP_ACCEPT事件最终将连接交给Netty处理 绑定OP_ACCEPT事件:当端口完成绑定触发active事件,active事件最终调用channel的read事件,read对于服务器来说可以读新连接 1234567891011121314151617181920212223242526272829303132333435private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; if (regFuture.isDone()) &#123; // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); &#125; else &#123; // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125; &#125; AbstractChannel 123456789101112131415161718192021222324252627282930313233343536public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; // ...... boolean wasActive = isActive(); try &#123; doBind(localAddress); &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); closeIfClosed(); return; &#125; if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123; @Override public void run() &#123; //JDK底层绑定成功，调用fireChannelActive传播 pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise); &#125;//上面的doBind()调用的是NioServerSocketChannel的实现:protected void doBind(SocketAddress localAddress) throws Exception &#123; javaChannel().socket().bind(localAddress, config.getBacklog());&#125;第二个参数backlog的重要性:在linux内核中TCP握手过程总共会有两个队列:1)一个俗称半连接队列, 装着那些握手一半的连接(syn queue)2)另一个是装着那些握手成功但是还没有被应用层accept的连接的队列(accept queue)backlog的大小跟这两个队列的容量之和息息相关, backlog的值也不是你设置多少它就是多少的扩展：对于TCP连接的ESTABLISHED状态, 并不需要应用层accept, 只要在accept queue里就已经变成状态ESTABLISHED NioServerSocketChannel 1234567protected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.javaVersion() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125; &#125; AbstractNioChannel端口绑定成功，告诉selector需要关心accept事件 1234567891011121314protected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125; &#125; 总结Netty服务端启动: 创建服务端Channel:创建底层JDK Channel,封装JDK Channel,创建基本组件绑定Channel; 初始化服务端Channel:设置Channel基本属性,添加逻辑处理器; 注册Selector:将底层JDK Channel注册到事件轮询器Selector上面,并把服务端Channel作为Attachment绑定在对应底层JDK Channel; 端口绑定:实现本地端口监听,绑定成功重新向Selector注册OP_ACCEPT事件接收新连接 服务端Socket在哪里初始化?反射创建服务端Channel:NioServerSocketChannel默认构造方法调用newSocket()使用provider.openServerSocketChannel()创建服务端Socket 在哪里accept连接?端口绑定:Pipeline调用fireChannelActive()传播active事件,HeadContext使用readIfIsAutoRead()重新绑定OP_ACCEPT事件,新连接接入Selector轮询到OP_ACCEPT事件处理]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[闪电侠netty小册阅读总结]]></title>
    <url>%2F2018%2F11%2F01%2Fnetty-study-review%2F</url>
    <content type="text"><![CDATA[前言Netty 入门与实战：仿写微信 IM 即时通讯系统阅读总结 编程模型1.传统IO编程 每个连接创建成功之后都需要一个线程来维护，每个线程包含一个 while 死循环，那么 1w 个连接对应 1w 个线程，继而 1w 个 while 死循环 12345* 线程资源受限：线程是操作系统中非常宝贵的资源，同一时刻有大量的线程处于阻塞状态是非常严重的资源浪费，操作系统耗不起* 线程切换效率低下：单机 CPU 核数固定，线程爆炸之后操作系统频繁进行线程切换，应用性能急剧下降* 数据读写是以字节流为单位 2.NIO编程模型 NIO 编程模型中，新来一个连接不再创建一个新的线程，而是可以把这条连接直接绑定到某个固定的线程，然后这条连接所有的读写都由这个线程来负责 1234567* NIO 模型中通常会有两个线程，每个线程绑定一个轮询器 selector ，serverSelector负责轮询是否有新的连接，clientSelector负责轮询连接是否有数据可读* 服务端监测到新的连接之后，不再创建一个新的线程，而是直接将新连接绑定到clientSelector上，这样就不用 IO 模型中 1w 个 while 循环在死等* clientSelector被一个 while 死循环包裹着，如果在某一时刻有多条连接有数据可读，那么通过 clientSelector.select(1)方法可以轮询出来，进而批量处理* 数据的读写面向 Buffer Netty编程1.服务端启动流程 1234567891011* 创建一个引导类，然后给他指定线程模型，IO模型，连接读写处理逻辑，绑定端口之后，服务端就启动起来了* 通过给 bind 方法添加监听器，用以实现自动绑定递增端口* attr 方法，为每条连接增加属性，相当于给NioServerSocketChannel维护一个map* handler()用于指定在服务端启动过程中的一些逻辑* childOption 方法，用于指定处理新连接数据的读写处理逻辑。设置一些TCP底层相关的属性。* 关于 TCP连接的优化，SO_KEEPALIVE 底层心跳，TCP_NODELAY （是否开启Nagle算法）延迟发送，SO_BACKLOG （临时存放已完成三次握手的请求的队列的最大长度）等待队列 2.客户端启动流程1234567* 与服务端启动类似。调用 connect 方法进行连接，返回Future，异步监听是否连接成功。可以增加* 重试不在主线程，定时任务是调用 bootstrap.config().group().schedule() * 重连优化：实现指数退避重连逻辑，位运算。* option() 方法CONNECT_TIMEOUT_MILLIS 属性 3.客户端与服务端双向通信1234567* initChannel() 方法添加逻辑处理器* 调用 ch.pipeline().addLast() 方法 添加一个逻辑处理器。其中ch.pipeline() 返回的是和这条连接相关的逻辑处理链，采用了责任链模式* 建立成功之后，会调用channelActive()方法,读取数据用channelRead()方法* 客户端与服务端交互的二进制数据载体为 ByteBuf，ByteBuf 通过连接的内存管理器创建，字节数据填充到 ByteBuf 之后才能写到对端 4.ByteBuf123* 基于读写指针和容量、最大可扩容容量，衍生出一系列的读写方法* 多个 ByteBuf 可以引用同一段内存，这段内存可以是堆内也可以是堆外的。通过引用计数来控制内存的释放，遵循谁 retain() 谁 release() 的原则 5.客户端与服务端通信协议编解码。扩展阅读RPC 消息协议1234567自定义通信协议* 4字节魔数校验* 版本号，预留字段，用于协议升级* 序列化算法，表示序列化方式* 1字节指令，每一种指令都会有相应的处理逻辑* 4字节数据长度，用于拆包粘包* N字节数据内容 6.实现客户端与服务端收发消息12* channel 的 attr() 绑定属性来设置某些状态，获取某些状态，不需要额外的 map 来维持。* hannel.attr(Attributes.LOGIN).set(true)绑定登陆标识 7.pipeline 与 channelHandler12* ChannelPipeline 是一个双向链表结构，他和 Channel 之间是一对一的关系。* ChannelPipeline 里面每个节点都是一个 ChannelHandlerContext 对象，这个对象能够拿到和 Channel 相关的所有的上下文信息，然后这个对象包着一个重要的对象，那就是逻辑处理器ChannelHandler。 8.构建客户端与服务端 pipeline123* 基于 SimpleChannelInboundHandler，不再需要强转，不再有冗长乏味的 if else 逻辑，不需要手动传递对象。(对比ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter理解)* 基于 MessageToByteEncoder，我们可以实现自定义编码，而不用关心 ByteBuf 的创建，内存释放。 9.拆包粘包理论与解决方案12345678* 1. 固定长度的拆包器 FixedLengthFrameDecoder 2. 行拆包器 LineBasedFrameDecoder 3. 分隔符拆包器 DelimiterBasedFrameDecoder 4. 基于长度域拆包器 LengthFieldBasedFrameDecoder* LengthFieldBasedFrameDecoder是最通用的一种拆包器，只要你的自定义协议中包含长度域字段，均可以使用这个拆包器来实现应用层拆包。* 扩展LengthFieldBasedFrameDecoder 通过魔数校验尽早屏蔽非本协议的客户端 10.channelHandler 的生命周期1234567* ChannelHandler 启动时回调方法的执行顺序为：handlerAdded() -&gt; channelRegistered() -&gt; channelActive() -&gt; channelRead() -&gt; channelReadComplete()* ChannelHandler 关闭时回调方法的执行顺序为：channelInactive() -&gt; channelUnregistered() -&gt; handlerRemoved()* channelActive() 与 channelInActive()统计单机的增减连接数* channelReadComplete()调用ctx.channel().flush() 批量刷新提升性能 11.使用 channelHandler 的热插拔实现客户端身份校验12345* 如果有很多业务逻辑的 handler 都要进行某些相同的操作，我们完全可以抽取出一个 handler 来单独处理* ctx.pipeline().remove(this)移除自身。通过 ChannelHandler 的热插拔机制来实现动态删除逻辑* handlerRemoved()通知移除事件 12.客户端互聊原理与实现1234567* channel.attr(Attributes.SESSION).set(session) 绑定session* channel.attr(Attributes.SESSION).set(null) 删除 session* channel.attr(Attributes.SESSION).get() 拿到 session* 通过Map实例化userId -&gt; channel 的映射 13.群聊的发起与通知12* ChannelGroup channelGroup = new DefaultChannelGroup(ctx.executor());* ChannelGroup：它可以把多个 chanel 的操作聚合在一起，可以往它里面添加删除 channel，可以进行 channel 的批量读写，关闭等操作 性能优化篇1.Netty性能优化12345678910111213* 共享 handler 1.无状态handler直接单例模式，提高效率，也避免了创建很多小的对象。 2.加上注解标识@ChannelHandler.Sharable，表明该 handler 是可以多个 channel 共享的* 压缩 handler - 合并编解码器——&gt;MessageToMessageCodec* 缩短事件传播路径 1.压缩 handler - 合并平行 handler。定义一个通用handler，依然是可以写成一个单例模式的类。内部维护 map，存放指令到各个指令处理器的映射，回调时通过指令找到具体的 handler 2.更改事件传播源。ctx.writeAndFlush()对比ctx.channel().writeAndFlush() * 减少阻塞主线程的操作 1.对于数据库或者网络等一些耗时操作，丢到业务线程池处理 2.计算耗时，使用回调 Future 2.心跳与空闲检测123* 空闲检测 IdleStateHandler ，连接假死之后会回调 channelIdle() 方法* 定时心跳 ctx.executor().scheduleAtFixedRate* 通常空闲检测时间要比发送心跳的时间的两倍要长一些，为了排除偶发的公网抖动，防止误判。]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式总结]]></title>
    <url>%2F2018%2F10%2F29%2Fdesign-mode-review%2F</url>
    <content type="text"><![CDATA[介绍设计模式总结项目地址：https://github.com/lishq/java-pattern-demo 六大原则单一职责原则 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单的多； 提高类的可读性，提高系统的可维护性； 变更引起的风险降低，变更是必然的，如果单一职责原则遵守的好，当修改一个功能时，可以显著降低对其他功能的影响。 里氏替换原则 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。 依赖倒置原则 低层模块尽量都要有抽象类或接口，或者两者都有。 变量的声明类型尽量是抽象类或接口。 使用继承时遵循里氏替换原则。 接口隔离原则 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。 为依赖接口的类定制服务，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。 提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。 迪米特法则 一个对象应该对其他对象保持最少的了解。 如果类与类的关系越紧密，耦合度越大，当一个类发生改变时，对另一个类的影响也越大，尽量降低类之间的耦合。 迪米特法则的初衷是降低类之间的耦合，由于每个类都减少了不必要的依赖，因此的确可以降低耦合关系，可以避免与非直接类的通信，但是通信需要通过中介类，会产生大量的中介类，导致系统变复杂。所以设计时，既要做到结构清晰，又要高内聚，低耦合。 开闭原则 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 只要我们对前面5项原则遵守的好了，设计出的软件自然是符合开闭原则的 一句话概括:单一职责原则告诉我们实现类要职责单一；里氏替换原则告诉我们不要破坏继承体系；依赖倒置原则告诉我们要面向接口编程；接口隔离原则告诉我们在设计接口的时候要精简单一；迪米特法则告诉我们要降低耦合。而开闭原则是总纲，他告诉我们要对扩展开放，对修改关闭。 设计模式分类创建型模式 简单工厂模式（Simple Factory） 工厂方法模式（Factory Method） 抽象工厂模式（Abstract Factory） 创建者模式（Builder） 原型模式（Prototype） 单例模式（Singleton） 因为对象的创建会消耗掉系统的很多资源，所以单独对对象的创建进行研究，从而能够高效地创建对象就是创建型模式要探讨的问题。创建型模式(Creational Pattern)对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。为了使软件的结构更加清晰，外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则。创建型模式在创建什么(What)，由谁创建(Who)，何时创建(When)等方面都为软件设计者提供了尽可能大的灵活性。创建型模式隐藏了类的实例的创建细节，通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的。 结构型模式 外观模式/门面模式（Facade门面模式） 适配器模式（Adapter） 代理模式（Proxy） 装饰模式（Decorator） 桥梁模式/桥接模式（Bridge） 组合模式（Composite） 享元模式（Flyweight） 在解决了对象的创建问题之后，对象的组成以及对象之间的依赖关系就成了开发人员关注的焦点，因为如何设计对象的结构、继承和依赖关系会影响到后续程序的维护性、代码的健壮性、耦合性等。对象结构的设计很容易体现出设计人员水平的高低结构型模式(Structural Pattern)描述如何将类或者对象结合在一起形成更大的结构，就像搭积木，可以通过简单积木的组合形成复杂的、功能更为强大的结构。类结构型模式关心类的组合，由多个类可以组合成一个更大的系统，在类结构型模式中一般只存在继承关系和实现关系。对象结构型模式关心类与对象的组合，通过关联关系使得在一个类中定义另一个类的实例对象，然后通过该对象调用其方法。 根据“合成复用原则”，在系统中尽量使用关联关系来替代继承关系，因此大部分结构型模式都是对象结构型模式。 行为模式 模板方法模式（Template Method） 观察者模式（Observer） 状态模式（State） 策略模式（Strategy） 职责链模式（Chain of Responsibility） 命令模式（Command） 访问者模式（Visitor） 调停者模式（Mediator） 备忘录模式（Memento） 迭代器模式（Iterator） 解释器模式（Interpreter） 在对象的结构和对象的创建问题都解决了之后，就剩下对象的行为问题了，如果对象的行为设计的好，那么对象的行为就会更清晰，它们之间的协作效率就会提高行为型模式(Behavioral Pattern)是对在不同的对象之间划分责任和算法的抽象化。行为型模式不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。通过行为型模式，可以更加清晰地划分类与对象的职责，并研究系统在运行时实例对象之间的交互。在系统运行时，对象并不是孤立的，它们可以通过相互通信与协作完成某些复杂功能，一个对象在运行时也将影响到其他对象的运行。类行为型模式：类的行为型模式使用继承关系在几个类之间分配行为，类行为型模式主要通过多态等方式来分配父类与子类的职责。对象行为型模式：对象的行为型模式则使用对象的聚合关联关系来分配行为，对象行为型模式主要是通过对象关联等方式来分配两个或多个类的职责。根据“合成复用原则”，系统中要尽量使用关联关系来取代继承关系，因此大部分行为型设计模式都属于对象行为型设计模式。 参考：https://www.uml.org.cn/sjms/201211023.asp《设计模式》《设计模式之禅》《大话设计模式》]]></content>
      <tags>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[框架设计原则]]></title>
    <url>%2F2018%2F10%2F27%2Fdesign-framework-principles%2F</url>
    <content type="text"><![CDATA[介绍好的架构和设计可以增加系统健壮性同时也便于维护。面向对象的设计过程中，需要先进行泛化，抽象。然后对具体的对象进行窄化，细化。了解框架设计思想不但可以开阔思维，增加阅读开源项目源码的能力。更能提升一个程序员对程序的抽象和管理能力。以下设计理念来源于Dubbo作者梁飞的总结，很有参考学习意义。总结整理以供学习 大纲 模块分包原则 框架扩展原则 领域划分原则 接口分离原则 组件协作原则 功能演进原则 模块分包原则 对业务进行抽象建模，业务数据与业务逻辑解耦，平台和产品解耦，系统各部件解耦。模块、组件高内聚，低耦合。 稳定度：各模块被依赖的包应该保持稳定，或者说，被依赖者应当比依赖者稳定，且不能成环状依赖。如果不稳定，将会影响其他的包。 抽象度，越抽象，越稳定。越具体，越容易变化。 框架扩展原则 微核插件式，平等对待第三方。比如Eclipse的微核是OSGi， Spring的微核是BeanFactory，Maven的微核是Plexus，通常核心是不应该带有功能性的，而是一个生命周期和集成容器，这样各功能可以通过相同的方式交互及扩展，并且任何功能都可以被替换， 如果做不到微核，至少要平等对待第三方。 外置生命周期，尽量引用外部对象的实例，而不类元。尽量使用IOC注入，减少静态工厂方法调用也就是说，框架只负责管理对象，对象的出生和死亡不由框架负责。即，用户应将实例注册到框架中。以服务、数据为中心，构建服务化、组件化架构，具备灵活，按需组合的能力。但Spring就是负责管理对象的生命周期的框架，这个我认为还是在于框架对于自身的定位问题。要灵活对待。 最少化概念模型，这个其实是一种优化，保持尽可能少的概念，有助于理解。另外，各接口都使用一致的概念模型，能相互指引，并减少模型转换 。 一致化数据模型：例如 URL 这种对象，就是一致化数据模型，拒绝使用 String 拼接，解析。 领域划分原则 任何框架或组件，总会有核心领域模型，比如： Spring的Bean，Struts的Action，Dubbo的Service等等。这个核心领域模型及其组成部分称为实体域，它代表着我们要操作的目标本身，实体域通常是线程安的，不管是通过不变类，同步状态，或复制的方式。服务域也就是行为域，它是组件的功能集，同时也负责实体域和会话域的生命周期管理，比如Spring的ApplicationContext，Dubbo的ServiceManager等。 领域模型划分优势： 结构清晰，可直接套用 充血模型，实体域带行为。 可变与不可变状态分离，可变状态集中 所有领域线程安全，不需要加锁 只有保证领域模型线程安全性设计，可变和不可变状态分离，可变状态集中。才能实现无锁编程。同时，设计一定要轻量。否则，对 GC 来说，将是很大的压力。 通常实体域都是只读的，即不变状态。会话域都是可变状态。 服务域无状态，天生线程安全，只需单一实例运行。实体域属性只读，或整个类应用替换，线程安全。会话域只在线程栈中使用，没有竞争，线程安全。 接口分离原则 接口分离，单一职责原则的实现。 API 面向用户，SPI 面向开发者。两者必须分离。 声明式 API 和过程式 SPI API 可配置，一定可编程 区分命令和查询，例如，不应该有 updateAndGet 这个方法（不包括原子类），应该分成 2 个方法，保证 get 方法幂等。 对称性接口：有 get 方法，就应该有 set 方法，有 add 就由 remove，称之为对称性和完备性。这样用户能自行推导出接口。 兼容性：如果接口加方法，应该是增加子接口的方式。 组件协作原则 首先Dubbo 是管道式设计。一个 Invoker 贯通整个流程，比如Netty的EventLoop、pipeline 关于派发，比如Spring 的 dispatchServlet Dubbo 暴露、引用、调用事件，都预留了监听器。 关键路径，即在管道使用责任连模式进行拦截，保证每个拦截器职责单一。 非关键路径，采用后置事件派发，不能影响主流程运行。 防御性编程。 防止空指针和下标越界，我认为这类问题是最不应该出现的，每敲一行代码都要考虑到 保证线程安全性和可见性，防止高并发下出现莫名其妙的问题 尽早失败和前置断言，这样报错后，其实内部状态可能已经混乱 分离可靠操作和不可靠操作，比如，写入一个线程安全的Map，可以认为是可靠的，而写入数据库等，可以认为是不可靠的，不可靠操作要增加容错 异常防御，但不忽略异常 缩小可变域和尽量final 降低修改时的误解性，不埋雷 一个原则就是永远不要区分null引用和empty值。 提高代码的可测性 功能演进原则 开闭原则，微核心加插件机制。 软件质量的下降，来源于修改。 每个扩展点只封装一个变化因子，最大化复用。 全管道式设计，框架自身逻辑，均使用截面拦截实现。 加功能的姿势：应该是增量式，而不是扩充式，即不在原有基础上修改，而是新增加功能。 关于高阶：顶层接口尽量抽象，且不能依赖底层实现。这样，当底层实现变化时，高层无需变化。 总结 参考：http://javatar.iteye.com/blog/706098]]></content>
      <tags>
        <tag>Design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis的集群模式]]></title>
    <url>%2F2018%2F10%2F16%2Fredis-cluster%2F</url>
    <content type="text"><![CDATA[介绍Redis 集群是一个提供在多个Redis间节点间共享数据的程序集Redis 集群方案： Codis、Cluster（去中心化） cluster 集群 自动分割数据到不同的节点上 整个集群的部分节点失败或者不可达的情况下能够继续处理命令。 不支持处理多个keys的命令,因为这需要在不同的节点间移动数据 在执行故障转移期间， 集群可能会丢失写命令。如图所示，该集群有三个 Redis 节点组成，每个节点负责整个集群的一部分数据，每个节点负责的数据多少可能不一样。这三个节点相互连接组成一个对等的集群，它们之间通过一种特殊的二进制协议相互交互集群信息。 槽位定位算法Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 Cluster 还允许用户强制某个 key 挂在特定槽位上 这种设计对增删节点友好，不会停止服务。 增加节点时：将部分节点数据移动到新加的节点；删除节点时：将需要删除的节点数据移动到其他节点上。 容错Redis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发生故障时，集群将完全处于不可用状态。不过 Redis 也提供了一个参数cluster-require-full-coverage可以允许部分节点故障，其它节点还可以继续提供对外访问。 Redis 一致性保证Redis 并不能保证数据的强一致性：1.集群使用了异步复制2.集群出现了网络抖动123Redis 集群的一个重要的配置选项cluster-node-timeoutcluster-slave-validity-factor cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。 cluster-slave-validity-factor作为倍乘系数来放大这个超时时间来宽松容错的紧急程度。如果这个系数为零，那么主从切换是不会抗拒网络抖动的。如果这个系数大于 1，它就成了主从切换的松弛系数 可能下线与确定下线因为 Redis Cluster 是去中心化的，一个节点认为某个节点失联了并不代表所有的节点都认为它失联了。所以集群还得经过一次协商的过程，只有当大多数节点都认定了某个节点失联了，集群才认为该节点需要进行主从切换来容错。 Redis 集群节点采用 Gossip协议来广播自己的状态以及自己对整个集群认知的改变 参考：https://redis.cn/topics/sentinel.htmlhttps://redis.cn/topics/cluster-spec.html《redis设计与实现（第二版）》]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis的sentinel模式]]></title>
    <url>%2F2018%2F10%2F16%2Fredis-sentinel%2F</url>
    <content type="text"><![CDATA[介绍 Redis Sentinel 是一个分布式系统，用于管理多个 Redis 服务器（instance），本质上只是一个运行在特殊模式下的 Redis 服务器，提供高可用性(HA)解决方案 Sentinel 监控： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 消息丢失 Redis 主从采用异步复制 Sentinel 无法保证消息完全不丢失，可以通过限制主从延迟过大，尽可能保证消息少丢失。 12min-slaves-to-write 1min-slaves-max-lag 10 第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。第二个参数单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。 Sentinel作为服务器的命令表123456789struct redisCommand sentinelcmds[] = &#123; &#123;"ping",pingCommand,1,"",0,NULL,0,0,0,0,0&#125;, &#123;"sentinel",sentinelCommand,-2,"",0,NULL,0,0,0,0,0&#125;, &#123;"subscribe",subscribeCommand,-2,"",0,NULL,0,0,0,0,0&#125;, &#123;"unsubscribe",unsubscribeCommand,-1,"",0,NULL,0,0,0,0,0&#125;, &#123;"psubscribe",psubscribeCommand,-2,"",0,NULL,0,0,0,0,0&#125;, &#123;"punsubscribe",punsubscribeCommand,-1,"",0,NULL,0,0,0,0,0&#125;, &#123;"info",sentinelInfoCommand,-1,"",0,NULL,0,0,0,0,0&#125;&#125;; 自动发现当Sentinel发现主服务器有新的从服务器出现时，Sentinel除了会为这个新的从服务器创建相应的实例结构之外，Sentinel还会创建连接到从服务器的命令连接和订阅服务 无需设置sentinel对应其他sentinel的地址，通过发布，订阅功能来自动发现正在监视相同主服务器的其他sentinel，这一功能是通过想频道 sentinel:hello发送信息来实现的。 默认情况下，Sentinel会以每两秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器发送命令，包含sentinel的ip，端口，pid 每个sentinel都会订阅被他监视服务的 sentinel:hello频道，如果有新的sentinel加入，更新自己的sentinel列表 对于监视同一个服务器的多个Sentinel来说，一个Sentinel发送的信息会被其它Sentinel接收到，用于更新自己的sentinel列表 添加新的sentinel时，先检查列表中是否已存在相同id或者相同地址的sentinel，如有，先移除 Sentinel之间不会创建订阅连接 主观/客观下线状态检查 主观下线（SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断。 客观下线（ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断， 并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后， 得出的服务器下线判断。 服务器对 PING 命令的有效回复包含： +PONG -LOADING -MASTERDOWN 对于主服务器：主观下线状态切换到客观下线状态，使用Gossip协议，在sentinel给定的时间内，从sentinel收集到了足够数量的主服务器下线报告，状态改成客观下线。 客观下线只适合主服务器。 其他类型的redis实例，sentinel判断下线无需协商。 每个 Sentinel 都需要定期执行的任务 每个 Sentinel 以每秒钟一次的频率向它所知的主从服务器以及其他 Sentinel 实例发送一个 PING 命令。 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 那么这个实例会被 Sentinel 标记为主观下线。 如果一个主服务器被标记为主观下线， 那么正在监视这个主服务器的所有 Sentinel 要以每秒一次的频率确认主服务器的确进入了主观下线状态。 如果一个主服务器被标记为主观下线， 并且有足够数量的 Sentinel （配置文件指定的数量）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线。 主服务器被 Sentinel 标记为客观下线时， Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。 当没有足够数量的 Sentinel 同意主服务器已经下线， 主服务器的客观下线状态就会被移除。 当主服务器重新向 Sentinel 的 PING 命令返回有效回复时， 主服务器的主管下线状态就会被移除。 故障转移 在已下线主服务器的所有从服务器里面，挑选出一个从服务器，并将其转换为主服务器。 让已下线主服务器属下的所有从服务器改为复制新的主服务器 将已下线主服务器设置为新的主服务器的从服务器，当这个旧的主服务器重新上线时，它就会成为新的主服务器的从服务器 新的主服务器是怎么挑选出来的领头Sentinel会将已下线主服务器的所有从服务器保存到一个列表里面 删除处于下线或者断线状态的从服务器 删除最近 5s 内没有回复过领头Sentinel的INFO命令的从服务器 删除与已下线主服务器连接断开超过down-after-milliseconds * 10 ms 的从服务器 剩下的，选择优先级最高、复制偏移量最大的从服务器，如果复制偏移量不可用，选择运行ID最小的从服务器升级为主服务器 参考：https://redis.cn/topics/sentinel.html《redis设计与实现（第二版）》]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构之『跳跃列表』]]></title>
    <url>%2F2018%2F10%2F15%2Fredis-data-structure-skiplist%2F</url>
    <content type="text"><![CDATA[介绍跳跃表在 Redis 中不如链表和字典等数据结构的应用广泛，只有两个地方用到。一是实现有序集合键，另一个是在集群节点中用作内部数据结构。 项目地址：https://github.com/lishq/redis-base-demo Redis 的 zset 是一个复合结构 需要hash存储value和score的关系 需要提供按照 score 来排序的功能 需要能够指定 score 的范围来获取 value 列表的功能，「跳跃列表」 数据结构 Redis 的跳跃表共有 64 层 最底层双向链表，保证数据存储，有序排列 不同的 kv 层高可能不一样，层数越高的 kv 越少 每一个层元素的遍历都是从 kv header 出发 123456789101112struct zslnode &#123; string value; double score; zslnode*[] forwards; // 多层连接指针 zslnode* backward; // 回溯指针&#125;struct zsl &#123; zslnode* header; // 跳跃列表头指针 int maxLevel; // 跳跃列表当前的最高层 map&lt;string, zslnode*&gt; ht; // hash 结构的所有键值对&#125; 查找过程 二分查找 逐层下降，搜索路径 随机层数 对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数。直观上期望的目标是 50% 的 Level1，25% 的 Level2。 跳跃列表会记录一下当前的最高层数maxLevel，遍历时从这个 maxLevel 开始遍历 插入过程 查找到位置，如果score相等判断value 创建节点，分配随机层数 将搜索路径上的节点和新节点通过前后指针串起来 删除过程 类似插入过程 同时还要注意更新一下最高层数maxLevel 排名计算 每一个 forward 指针都增加了 span 属性 将「搜索路径」上的经过的所有节点的跨度 span 值进行叠加就可以算出元素的最终 rank 值]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构之『快速列表』]]></title>
    <url>%2F2018%2F10%2F15%2Fredis-data-structure-quicklist%2F</url>
    <content type="text"><![CDATA[介绍Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是元素少时用 ziplist，元素多时用 linkedlist。 项目地址：https://github.com/lishq/redis-base-demo linkedlist123456789101112// 链表的节点struct listNode&lt;T&gt; &#123; listNode* prev; listNode* next; T value;&#125;// 链表struct list &#123; listNode *head; listNode *tail; long length;&#125; 考虑到链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。 1234127.0.0.1:6379&gt; rpush lishq:test redis mongodb spark(integer) 3127.0.0.1:6379&gt; debug object lishq:testValue at:0x7f3bd7e285b0 refcount:1 encoding:quicklist serializedlength:36 lru:12861819 lru_seconds_idle:22 ql_nodes:1 ql_avg_node:3.00 ql_ziplist_max:-2 ql_compressed:0 ql_uncompressed_size:34 quicklistquicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。 为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度。 压缩深度 quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数list-max-ziplist-size决定。 quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数list-compress-depth决定。 为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构之『压缩列表』]]></title>
    <url>%2F2018%2F10%2F15%2Fredis-data-structure-ziplist%2F</url>
    <content type="text"><![CDATA[介绍Redis 为了节约内存空间使用，zset 和 hash 容器对象在元素个数较少的时候，采用压缩列表 (ziplist) 进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。 项目地址：https://github.com/lishq/redis-base-demo ziplist1234567struct ziplist&lt;T&gt; &#123; int32 zlbytes; // 整个压缩列表占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表，挨个挨个紧凑存储 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF&#125; 压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。 entry 块随着容纳的元素类型不同，也会有不一样的结构。12345struct entry &#123; int&lt;var&gt; prevlen; // 前一个 entry 的字节长度 int&lt;var&gt; encoding; // 元素类型编码 optional byte[] content; // 元素内容&#125; 它的 prevlen 字段表示前一个 entry 的字节长度，当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。 它是一个变长的整数，如果entry.content小于254字节，prevlen是1个字节，内容大于254则prevlen是5个字节。所以list中内容变化可能导致级联更新的问题。 当字符串长度比较长的时候，5 个字节只占用不到(5/(254+5))&lt;2%的空间。 增加元素因为 ziplist 都是紧凑存储，没有冗余空间 (对比一下 Redis 的字符串结构)。意味着插入一个新的元素就需要调用 realloc 扩展内存。取决于内存分配器算法和当前的 ziplist 内存大小，realloc 可能会重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址，也可能在原有的地址上进行扩展，这时就不需要进行旧内容的内存拷贝。如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗。所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。 连锁更新 如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作。 如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，其中big 节点的长度大于等于 254 字节， 而 small 节点的长度小于 254 字节， 那么当我们将 small 节点从压缩列表中删除之后， 也会导致后续所有 entry 的级联更新。 IntSet 小整数集合当 set 集合容纳的元素都是整数并且元素个数较小时，Redis 会使用 intset 来存储结合元素。intset 是紧凑的数组结构，同时支持 16 位、32 位和 64 位整数。12345struct intset&lt;T&gt; &#123; int32 encoding; // 决定整数位宽是 16 位、32 位还是 64 位 int32 length; // 元素个数 int&lt;T&gt; contents; // 整数数组，可以是 16 位、32 位和 64 位&#125; 12345678127.0.0.1:6379&gt; sadd lishq:test 1 2 3(integer) 3127.0.0.1:6379&gt; debug object lishq:testValue at:0x7f3bd7e28590 refcount:1 encoding:intset serializedlength:15 lru:12860648 lru_seconds_idle:18127.0.0.1:6379&gt; sadd lishq:test java(integer) 1127.0.0.1:6379&gt; debug object lishq:testValue at:0x7f3bd7e28590 refcount:1 encoding:hashtable serializedlength:12 lru:12860705 lru_seconds_idle:11 观察 debug object 的输出字段 encoding 的值，可以发现当 set 里面放进去了非整数值时，存储形式立即从 intset 转变成了 hash 结构。 总结 压缩列表是一种为节约内存而开发的顺序型数据结构。 压缩列表被用作列表键和哈希键的底层实现之一。 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 添加新节点到压缩列表， 或者从压缩列表中删除节点， 可能会引发连锁更新操作， 但这种操作出现的几率并不高。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构之『字典』]]></title>
    <url>%2F2018%2F10%2F15%2Fredis-data-structure-dict%2F</url>
    <content type="text"><![CDATA[介绍dict 是 Redis 服务器中出现最为频繁的复合型数据结构 项目地址：https://github.com/lishq/redis-base-demo 数据结构 hash结构使用dict redis所有的key-value组成一个全局dict 带过期时间的key也是一个dict zset存储value和score值映射关系使用dict set的结构底层实现也是dict，只不过所有的value都是NULL12345678910struct RedisDb &#123; dict* dict; // all keys key=&gt;value dict* expires; // all expired keys key=&gt;long(timestamp) ...&#125;struct zset &#123; dict *dict; // all values value=&gt;score zskiplist *zsl;&#125; dict 内部结构 dict结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 的值被删除，新hashtable 取而代之。 1234struct dict &#123; ... dictht ht[2];&#125; 类似Java的HashMap，数组+链表的形式。 渐进式rehash大字典的扩容是遍历链表中所有旧元素，copy到新的数组下，O(n)的操作，所以redis执行渐进式搬迁。 当前dict的hset，hdel会触发搬迁操作 redis定时任务中主动进行搬迁 hash函数Redis 的字典默认的 hash 函数是 siphash。siphash 算法即使在输入 key 很小的情况下，也可以产生随机性特别好的输出，而且它的性能也非常突出 扩容条件正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。 缩容条件当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。缩容不会考虑 Redis 是否正在做 bgsave。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据结构之『字符串』]]></title>
    <url>%2F2018%2F10%2F15%2Fredis-data-structure-string%2F</url>
    <content type="text"><![CDATA[介绍Redis 中的字符串是可以修改的字符串，在内存中它是以字节数组的形式存在的。由于Redis对字符串在安全性、效率以及功能方面的要求。自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。 除了用来保存数据库中的字符串值之外， SDS 还被用作缓冲区（buffer） AOF 模块中的 AOF 缓冲区， 以及客户端状态中的输入缓冲区， 都是由 SDS 实现的 项目地址：https://github.com/lishq/redis-base-demo RedisObject123456struct SDS&lt;T&gt; &#123; T capacity; // 数组容量 T len; // 数组长度 byte flags; // 特殊标识位，不理睬它 byte[] content; // 数组内容&#125; 上面的 SDS 结构使用了范型 T，为什么不直接用 int 呢，这是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。### embstr vs rawRedis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。 Redis 对象头结构体1234567struct RedisObject &#123; int4 type; // 4bits int4 encoding; // 4bits int24 lru; // 24bits int32 refcount; // 4bytes ；对象引用计数器，内存回收 void *ptr; // 8bytes，64-bit system；指向对象内容的具体存储位置&#125; robj; 一个 RedisObject 对象头需要占据 16 字节的存储空间。 SDS结构体123456struct SDS &#123; int8 capacity; // 1byte int8 len; // 1byte int8 flags; // 1byte byte[] content; // 内联数组，长度为 capacity&#125; 在字符串比较小时，SDS 对象头的大小是capacity+3，至少是 3。意味着分配一个字符串的最小空间占用为 19 字节 (16+3)。 embstr将RedisObject对象头和sds连续存储，只需要一次malloc，占用内存更少。但是每次改变需要重新分配内存。 raw需要两次malloc，两个对象头在内存地址不连续。 因为jemalloc/tcmalloc 等分配内存的单位是2的指数。如果长度超过64bytes，redis认为是大字符串。不再使用embstr存储，改用raw形式。看上面这张图可以算出，留给 content 的长度最多只有 45(64-19) 字节了。字符串又是以\0结尾，之所以多出这样一个字节，是为了便于直接使用 glibc 的字符串处理函数，所以 embstr 最大能容纳的字符串长度就是 44。 扩容策略字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。 Redis 规定字符串的长度不得超过 512M 字节。创建字符串时 len 和 capacity 一样长，不会多分配冗余空间，这是因为绝大多数场景下我们不会使用 append 操作来修改字符串。 C字符串和 SDS 之间的区别 获取字符串长度的复杂度由O(N)降为O(1) 。 API 是安全的，不会造成缓冲区溢出。 修改字符串长度 N 次最多需要执行 N 次内存重分配。 可以保存文本或者二进制数据。 可以使用一部分 &lt;string.h&gt; 库中的函数。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于切面/快照/日志/操作/统计的通用服务]]></title>
    <url>%2F2018%2F09%2F26%2Fjava-annotation-common-log%2F</url>
    <content type="text"><![CDATA[介绍aop + 自定义注解，实现统一日志，统计，的功能。 期望能满足如下要求： 高吞吐 支持同步，异步两种模式，分别代表，允许丢数据，不允许丢数据 场景 登陆登出、系统核心功能调用频率统计、系统运行关键数据收集等 思路 需要一个自定义注解，一个aop，一个异步线程持续将数据写入到数据库中。当然也可以考虑同步的。 实现方法上的调用代码12345@AuditLog(operation = "动作标识",objectType="类型标识",type=async,module="模块标识", objectName=@Value("args[]"),level="日志级别")public boolean publishProblem(Object args) &#123; //dosomething&#125; aop中的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344@Aspect@Componentpublic class AuditLogInterceptor &#123; @Resource private AuditLogger auditLogger; private ExecutorService executors = new TraceThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; Object o = pjp.proceed(); try &#123; Method method = Modifier.isInterface(pjp.getSignature().getDeclaringType().getModifiers()) ? pjp.getTarget().getClass().getMethod(pjp.getSignature().getName(), ((MethodSignature) pjp.getSignature()).getMethod().getParameterTypes()) : ((MethodSignature) pjp.getSignature()).getMethod(); AuditLog auditLog = method.getAnnotation(AuditLog.class); if (!SyswareUtil.isEmpty(auditLog)) &#123; executors.execute(new AuditLogInterceptor.AuditLogThread(auditLogger, getAuditLog(auditLog, pjp.getArgs(), o))); &#125; &#125; catch (Exception e) &#123; throw new AuditLogException("获取实现方法发生错误：" + e.getMessage()); &#125; return o; &#125; public class AuditLogThread implements Runnable &#123; private AuditLogger service; private AuditLogObject instance; public AuditLogThread(AuditLogger service, AuditLogObject instance) &#123; this.service = service; this.instance = instance; &#125; @Override public void run()&#123; service.log(instance); &#125; &#125; 多线程参数传递问题使用多线程时父线程中的上下文信息通常无法直接传递到子线程中去，容易造成程序bug。 method-1：每次都手动的将子线程需要用到的ThreadLocal数据传递到子线程中，这样子线程也能随时获取到线程上下文信息。 method-2：自定义一个ThreadPoolExecutor代替系统的ThreadPoolExecutor，每次用线程池提交线程任务时，线程池会自动将父线程的ThreadLocal自动传递到子线程中，避免每次手动传递ThreadLocal到子线程。method-2实现12345678910111213141516171819202122232425262728293031323334353637public class TraceThreadPoolExecutor extends ThreadPoolExecutor &#123; public TraceThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; public TraceThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); &#125; public TraceThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); &#125; public TraceThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); &#125; @Override public void execute(final Runnable command) &#123; final Operator operator = OperationContext.getInstance().getOperator(); final String userId = operator.getUserId(); Runnable task = new Runnable() &#123; @Override public void run() &#123; OperationContextUtil.operatorContext(userId); try&#123; command.run(); &#125; catch (Exception e)&#123; //dosomething &#125; finally &#123; OperationContext.getInstance().clear(); &#125; &#125; &#125;; super.execute(task); &#125; 考虑的点 分布式部署，server端随时上下线会不会有影响，基本上常见的并发编程问题。 更优雅的接入方式，提供一个jar包，方法上增加一个注解即可。 与CAT等常用优秀开源产品的结合使用 总结 保证效率和代码质量的情况下，根据自身项目去灵活实现。合适自己的才是最好的 后续遇到其他的使用方案再进行补充]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-GC总结]]></title>
    <url>%2F2018%2F09%2F23%2Fjava-gc-review%2F</url>
    <content type="text"><![CDATA[介绍最近读了周志明先生写的深入理解jvm，不敢说理解有多深。总结以供回顾。 自动内存管理机制 对象是否已死 可达性分析算法判断对象是否存活的算法是这样的：通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。此外，这里没有使用引用记数算法，因为很难解决对象之间相互引用的关系。 垃圾收集算法标记-清除(Mark-Sweep)算法 效率不高；标记清除之后会产生大量空间碎片，导致提前触发一下次GC首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 复制算法 实现简单，运行高效。代价是把内存缩小为了原来的一半将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面然后再把已使用过的内存空间一次清理掉。 标记-整理算法标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集都发现有大批对象死去，只有少量存活，那就选用复制算法。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须用“标记-清理”或者“标记-整理”算法来进行回收。 常见垃圾收集器 串行 Serial 单线程的一个回收器，简单，易实现，效率高 并行 ParNew Serial的多线程版，可以充分的利用cpu的资源，减少回收的时间 吞吐量优先 Parallel Scavenge，侧重于吞吐量的控制 并发标记清除 CMS concurrent mark sweep 一种以获取最短回收停顿时间为目标的回收器，该回收器基于标记-清除算法 CMS GC 初始标记,仅仅标记一下GC Roots能直接关联到的对象，速度很快 concurrent-mark 并发标记，由前段标记过的绿色对象出发，所有可达到的对象都在本阶段标记 重新标记(修正并发标记期间因用户程序继续用作而导致标记产生变动的那一部分对象的标记记录)，暂停所有用户线程，重新扫描用户堆对象，进行可达性分析。注意，当前阶段以新生代对象为根来判断对象是否存活 并发清理，进行并发的垃圾清理 常用优化 如果应用存在大量的短期对象，应该选择较大的年轻代；如果存在相对较多的持久对象，老年代应该适当增大。 CMS提供CMSScavengeBeforeRemark参数，用来保证Remark前强制进行一次Minor GC 通过把-XX:PermSize参数和-XX:MaxPermSize设置成一样，强制虚拟机在启动的时候就把永久代的容量固定下来，避免运行时自动扩容 CMS默认情况下不会回收Perm区，通过参数CMSPermGenSweepingEnabled、CMSClassUnloadingEnabled ，可以让CMS在Perm区容量不足时对其回收 G1 GC 初始标记———&gt;并发标记———&gt;最终标记———&gt;清理回收 并行与并发;分代收集;空间整理;可预测的停顿;运行期间不会产生内存空间碎片;它将整个Java堆划分为多个大小相等的独立区域(Region),虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region的集合 region每个region被标记成eden, old, survivor, humongous，其中humongous代表巨型对象。region大小设置 -XX:G1HeapRegionSize ，1，2，4，8，32M，默认值是堆的大小/2048 yong gc一般对象均在eden区分配内存，除了humongous对象，当所有eden区域被耗尽内存时，触发yong gc，活跃对象copy到survivor区和old区中，空闲的region会被放入空闲列表-XX:MaxGCPauseMillis 设置G1收集过程目标时间，默认值200ms-XX:G1NewSizePercent 新生代最小值，默认值5%-XX:G1MaxNewSizePercent 新生代最大值，默认值60% mixed gc触发机制：当老年代的大小占整个堆大小百分比达到该阀值时，会触发一次mixed gc执行过程：参考cms执行过程。类似。会优先考虑收益高的old区域执行gc。 full gc如果对象内存分配过快，mixed gc来不及执行，导致年轻代被占满，就会触发full gc，serial old gc，导致长时间的暂停时间。 参数UseSerialGC:client模式下，采用serial+serial Old组合UseParNewGC:常用ParNew+Serial Old组合UseConcMarkSweepGC:常用ParNew+CMS+Serial OldUseParallelGC:采用Parallel Scavenge+serial Old收集器UseParallelOldGC:采用Parallel Scavenge+Parallel Old组合]]></content>
      <tags>
        <tag>Jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty-reactor]]></title>
    <url>%2F2018%2F09%2F22%2Fnetty-reactor%2F</url>
    <content type="text"><![CDATA[Reactor模型大量网络框架采用reactor模型进行设计和开发，reactor模式基于事件驱动，特别适合处理海量的I/O事件。 Reactor多线程模型 有专门的nio线程-acceptor线程用于监听服务端，接收客户端的tcp连接请求 网络io操作读写由一个nio线程池负责，包含一个队列和多个可用线程，由这些nio线程负责消息的读取，解码，编码，发送 一个nio线程可以同时处理n条链路，反之不可，防止出现并发操作问题 一个nio线程监听和处理客户端连接可能会存在性能问题。 例如百万客户端连接，or 服务端需要对客户端握手进行安全认证，本身非常损耗性能。 为了解决性能问题，出现了主从reactor多线程模型。 Netty中Reactor模型的实现 特点 服务端接收客户端的连接是一个独立的nio线程池 accptor线程池仅只用于客户端的登录，握手和安全认证，成功后，将链路注册到subReactor线程池上 相比nio创建更少的对象，更小的GC压力； 执行过程 从主线程中随机选择一个reactor线程作为accptor线程，用于绑定监听端口，接收客户端连接 accptor线程接收客户端连接请求后创建新的SocketChannel，将其注册到主线程池的其他reactor线程，其负责接入认证，黑白名单，握手等操作 将SocketChannel从主reactor线程摘除，重新注册到sub reactor线程池上，用于读取，解码，编码，发送操作 Netty中几个重要概念及其关系1.EventLoopGroup 2.EventLoop 3.boss/worker 4.channel 5.event(inbound/outbound) 6.pipeline 7.handler -------------------------------------------------------------------- 1.EventLoopGroup中包含一组EventLoop 2.EventLoop的大致数据结构是 a.一个任务队列 b.一个延迟任务队列(schedule) c.EventLoop绑定了一个Thread, 这直接避免了pipeline中的线程竞争 d.每个EventLoop有一个Selector, boss用Selector处理accept, worker用Selector处理read,write等 3.EventLoop执行的任务分为两大类:IO任务和非IO任务. a.IO任务比如: OP_ACCEPT、OP_CONNECT、OP_READ、OP_WRITE b.非IO任务比如: bind、channelActive等 4.boss可简单理解为Reactor模式中的mainReactor的角色, worker可简单理解为subReactor的角色 a.boss和worker共用EventLoop的代码逻辑 b.在不bind多端口的情况下bossEventLoopGroup中只需要包含一个EventLoop c.workerEventLoopGroup中一般包含多个EventLoop d.netty server启动后会把一个监听套接字ServerSocketChannel注册到bossEventLoop中 e.bossEventLoop一个主要责任就是负责accept连接(channel)然后dispatch到worker f.worker接到boss转发的channel后负责处理此chanel后续的read,write等event 5.channel分两大类ServerChannel和channel, ServerChannel对应着监听套接字(ServerSocketChannel), channel对应着一个网络连接 6.有两大类event:inbound/outbound(上行/下行) 7.event按照一定顺序在pipeline里面流转, 流转顺序参见下图 8.pipeline是责任链模式的设计，里面有多个handler的,上行事件顺序执行pipeline，下行事件逆序执行pipeline。 同时每个handler节点过滤在pipeline中流转的event, 如果判定需要自己处理这个event,则处理(用户可以在pipeline中添加自己的handler) -------------------------------------------------------------------- I/O Request via Channel or ChannelHandlerContext | +---------------------------------------------------+---------------+ | ChannelPipeline | | | \|/ | | +---------------------+ +-----------+----------+ | | | Inbound Handler N | | Outbound Handler 1 | | | +----------+----------+ +-----------+----------+ | | /|\ | | | | \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler N-1 | | Outbound Handler 2 | | | +----------+----------+ +-----------+----------+ | | /|\ . | | . . | | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()| | [ method call] [method call] | | . . | | . \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 2 | | Outbound Handler M-1 | | | +----------+----------+ +-----------+----------+ | | /|\ | | | | \|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 1 | | Outbound Handler M | | | +----------+----------+ +-----------+----------+ | | /|\ | | +---------------+-----------------------------------+---------------+ | \|/ +---------------+-----------------------------------+---------------+ | | | | | [ Socket.read() ] [ Socket.write() ] | | | | Netty Internal I/O Threads (Transport Implementation) | +-------------------------------------------------------------------+ NioEventLoop的设计原理 消息的读取，解码，后续handler的执行，始终由NioEventLoop负责，整个流程不会存在上下文的切换 一个客户端连接只注册到一个NioEventLoop上，避免了多个IO线程并发操作 一个NioEventLoop聚合了一个多路复用器Selector，因此可以处理成千上万的客户端连接 netty通过串行化线程水平并行处理，既能提升了多核并发处理能力，也避免了上下文切换和并发保护带来的额外性能损耗 Code实现：123456789101112131415161718192021newchild()protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider) args[0]);&#125;构造方法:NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider) &#123; super(parent, executor, false); // ...... provider = selectorProvider; selector = openSelector();&#125;父类构造方法:protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp) &#123; super(parent); // ...... this.addTaskWakesUp = addTaskWakesUp; this.executor = executor; taskQueue = newTaskQueue();&#125; 大致流程： 1.newChild():创建NioEventLoop线程,首先是打开一个selector 2.接着在父类中会构造一个MpscQueue:taskQueue用于外部线程执行(非IO事件)Netty任务的时候,如果判断不是在NioEventLoop对应线程里面执行,非IO事件都是先丢到这个MPSC队列再由worker线程去异步执行,PlatformDependent.newMpscQueue(maxPendingTasks)创建MpscQueue保存异步任务队列; 3.创建一个selector:provider.openSelector()创建selector轮询初始化连接 4.接着DISABLE_KEYSET_OPTIMIZATION是判断是否需要对sun.nio.ch.SelectorImpl中的selectedKeys进行优化, 不做配置的话默认需要优化. 哪些优化呢：1234567891011121314151617181920212223final class SelectedSelectionKeySet extends AbstractSet&lt;SelectionKey&gt; &#123; SelectionKey[] keys; int size; SelectedSelectionKeySet() &#123; keys = new SelectionKey[1024]; &#125; @Override public boolean add(SelectionKey o) &#123; if (o == null) &#123; return false; &#125; keys[size++] = o; if (size == keys.length) &#123; increaseCapacity(); &#125; return true; &#125;&#125; 原来SelectorImpl中的selectedKeys和publicSelectedKeys是个HashSet, 新的数据结构是数组, 初始大小1024。 a.避免了HashSet的频繁自动扩容。 b.屏蔽了remove、contains、iterator这些不需要的功能。 c.HashSet用拉链法解决哈希冲突, 也就是说它的数据结构是数组+链表, 而我们又知道, 对于selectedKeys, 最重要的操作是遍历全部元素, 但是数组+链表的数据结构对于cpu的 cache line 来说肯定是不够友好的.如果是直接遍历数组的话, cpu会把数组中相邻的元素一次加载到同一个cache line里面(一个cache line的大小一般是64个字节), 所以遍历数组无疑效率更高.]]></content>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 通配符替换的几种实现方式]]></title>
    <url>%2F2018%2F05%2F22%2Fjava-wildcard-achieve%2F</url>
    <content type="text"><![CDATA[Java常用通配符的替换及定制实现。 String.format(“hi, %s”, “uname”) log.info(“hi, {}”, “uname”) 自行实现思路： 方法体 format(Object… value)； 实现方式：字符匹配替换，Matcher类find。Pattern类的作用在于编译正则表达式后创建一个匹配模式.Matcher类使用Pattern实例提供的模式信息对正则表达式进行匹配.matcher.appendReplacement() 与 matcher.appendTail().前者是将当前匹配子串替换为指定字符串，并且将替换后的子串，以及其之前到上次匹配子串之后的字符串段添加到一个 StringBuffer 对象里。后者则将最后一次匹配工作后剩余的字符串添加到一个 StringBuffer 对象里。 Code实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private StringBuilder buffer;private static final String namedParameterPrefix = ":";private static final String regex = "[&#123;]\\d*[&#125;]";private static Pattern fsPattern = Pattern.compile(regex);public StringWrapper(String str) &#123; buffer = new StringBuilder(str);&#125;public StringWrapper(StringBuilder s)&#123; buffer = s;&#125;private Map&lt;String, Object&gt; namedParameter = new HashMap&lt;String, Object&gt;(32);public StringWrapper setParameter(String namedParameter, Object value) &#123; this.namedParameter.put(namedParameter, value); return this;&#125;public StringWrapper setProperties(Map&lt;String, Object&gt; map) &#123; namedParameter = map; return this;&#125;public String format(Object... value) &#123; if (namedParameter.size() &gt; 0) &#123; Set&lt;String&gt; keySet = namedParameter.keySet(); for (String key : keySet) &#123; Object objValue = namedParameter.get(key); String parameterName = namedParameterPrefix + key; buffer = new StringBuilder(buffer.toString().replace(parameterName, (objValue == null ? "" : objValue.toString()))); &#125; &#125; int len = value.length; if (len == 0) return buffer.toString(); StringBuffer sb = new StringBuffer(); Matcher matcher = fsPattern.matcher(buffer); while (matcher.find()) &#123; String group = matcher.group(); int index = getIndex(group); if (index &gt; len - 1) throw new RuntimeException("format的输入参数没有第" + (index + 1) + "个参数值！"); Object objValue = value[index]; matcher.appendReplacement(sb, (objValue == null ? "" : objValue.toString())); &#125; matcher.appendTail(sb); return sb.toString();&#125;public int getIndex(String group) &#123; if (group == null || group.trim().equals("")) throw new RuntimeException("regex匹配的group为空！"); int len = group.length(); return NumberUtils.toInt(group.substring(1, len - 1));&#125;public static void main(String[] args) &#123; String ttt = "hello world, :username, Time：&#123;0&#125;！"; StringWrapper w = new StringWrapper(ttt); System.out.println(w.setParameter("username", "lsq").format(new Date().getTime()));&#125; 执行结果如下hello world, lsq, Time：1526978430709！ String.format实现过程 分析源码得到其通过java.util.Formatter实现。 代码比较简洁，贴出用来作为对比。 先通过Matcher从字符串中查找分隔符，拆分成FOrmatString数组，在进行分段print输出。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static String format(String format, Object... args) &#123; return new Formatter().format(format, args).toString();&#125;public Formatter format(Locale l, String format, Object ... args) &#123; ensureOpen(); // index of last argument referenced int last = -1; // last ordinary index int lasto = -1; FormatString[] fsa = parse(format); for (int i = 0; i &lt; fsa.length; i++) &#123; FormatString fs = fsa[i]; int index = fs.index(); try &#123; switch (index) &#123; case -2: // fixed string, "%n", or "%%" fs.print(null, l); break; case -1: // relative index if (last &lt; 0 || (args != null &amp;&amp; last &gt; args.length - 1)) throw new MissingFormatArgumentException(fs.toString()); fs.print((args == null ? null : args[last]), l); break; case 0: // ordinary index lasto++; last = lasto; if (args != null &amp;&amp; lasto &gt; args.length - 1) throw new MissingFormatArgumentException(fs.toString()); fs.print((args == null ? null : args[lasto]), l); break; default: // explicit index last = index - 1; if (args != null &amp;&amp; last &gt; args.length - 1) throw new MissingFormatArgumentException(fs.toString()); fs.print((args == null ? null : args[last]), l); break; &#125; &#125; catch (IOException x) &#123; lastException = x; &#125; &#125; return this;&#125; org.slf4j.Logger.info实现过程 org.slf4j.helpers.MessageFormatter.arrayFormat() 总结 Formatter是广泛被用到的格式化方法，它能让一些东西变得更加有规范，很多超市小票，信息单，用这个方法来格式化就显得很不错。 String.format 这个方法很实用，但如果是大批量进行字符串格式化，就需要考虑到性能方面的问题，因为每次调用 format() 方法都会 new 一个 Formatter 对象。而在 Java 中频繁创建对象需要大量时间，而且还要花时间对这些对象进行GC。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
